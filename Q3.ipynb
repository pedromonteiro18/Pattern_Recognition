{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "colab": {
      "name": "Coursework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedromonteiro18/Pattern_Recognition/blob/master/Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rkTRAwNgyBl1",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedromonteiro18/Pattern_Recognition/blob/master/Coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "FCJ1GRw0yBl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.linalg import eigh\n",
        "\n",
        "\n",
        "mat_content = sio.loadmat('face.mat')\n",
        "1\n",
        "# mat_content # Let's see the content... \n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "q7to5znIyBl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_data = mat_content['X']\n",
        "face_labels = mat_content['l']\n",
        "\n",
        "#transpose to select test and training data\n",
        "face_data = face_data\n",
        "face_labels = face_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "gUqAR7rjyBmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39ddfa59-a8df-41cf-b2b7-f55f86347e73"
      },
      "source": [
        "#20/80 test/training split\n",
        "# data_train, data_test, label_train, label_test = train_test_split(\n",
        "#     face_data.T, face_labels.T, test_size=0.2, random_state =1 )\n",
        "# face_data = face_data.T\n",
        "# face_labels = face_labels.T\n",
        "\n",
        "data_train = np.reshape(face_data[:,:8],(2576,8))\n",
        "data_test= np.reshape(face_data[:,8:10],(2576,2))\n",
        "label_train = np.reshape(face_labels[:,:8],(1,8))\n",
        "label_test = np.reshape(face_labels[:,8:10],(1,2))\n",
        "\n",
        "\n",
        "for i in range(10,520,10):\n",
        "    data_train = np.concatenate((data_train, face_data[:,i:i+8]),axis=1)\n",
        "    data_test = np.concatenate((data_test, face_data[:,i+8:i+10]),axis=1)\n",
        "    label_train = np.concatenate((label_train, face_labels[:,i:i+8]),axis=1)\n",
        "    label_test = np.concatenate((label_test, face_labels[:,i+8:i+10]), axis=1)\n",
        "    \n",
        "    \n",
        "class_indexes = {k : [] for k in range(1, 53)}\n",
        "for i in range(label_train.shape[1]):\n",
        "    class_indexes[label_train.T[i].item()].append(i)\n",
        "    \n",
        "for i in range(1, len(class_indexes) + 1):\n",
        "    print(i, class_indexes[i], len(class_indexes[i]))\n",
        "\n",
        "fig = plt.figure(figsize = (20, 10))\n",
        "\n",
        "class_means = []\n",
        "\n",
        "for i in range(1, len(class_indexes)+1):\n",
        "    temp = np.zeros(2576)\n",
        "    for k in class_indexes[i]:\n",
        "        temp += data_train.T[k]\n",
        "    class_means.append(temp/len(class_indexes[i]))\n",
        "class_means = np.asarray(class_means)\n",
        "fig = plt.figure(figsize = (20, 10))\n",
        "\n",
        "for i in range(10):\n",
        "    img = np.reshape(class_means[i], (46, 56))\n",
        "    fig.add_subplot(2, 5, i+1)\n",
        "    plt.imshow(img.T, cmap = 'gist_gray' )\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 [0, 1, 2, 3, 4, 5, 6, 7] 8\n",
            "2 [8, 9, 10, 11, 12, 13, 14, 15] 8\n",
            "3 [16, 17, 18, 19, 20, 21, 22, 23] 8\n",
            "4 [24, 25, 26, 27, 28, 29, 30, 31] 8\n",
            "5 [32, 33, 34, 35, 36, 37, 38, 39] 8\n",
            "6 [40, 41, 42, 43, 44, 45, 46, 47] 8\n",
            "7 [48, 49, 50, 51, 52, 53, 54, 55] 8\n",
            "8 [56, 57, 58, 59, 60, 61, 62, 63] 8\n",
            "9 [64, 65, 66, 67, 68, 69, 70, 71] 8\n",
            "10 [72, 73, 74, 75, 76, 77, 78, 79] 8\n",
            "11 [80, 81, 82, 83, 84, 85, 86, 87] 8\n",
            "12 [88, 89, 90, 91, 92, 93, 94, 95] 8\n",
            "13 [96, 97, 98, 99, 100, 101, 102, 103] 8\n",
            "14 [104, 105, 106, 107, 108, 109, 110, 111] 8\n",
            "15 [112, 113, 114, 115, 116, 117, 118, 119] 8\n",
            "16 [120, 121, 122, 123, 124, 125, 126, 127] 8\n",
            "17 [128, 129, 130, 131, 132, 133, 134, 135] 8\n",
            "18 [136, 137, 138, 139, 140, 141, 142, 143] 8\n",
            "19 [144, 145, 146, 147, 148, 149, 150, 151] 8\n",
            "20 [152, 153, 154, 155, 156, 157, 158, 159] 8\n",
            "21 [160, 161, 162, 163, 164, 165, 166, 167] 8\n",
            "22 [168, 169, 170, 171, 172, 173, 174, 175] 8\n",
            "23 [176, 177, 178, 179, 180, 181, 182, 183] 8\n",
            "24 [184, 185, 186, 187, 188, 189, 190, 191] 8\n",
            "25 [192, 193, 194, 195, 196, 197, 198, 199] 8\n",
            "26 [200, 201, 202, 203, 204, 205, 206, 207] 8\n",
            "27 [208, 209, 210, 211, 212, 213, 214, 215] 8\n",
            "28 [216, 217, 218, 219, 220, 221, 222, 223] 8\n",
            "29 [224, 225, 226, 227, 228, 229, 230, 231] 8\n",
            "30 [232, 233, 234, 235, 236, 237, 238, 239] 8\n",
            "31 [240, 241, 242, 243, 244, 245, 246, 247] 8\n",
            "32 [248, 249, 250, 251, 252, 253, 254, 255] 8\n",
            "33 [256, 257, 258, 259, 260, 261, 262, 263] 8\n",
            "34 [264, 265, 266, 267, 268, 269, 270, 271] 8\n",
            "35 [272, 273, 274, 275, 276, 277, 278, 279] 8\n",
            "36 [280, 281, 282, 283, 284, 285, 286, 287] 8\n",
            "37 [288, 289, 290, 291, 292, 293, 294, 295] 8\n",
            "38 [296, 297, 298, 299, 300, 301, 302, 303] 8\n",
            "39 [304, 305, 306, 307, 308, 309, 310, 311] 8\n",
            "40 [312, 313, 314, 315, 316, 317, 318, 319] 8\n",
            "41 [320, 321, 322, 323, 324, 325, 326, 327] 8\n",
            "42 [328, 329, 330, 331, 332, 333, 334, 335] 8\n",
            "43 [336, 337, 338, 339, 340, 341, 342, 343] 8\n",
            "44 [344, 345, 346, 347, 348, 349, 350, 351] 8\n",
            "45 [352, 353, 354, 355, 356, 357, 358, 359] 8\n",
            "46 [360, 361, 362, 363, 364, 365, 366, 367] 8\n",
            "47 [368, 369, 370, 371, 372, 373, 374, 375] 8\n",
            "48 [376, 377, 378, 379, 380, 381, 382, 383] 8\n",
            "49 [384, 385, 386, 387, 388, 389, 390, 391] 8\n",
            "50 [392, 393, 394, 395, 396, 397, 398, 399] 8\n",
            "51 [400, 401, 402, 403, 404, 405, 406, 407] 8\n",
            "52 [408, 409, 410, 411, 412, 413, 414, 415] 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAI0CAYAAABrpu4pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "y-V6WJJ3yBmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_face = np.mean(data_train, axis = 1)\n",
        "\n",
        "print('Mean Face Shape {}'.format( mean_face.shape))\n",
        "mean_face_img = np.reshape(mean_face,(46,56))\n",
        "plt.imshow( mean_face_img.T, cmap = 'gist_gray')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOaWA22rB74m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6716e99c-ea66-4892-b4a0-116eb0259e47"
      },
      "source": [
        "print(data_train.shape)\n",
        "print(label_train.shape)\n",
        "train_subspaces = []\n",
        "for i in range(52):\n",
        "    images = []\n",
        "    for j in range(int(data_train.shape[1])):\n",
        "        if label_train.T[j][0] == i+1:\n",
        "          images.append(data_train.T[j])\n",
        "    images=np.asarray(images)\n",
        "    train_subspaces.append(images)\n",
        "print('    shape:', np.asarray(train_subspaces).shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2576, 416)\n",
            "(1, 416)\n",
            "    shape: (52, 8, 2576)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UoHQ8JGB7wS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NNkjtdVBQJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SWSB(bag_subspaces, X_bar_bag):\n",
        "    elements = np.asarray(bag_subspaces[0])\n",
        "    elements_mean = np.mean(elements, axis=0)\n",
        "    elements = np.subtract(elements,elements_mean)\n",
        "    S_W = np.matmul(elements.T,elements)\n",
        "    mean_diff = np.atleast_2d(elements_mean)-X_bar_bag\n",
        "#     print(mean_diff.shape)\n",
        "    S_B = np.matmul(mean_diff.T, mean_diff)\n",
        "    for i in range(1,52):\n",
        "#         print(i)\n",
        "        elements = np.asarray(bag_subspaces[i])\n",
        "#         print(train_subspaces.shape)\n",
        "        elements_mean = np.mean(elements, axis=0)\n",
        "        elements = np.subtract(elements,elements_mean)\n",
        "        S_W += np.matmul(elements.T,elements)\n",
        "        mean_diff = np.atleast_2d(elements_mean)-X_bar_bag\n",
        "        S_B += np.matmul(mean_diff.T, mean_diff)\n",
        "    \n",
        "    return S_W, S_B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xr3ui-GFcjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "dc2518b8-0ffd-4119-a6c3-0dd10d3d5f9d"
      },
      "source": [
        "S_W, S_B = SWSB(train_subspaces, mean_face)\n",
        "rank_SB = np.linalg.matrix_rank(S_B)\n",
        "rank_SW = np.linalg.matrix_rank(S_W)\n",
        "print('S_B: {}'.format(S_B.shape))\n",
        "print('Rank of S_B:', rank_SB)\n",
        "print('S_W: {}'.format(S_W.shape))\n",
        "print('Rank of S_W:', rank_SW)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S_B: (2576, 2576)\n",
            "Rank of S_B: 51\n",
            "S_W: (2576, 2576)\n",
            "Rank of S_W: 364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "f7BdAtdjyBmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e6e530d6-3ff2-46a7-d6ef-79ac0078baa5"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def createA(data):\n",
        "  avg = np.mean(data, axis = 0)\n",
        "  A = np.empty([0,2576])\n",
        "  for i in range(len(data)):\n",
        "    app = np.array([data[i] - avg])\n",
        "    newA = np.append(A, app, axis = 0)\n",
        "    A = newA\n",
        "  A = A.T\n",
        "\n",
        "  return  A, avg\n",
        "\n",
        "def createEig(A, S):\n",
        "  eigvals, eigvecs = np.linalg.eig(S)\n",
        "  eigvecs = preprocessing.normalize(np.real(np.dot(A, eigvecs).T))\n",
        "  idx = eigvals.argsort()[::-1]   \n",
        "  eigvals = eigvals[idx]\n",
        "  eigvecs  = eigvecs[idx, :]\n",
        "  return eigvals, eigvecs\n",
        "\n",
        "def PCA(data_train):\n",
        "  A, avg = createA(data_train)\n",
        "  #Low-dimensional computation of eigenspace of dataset 1\n",
        "  S2 = np.dot(A.T, A)*1/len(data_train)\n",
        "  Meigvals_new, Meigvecs_new = createEig(A, S2)\n",
        "  return Meigvals_new, Meigvecs_new, A, avg\n",
        "\n",
        "Meigvals_new, Meigvecs_new, A, avg = PCA(data_train.T)\n",
        "\n",
        "M_pca = 19\n",
        "M_lda = 30\n",
        "\n",
        "M_pca_range = rank_SW\n",
        "M_lda_range = rank_SB\n",
        "acc_array = np.empty((M_pca_range, M_lda_range))\n",
        "M_pca_array = np.arange(1, M_pca_range+1)\n",
        "M_lda_array = np.arange(1, M_lda_range+1)\n",
        "M_pca_best = None\n",
        "M_lda_best = None\n",
        "acc_max = 0\n",
        "for M_pca in range(1, M_pca_range):\n",
        "  for M_lda in range (1, M_lda_range):\n",
        "\n",
        "    eigvecsM = Meigvecs_new[:M_pca]\n",
        "    Wpca = np.dot(A.T, eigvecsM.T).T\n",
        "\n",
        "    X = Wpca.T\n",
        "    Y = label_train.reshape(label_train.shape[1])\n",
        "    lda = LinearDiscriminantAnalysis(n_components = M_lda)\n",
        "    Wlda = lda.fit_transform(X, Y)\n",
        "    \n",
        "    nn = KNeighborsClassifier(n_neighbors=1)\n",
        "    nn.fit(Wlda, label_train.T.ravel())\n",
        "\n",
        "    W_test = np.dot(eigvecsM, data_test ).T\n",
        "    W_test_2 = lda.transform(W_test)\n",
        "    Accuracy = nn.score(W_test_2, label_test.T.ravel())\n",
        "\n",
        "    \n",
        "    print(\"Mpca\",M_pca,\"Mlda\",M_lda,\"Accuracy\", Accuracy)\n",
        "    acc_array[M_pca-1, M_lda-1] = Accuracy\n",
        "\n",
        "    if (Accuracy > acc_max):\n",
        "              M_pca_best = M_pca\n",
        "              M_lda_best = M_lda\n",
        "              acc_max = Accuracy\n",
        "\n",
        "print(\"Accuracy is highest for M_pca:\", M_pca_best, \"M_lda\", M_lda_best)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mpca 1 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 2 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 3 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 4 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 5 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 6 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 7 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 8 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 9 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 10 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 11 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 12 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 13 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 14 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 15 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 16 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 17 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 18 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 19 Accuracy 0.019230769230769232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 1 Mlda 20 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 21 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 22 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 23 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 24 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 25 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 26 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 27 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 28 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 29 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 30 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 31 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 32 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 33 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 34 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 35 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 36 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 37 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 38 Accuracy 0.019230769230769232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 1 Mlda 39 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 40 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 41 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 42 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 43 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 44 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 45 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 46 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 47 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 48 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 49 Accuracy 0.019230769230769232\n",
            "Mpca 1 Mlda 50 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 2 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 3 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 4 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 5 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 6 Accuracy 0.019230769230769232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1, 52 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 2 Mlda 7 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 8 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 9 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 10 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 11 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 12 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 13 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 14 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 15 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 16 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 17 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 18 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 19 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 20 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 21 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 22 Accuracy 0.019230769230769232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 2 Mlda 23 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 24 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 25 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 26 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 27 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 28 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 29 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 30 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 31 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 32 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 33 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 34 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 35 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 36 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 37 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 38 Accuracy 0.019230769230769232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 2 Mlda 39 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 40 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 41 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 42 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 43 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 44 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 45 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 46 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 47 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 48 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 49 Accuracy 0.019230769230769232\n",
            "Mpca 2 Mlda 50 Accuracy 0.019230769230769232\n",
            "Mpca 3 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 3 Mlda 2 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 3 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 4 Accuracy 0.009615384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2, 52 - 1) = 2 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 3 Mlda 5 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 6 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 7 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 8 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 9 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 10 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 11 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 12 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 13 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 14 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 15 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 16 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 17 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 18 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 19 Accuracy 0.009615384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 3 Mlda 20 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 21 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 22 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 23 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 24 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 25 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 26 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 27 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 28 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 29 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 30 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 31 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 32 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 33 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 34 Accuracy 0.009615384615384616\n",
            "Mpca"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 3 Mlda 35 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 36 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 37 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 38 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 39 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 40 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 41 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 42 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 43 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 44 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 45 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 46 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 47 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 48 Accuracy 0.009615384615384616\n",
            "Mpca 3 Mlda 49 Accuracy 0.009615384615384616\n",
            "Mpca"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(3, 52 - 1) = 3 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 3 Mlda 50 Accuracy 0.009615384615384616\n",
            "Mpca 4 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 4 Mlda 2 Accuracy 0.04807692307692308\n",
            "Mpca 4 Mlda 3 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 4 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 5 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 6 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 7 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 8 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 9 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 10 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 11 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 12 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 13 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 14 Accuracy 0.028846153846153848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 4 Mlda 15 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 16 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 17 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 18 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 19 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 20 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 21 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 22 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 23 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 24 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 25 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 26 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 27 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 28 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 29 Accuracy 0.028846153846153848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 4 Mlda 30 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 31 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 32 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 33 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 34 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 35 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 36 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 37 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 38 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 39 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 40 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 41 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 42 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 43 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 44 Accuracy 0.028846153846153848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 4 Mlda 45 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 46 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 47 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 48 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 49 Accuracy 0.028846153846153848\n",
            "Mpca 4 Mlda 50 Accuracy 0.028846153846153848\n",
            "Mpca 5 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 5 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 5 Mlda 3 Accuracy 0.057692307692307696\n",
            "Mpca 5 Mlda 4 Accuracy 0.028846153846153848\n",
            "Mpca 5 Mlda 5 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 6 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 7 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 8 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 9 Accuracy 0.038461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(4, 52 - 1) = 4 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 5 Mlda 10 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 11 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 12 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 13 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 14 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 15 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 16 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 17 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 18 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 19 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 20 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 21 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 22 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 23 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 24 Accuracy 0.038461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 5 Mlda 25 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 26 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 27 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 28 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 29 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 30 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 31 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 32 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 33 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 34 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 35 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 36 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 37 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 38 Accuracy 0.038461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 5 Mlda 39 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 40 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 41 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 42 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 43 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 44 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 45 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 46 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 47 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 48 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 49 Accuracy 0.038461538461538464\n",
            "Mpca 5 Mlda 50 Accuracy 0.038461538461538464\n",
            "Mpca 6 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 6 Mlda 2 Accuracy 0.125\n",
            "Mpca 6 Mlda 3 Accuracy 0.11538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(5, 52 - 1) = 5 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 6 Mlda 4 Accuracy 0.057692307692307696\n",
            "Mpca 6 Mlda 5 Accuracy 0.0673076923076923\n",
            "Mpca 6 Mlda 6 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 7 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 8 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 9 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 10 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 11 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 12 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 13 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 14 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 15 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 16 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 17 Accuracy 0.04807692307692308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 6 Mlda 18 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 19 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 20 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 21 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 22 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 23 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 24 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 25 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 26 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 27 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 28 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 29 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 30 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 31 Accuracy 0.04807692307692308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 6 Mlda 32 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 33 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 34 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 35 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 36 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 37 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 38 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 39 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 40 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 41 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 42 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 43 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 44 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 45 Accuracy 0.04807692307692308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(6, 52 - 1) = 6 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 6 Mlda 46 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 47 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 48 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 49 Accuracy 0.04807692307692308\n",
            "Mpca 6 Mlda 50 Accuracy 0.04807692307692308\n",
            "Mpca 7 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 7 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 7 Mlda 3 Accuracy 0.11538461538461539\n",
            "Mpca 7 Mlda 4 Accuracy 0.09615384615384616\n",
            "Mpca 7 Mlda 5 Accuracy 0.08653846153846154\n",
            "Mpca 7 Mlda 6 Accuracy 0.07692307692307693\n",
            "Mpca 7 Mlda 7 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 8 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 9 Accuracy 0.0673076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 7 Mlda 10 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 11 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 12 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 13 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 14 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 15 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 16 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 17 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 18 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 19 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 20 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 21 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 22 Accuracy 0.0673076923076923\n",
            "Mpca"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 7 Mlda 23 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 24 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 25 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 26 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 27 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 28 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 29 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 30 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 31 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 32 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 33 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 34 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 35 Accuracy 0.0673076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 7 Mlda 36 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 37 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 38 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 39 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 40 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 41 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 42 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 43 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 44 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 45 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 46 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 47 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 48 Accuracy 0.0673076923076923\n",
            "Mpca 7 Mlda 49 Accuracy 0.0673076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(7, 52 - 1) = 7 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 7 Mlda 50 Accuracy 0.0673076923076923\n",
            "Mpca 8 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 8 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 8 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 8 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 8 Mlda 5 Accuracy 0.09615384615384616\n",
            "Mpca 8 Mlda 6 Accuracy 0.0673076923076923\n",
            "Mpca 8 Mlda 7 Accuracy 0.07692307692307693\n",
            "Mpca 8 Mlda 8 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 9 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 10 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 11 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 12 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 13 Accuracy 0.08653846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 8 Mlda 14 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 15 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 16 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 17 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 18 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 19 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 20 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 21 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 22 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 23 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 24 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 25 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 26 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 27 Accuracy 0.08653846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 8 Mlda 28 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 29 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 30 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 31 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 32 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 33 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 34 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 35 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 36 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 37 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 38 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 39 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 40 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 41 Accuracy 0.08653846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(8, 52 - 1) = 8 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 8 Mlda 42 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 43 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 44 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 45 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 46 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 47 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 48 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 49 Accuracy 0.08653846153846154\n",
            "Mpca 8 Mlda 50 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 9 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 9 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 9 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 9 Mlda 5 Accuracy 0.11538461538461539\n",
            "Mpca 9 Mlda 6 Accuracy 0.09615384615384616\n",
            "Mpca 9 Mlda 7 Accuracy 0.07692307692307693\n",
            "Mpca 9 Mlda 8 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 9 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 10 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 11 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 12 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 13 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 14 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 15 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 16 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 17 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 18 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 19 Accuracy 0.08653846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 9 Mlda 20 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 21 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 22 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 23 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 24 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 25 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 26 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 27 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 28 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 29 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 30 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 31 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 32 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 33 Accuracy 0.08653846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 9 Mlda 34 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 35 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 36 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 37 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 38 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 39 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 40 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 41 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 42 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 43 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 44 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 45 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 46 Accuracy 0.08653846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 9 Mlda 47 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 48 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 49 Accuracy 0.08653846153846154\n",
            "Mpca 9 Mlda 50 Accuracy 0.08653846153846154\n",
            "Mpca 10 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 10 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 10 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 10 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 10 Mlda 5 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 6 Accuracy 0.125\n",
            "Mpca 10 Mlda 7 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 8 Accuracy 0.08653846153846154\n",
            "Mpca 10 Mlda 9 Accuracy 0.10576923076923077\n",
            "Mpca 10 Mlda 10 Accuracy 0.11538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 52 - 1) = 9 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 10 Mlda 11 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 12 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 13 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 14 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 15 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 16 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 17 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 18 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 19 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 20 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 21 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 22 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 23 Accuracy 0.11538461538461539\n",
            "Mpca 10 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mlda 24 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 25 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 26 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 27 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 28 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 29 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 30 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 31 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 32 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 33 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 34 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 35 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 36 Accuracy 0.11538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 10 Mlda 37 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 38 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 39 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 40 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 41 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 42 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 43 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 44 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 45 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 46 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 47 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 48 Accuracy 0.11538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(10, 52 - 1) = 10 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 10 Mlda 49 Accuracy 0.11538461538461539\n",
            "Mpca 10 Mlda 50 Accuracy 0.11538461538461539\n",
            "Mpca 11 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 11 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 11 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 11 Mlda 4 Accuracy 0.23076923076923078\n",
            "Mpca 11 Mlda 5 Accuracy 0.07692307692307693\n",
            "Mpca 11 Mlda 6 Accuracy 0.16346153846153846\n",
            "Mpca 11 Mlda 7 Accuracy 0.16346153846153846\n",
            "Mpca 11 Mlda 8 Accuracy 0.14423076923076922\n",
            "Mpca 11 Mlda 9 Accuracy 0.11538461538461539\n",
            "Mpca 11 Mlda 10 Accuracy 0.10576923076923077\n",
            "Mpca 11 Mlda 11 Accuracy 0.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 11 Mlda 12 Accuracy 0.125\n",
            "Mpca 11 Mlda 13 Accuracy 0.125\n",
            "Mpca 11 Mlda 14 Accuracy 0.125\n",
            "Mpca 11 Mlda 15 Accuracy 0.125\n",
            "Mpca 11 Mlda 16 Accuracy 0.125\n",
            "Mpca 11 Mlda 17 Accuracy 0.125\n",
            "Mpca 11 Mlda 18 Accuracy 0.125\n",
            "Mpca 11 Mlda 19 Accuracy 0.125\n",
            "Mpca 11 Mlda 20 Accuracy 0.125\n",
            "Mpca 11 Mlda 21 Accuracy 0.125\n",
            "Mpca 11 Mlda 22 Accuracy 0.125\n",
            "Mpca 11 Mlda 23 Accuracy 0.125\n",
            "Mpca 11 Mlda 24 Accuracy 0.125\n",
            "Mpca 11 Mlda 25 Accuracy 0.125\n",
            "Mpca 11 Mlda 26 Accuracy 0.125\n",
            "Mpca 11 Mlda 27 Accuracy 0.125\n",
            "Mpca 11 Mlda 28 Accuracy 0.125\n",
            "Mpca 11 Mlda 29 Accuracy 0.125\n",
            "Mpca 11 Mlda 30 Accuracy 0.125\n",
            "Mpca 11 Mlda 31 Accuracy 0.125\n",
            "Mpca 11 Mlda 32 Accuracy 0.125\n",
            "Mpca 11 Mlda 33 Accuracy 0.125\n",
            "Mpca 11 Mlda 34 Accuracy 0.125\n",
            "Mpca 11 Mlda 35 Accuracy 0.125\n",
            "Mpca 11 Mlda 36 Accuracy 0.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 11 Mlda 37 Accuracy 0.125\n",
            "Mpca 11 Mlda 38 Accuracy 0.125\n",
            "Mpca 11 Mlda 39 Accuracy 0.125\n",
            "Mpca 11 Mlda 40 Accuracy 0.125\n",
            "Mpca 11 Mlda 41 Accuracy 0.125\n",
            "Mpca 11 Mlda 42 Accuracy 0.125\n",
            "Mpca 11 Mlda 43 Accuracy 0.125\n",
            "Mpca 11 Mlda 44 Accuracy 0.125\n",
            "Mpca 11 Mlda 45 Accuracy 0.125\n",
            "Mpca 11 Mlda 46 Accuracy 0.125\n",
            "Mpca 11 Mlda 47 Accuracy 0.125\n",
            "Mpca 11 Mlda 48 Accuracy 0.125\n",
            "Mpca 11 Mlda 49 Accuracy 0.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(11, 52 - 1) = 11 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 11 Mlda 50 Accuracy 0.125\n",
            "Mpca 12 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 12 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 12 Mlda 3 Accuracy 0.3076923076923077\n",
            "Mpca 12 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 12 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 12 Mlda 6 Accuracy 0.1346153846153846\n",
            "Mpca 12 Mlda 7 Accuracy 0.15384615384615385\n",
            "Mpca 12 Mlda 8 Accuracy 0.15384615384615385\n",
            "Mpca 12 Mlda 9 Accuracy 0.14423076923076922\n",
            "Mpca 12 Mlda 10 Accuracy 0.1346153846153846\n",
            "Mpca 12 Mlda 11 Accuracy 0.11538461538461539\n",
            "Mpca 12 Mlda 12 Accuracy 0.125\n",
            "Mpca 12 Mlda 13 Accuracy 0.125\n",
            "Mpca 12 Mlda 14 Accuracy 0.125\n",
            "Mpca 12 Mlda 15 Accuracy 0.125\n",
            "Mpca 12 Mlda 16 Accuracy 0.125\n",
            "Mpca 12 Mlda 17 Accuracy 0.125\n",
            "Mpca 12 Mlda 18 Accuracy 0.125\n",
            "Mpca 12 Mlda 19 Accuracy 0.125\n",
            "Mpca 12 Mlda 20 Accuracy 0.125\n",
            "Mpca 12 Mlda 21 Accuracy 0.125\n",
            "Mpca 12 Mlda 22 Accuracy 0.125\n",
            "Mpca 12 Mlda 23 Accuracy 0.125\n",
            "Mpca 12 Mlda 24 Accuracy 0.125\n",
            "Mpca 12 Mlda 25 Accuracy 0.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 12 Mlda 26 Accuracy 0.125\n",
            "Mpca 12 Mlda 27 Accuracy 0.125\n",
            "Mpca 12 Mlda 28 Accuracy 0.125\n",
            "Mpca 12 Mlda 29 Accuracy 0.125\n",
            "Mpca 12 Mlda 30 Accuracy 0.125\n",
            "Mpca 12 Mlda 31 Accuracy 0.125\n",
            "Mpca 12 Mlda 32 Accuracy 0.125\n",
            "Mpca 12 Mlda 33 Accuracy 0.125\n",
            "Mpca 12 Mlda 34 Accuracy 0.125\n",
            "Mpca 12 Mlda 35 Accuracy 0.125\n",
            "Mpca 12 Mlda 36 Accuracy 0.125\n",
            "Mpca 12 Mlda 37 Accuracy 0.125\n",
            "Mpca 12 Mlda 38 Accuracy 0.125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(12, 52 - 1) = 12 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 12 Mlda 39 Accuracy 0.125\n",
            "Mpca 12 Mlda 40 Accuracy 0.125\n",
            "Mpca 12 Mlda 41 Accuracy 0.125\n",
            "Mpca 12 Mlda 42 Accuracy 0.125\n",
            "Mpca 12 Mlda 43 Accuracy 0.125\n",
            "Mpca 12 Mlda 44 Accuracy 0.125\n",
            "Mpca 12 Mlda 45 Accuracy 0.125\n",
            "Mpca 12 Mlda 46 Accuracy 0.125\n",
            "Mpca 12 Mlda 47 Accuracy 0.125\n",
            "Mpca 12 Mlda 48 Accuracy 0.125\n",
            "Mpca 12 Mlda 49 Accuracy 0.125\n",
            "Mpca 12 Mlda 50 Accuracy 0.125\n",
            "Mpca 13 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 13 Mlda 2 Accuracy 0.125\n",
            "Mpca 13 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 13 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 13 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 13 Mlda 6 Accuracy 0.14423076923076922\n",
            "Mpca 13 Mlda 7 Accuracy 0.19230769230769232\n",
            "Mpca 13 Mlda 8 Accuracy 0.14423076923076922\n",
            "Mpca 13 Mlda 9 Accuracy 0.125\n",
            "Mpca 13 Mlda 10 Accuracy 0.125\n",
            "Mpca 13 Mlda 11 Accuracy 0.14423076923076922\n",
            "Mpca 13 Mlda 12 Accuracy 0.125\n",
            "Mpca 13 Mlda 13 Accuracy 0.11538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 13 Mlda 14 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 15 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 16 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 17 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 18 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 19 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 20 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 21 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 22 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 23 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 24 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 25 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 26 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 27 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 28 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 29 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 30 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 31 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 32 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 33 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 34 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 35 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 36 Accuracy 0.11538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 13 Mlda 37 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 38 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 39 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 40 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 41 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 42 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 43 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 44 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 45 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 46 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 47 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 48 Accuracy 0.11538461538461539\n",
            "Mpca 13"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Mlda 49 Accuracy 0.11538461538461539\n",
            "Mpca 13 Mlda 50 Accuracy 0.11538461538461539\n",
            "Mpca 14 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 14 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 14 Mlda 3 Accuracy 0.25\n",
            "Mpca 14 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 14 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 14 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 14 Mlda 7 Accuracy 0.17307692307692307\n",
            "Mpca 14 Mlda 8 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 9 Accuracy 0.14423076923076922\n",
            "Mpca 14 Mlda 10 Accuracy 0.15384615384615385\n",
            "Mpca 14 Mlda 11 Accuracy 0.15384615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 52 - 1) = 13 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 14 Mlda 12 Accuracy 0.16346153846153846\n",
            "Mpca 14 Mlda 13 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 14 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 15 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 16 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 17 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 18 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 19 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 20 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 21 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 22 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 23 Accuracy 0.18269230769230768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 14 Mlda 24 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 25 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 26 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 27 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 28 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 29 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 30 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 31 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 32 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 33 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 34 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 35 Accuracy 0.18269230769230768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 14 Mlda 36 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 37 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 38 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 39 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 40 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 41 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 42 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 43 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 44 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 45 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 46 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 47 Accuracy 0.18269230769230768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(14, 52 - 1) = 14 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 14 Mlda 48 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 49 Accuracy 0.18269230769230768\n",
            "Mpca 14 Mlda 50 Accuracy 0.18269230769230768\n",
            "Mpca 15 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 15 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 15 Mlda 3 Accuracy 0.14423076923076922\n",
            "Mpca 15 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 15 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 15 Mlda 6 Accuracy 0.33653846153846156\n",
            "Mpca 15 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 15 Mlda 8 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 9 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 10 Accuracy 0.15384615384615385\n",
            "Mpca 15 Mlda 11 Accuracy 0.17307692307692307\n",
            "Mpca 15 Mlda 12 Accuracy 0.15384615384615385\n",
            "Mpca 15 Mlda 13 Accuracy 0.17307692307692307\n",
            "Mpca 15 Mlda 14 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 15 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 16 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 17 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 18 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 19 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 20 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 21 Accuracy 0.21153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 15 Mlda 22 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 23 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 24 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 25 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 26 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 27 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 28 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 29 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 30 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 31 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 32 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 33 Accuracy 0.21153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 15 Mlda 34 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 35 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 36 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 37 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 38 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 39 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 40 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 41 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 42 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 43 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 44 Accuracy 0.21153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(15, 52 - 1) = 15 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 15 Mlda 45 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 46 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 47 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 48 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 49 Accuracy 0.21153846153846154\n",
            "Mpca 15 Mlda 50 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 16 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 16 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 16 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 16 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 16 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 16 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 16 Mlda 8 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 9 Accuracy 0.22115384615384615\n",
            "Mpca 16 Mlda 10 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 11 Accuracy 0.19230769230769232\n",
            "Mpca 16 Mlda 12 Accuracy 0.20192307692307693\n",
            "Mpca 16 Mlda 13 Accuracy 0.20192307692307693\n",
            "Mpca 16 Mlda 14 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 15 Accuracy 0.22115384615384615\n",
            "Mpca 16 Mlda 16 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 17 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 18 Accuracy 0.21153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 16 Mlda 19 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 20 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 21 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 22 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 23 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 24 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 25 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 26 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 27 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 28 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 29 Accuracy 0.21153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 16 Mlda 30 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 31 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 32 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 33 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 34 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 35 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 36 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 37 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 38 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 39 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 40 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 41"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(16, 52 - 1) = 16 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 42 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 43 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 44 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 45 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 46 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 47 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 48 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 49 Accuracy 0.21153846153846154\n",
            "Mpca 16 Mlda 50 Accuracy 0.21153846153846154\n",
            "Mpca 17 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 17 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 17 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 17 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 17 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 17 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 17 Mlda 8 Accuracy 0.2403846153846154\n",
            "Mpca 17 Mlda 9 Accuracy 0.28846153846153844\n",
            "Mpca 17 Mlda 10 Accuracy 0.27884615384615385\n",
            "Mpca 17 Mlda 11 Accuracy 0.23076923076923078\n",
            "Mpca 17 Mlda 12 Accuracy 0.22115384615384615\n",
            "Mpca 17 Mlda 13 Accuracy 0.22115384615384615\n",
            "Mpca 17 Mlda 14 Accuracy 0.23076923076923078\n",
            "Mpca 17 Mlda 15 Accuracy 0.2403846153846154\n",
            "Mpca 17 Mlda 16 Accuracy 0.27884615384615385\n",
            "Mpca 17 Mlda 17 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 18 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 19 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 20 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 21 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 22 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 23 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 24 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 25 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 26 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 17 Mlda 27 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 28 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 29 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 30 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 31 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 32 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 33 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 34 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 35 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 36 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 37 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 17 Mlda 38 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 39 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 40 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 41 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 42 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 43 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 44 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 45 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 46 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 47 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 48 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(17, 52 - 1) = 17 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 17 Mlda 49 Accuracy 0.25961538461538464\n",
            "Mpca 17 Mlda 50 Accuracy 0.25961538461538464\n",
            "Mpca 18 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 18 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 18 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 18 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 18 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 18 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 18 Mlda 7 Accuracy 0.4230769230769231\n",
            "Mpca 18 Mlda 8 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 9 Accuracy 0.27884615384615385\n",
            "Mpca 18 Mlda 10 Accuracy 0.3173076923076923\n",
            "Mpca 18 Mlda 11 Accuracy 0.2692307692307692\n",
            "Mpca 18 Mlda 12 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 13 Accuracy 0.25961538461538464\n",
            "Mpca 18 Mlda 14 Accuracy 0.25961538461538464\n",
            "Mpca 18 Mlda 15 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 16 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 17 Accuracy 0.25961538461538464\n",
            "Mpca 18 Mlda 18 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 19 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 20 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 21 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 22 Accuracy 0.2403846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 18 Mlda 23 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 24 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 25 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 26 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 27 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 28 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 29 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 30 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 31 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 32 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 33 Accuracy 0.2403846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 18 Mlda 34 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 35 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 36 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 37 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 38 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 39 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 40 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 41 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 42 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 43 Accuracy 0.2403846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(18, 52 - 1) = 18 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 18 Mlda 44 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 45 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 46 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 47 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 48 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 49 Accuracy 0.2403846153846154\n",
            "Mpca 18 Mlda 50 Accuracy 0.2403846153846154\n",
            "Mpca 19 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 19 Mlda 2 Accuracy 0.125\n",
            "Mpca 19 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 19 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 19 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 19 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 19 Mlda 8 Accuracy 0.3557692307692308\n",
            "Mpca 19 Mlda 9 Accuracy 0.3269230769230769\n",
            "Mpca 19 Mlda 10 Accuracy 0.33653846153846156\n",
            "Mpca 19 Mlda 11 Accuracy 0.28846153846153844\n",
            "Mpca 19 Mlda 12 Accuracy 0.25961538461538464\n",
            "Mpca 19 Mlda 13 Accuracy 0.2403846153846154\n",
            "Mpca 19 Mlda 14 Accuracy 0.2692307692307692\n",
            "Mpca 19 Mlda 15 Accuracy 0.25961538461538464\n",
            "Mpca 19 Mlda 16 Accuracy 0.28846153846153844\n",
            "Mpca 19 Mlda 17 Accuracy 0.2692307692307692\n",
            "Mpca 19 Mlda 18 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 19 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 20 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 21 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 22 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 23 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 24 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 25 Accuracy 0.27884615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 19 Mlda 26 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 27 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 28 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 29 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 30 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 31 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 32 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 33 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 34 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 35 Accuracy 0.27884615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 19 Mlda 36 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 37 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 38 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 39 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 40 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 41 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 42 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 43 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 44 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 45 Accuracy 0.27884615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 19 Mlda 46 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 47 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 48 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 49 Accuracy 0.27884615384615385\n",
            "Mpca 19 Mlda 50 Accuracy 0.27884615384615385\n",
            "Mpca 20 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 20 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 20 Mlda 3 Accuracy 0.3076923076923077\n",
            "Mpca 20 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 20 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 20 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 20 Mlda 7 Accuracy 0.3942307692307692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(19, 52 - 1) = 19 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 20 Mlda 8 Accuracy 0.27884615384615385\n",
            "Mpca 20 Mlda 9 Accuracy 0.25\n",
            "Mpca 20 Mlda 10 Accuracy 0.2980769230769231\n",
            "Mpca 20 Mlda 11 Accuracy 0.3076923076923077\n",
            "Mpca 20 Mlda 12 Accuracy 0.33653846153846156\n",
            "Mpca 20 Mlda 13 Accuracy 0.28846153846153844\n",
            "Mpca 20 Mlda 14 Accuracy 0.28846153846153844\n",
            "Mpca 20 Mlda 15 Accuracy 0.22115384615384615\n",
            "Mpca 20 Mlda 16 Accuracy 0.25\n",
            "Mpca 20 Mlda 17 Accuracy 0.27884615384615385\n",
            "Mpca 20 Mlda 18 Accuracy 0.28846153846153844\n",
            "Mpca 20 Mlda 19 Accuracy 0.2692307692307692\n",
            "Mpca 20 Mlda 20 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 21 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 22 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 23 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 24 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 25 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 26 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 27 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 28 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 29 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 20 Mlda 30 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 31 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 32 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 33 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 34 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 35 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 36 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 37 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 38 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 39 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 20 Mlda 40 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 41 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 42 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 43 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 44 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 45 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 46 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 47 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 48 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 49 Accuracy 0.25961538461538464\n",
            "Mpca 20 Mlda 50 Accuracy"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(20, 52 - 1) = 20 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 0.25961538461538464\n",
            "Mpca 21 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 21 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 21 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 21 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 21 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 21 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 21 Mlda 7 Accuracy 0.3557692307692308\n",
            "Mpca 21 Mlda 8 Accuracy 0.3942307692307692\n",
            "Mpca 21 Mlda 9 Accuracy 0.25\n",
            "Mpca 21 Mlda 10 Accuracy 0.3173076923076923\n",
            "Mpca 21 Mlda 11 Accuracy 0.3173076923076923\n",
            "Mpca 21 Mlda 12 Accuracy 0.28846153846153844\n",
            "Mpca 21 Mlda 13 Accuracy 0.34615384615384615\n",
            "Mpca 21 Mlda 14 Accuracy 0.3076923076923077\n",
            "Mpca 21 Mlda 15 Accuracy 0.3173076923076923\n",
            "Mpca 21 Mlda 16 Accuracy 0.22115384615384615\n",
            "Mpca 21 Mlda 17 Accuracy 0.25\n",
            "Mpca 21 Mlda 18 Accuracy 0.2692307692307692\n",
            "Mpca 21 Mlda 19 Accuracy 0.3173076923076923\n",
            "Mpca 21 Mlda 20 Accuracy 0.28846153846153844\n",
            "Mpca 21 Mlda 21 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 22 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 23 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 24 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 21 Mlda 25 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 26 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 27 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 28 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 29 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 30 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 31 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 32 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 21 Mlda 33 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 34 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 35 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 36 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 37 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 38 Accuracy 0.25961538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 21 Mlda 39 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 40 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 41 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 42 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 43 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 44 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 45 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 46 Accuracy 0.25961538461538464\n",
            "Mpca"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 21 Mlda 47 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 48 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 49 Accuracy 0.25961538461538464\n",
            "Mpca 21 Mlda 50 Accuracy 0.25961538461538464\n",
            "Mpca 22 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 22 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 22 Mlda 3 Accuracy 0.2980769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(21, 52 - 1) = 21 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 22 Mlda 4 Accuracy 0.375\n",
            "Mpca 22 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 22 Mlda 6 Accuracy 0.5480769230769231\n",
            "Mpca 22 Mlda 7 Accuracy 0.5\n",
            "Mpca 22 Mlda 8 Accuracy 0.28846153846153844\n",
            "Mpca 22 Mlda 9 Accuracy 0.2980769230769231\n",
            "Mpca 22 Mlda 10 Accuracy 0.33653846153846156\n",
            "Mpca 22 Mlda 11 Accuracy 0.3269230769230769\n",
            "Mpca 22 Mlda 12 Accuracy 0.34615384615384615\n",
            "Mpca 22 Mlda 13 Accuracy 0.3269230769230769\n",
            "Mpca 22 Mlda 14 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 15 Accuracy 0.3076923076923077\n",
            "Mpca 22 Mlda 16 Accuracy 0.28846153846153844\n",
            "Mpca 22 Mlda 17 Accuracy 0.2692307692307692\n",
            "Mpca 22 Mlda 18 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 19 Accuracy 0.28846153846153844\n",
            "Mpca 22 Mlda 20 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 21 Accuracy 0.2980769230769231\n",
            "Mpca 22 Mlda 22 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 23 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 24 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 25 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 26 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 27 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 28 Accuracy 0.3173076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 22 Mlda 29 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 30 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 31 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 32 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 33 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 34 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 35 Accuracy 0.3173076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 22 Mlda 36 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 37 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 38 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 39 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 40 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 41 Accuracy 0.3173076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 22 Mlda 42 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 43 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 44 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 45 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 46 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 47 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 48 Accuracy 0.3173076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 22 Mlda 49 Accuracy 0.3173076923076923\n",
            "Mpca 22 Mlda 50 Accuracy 0.3173076923076923\n",
            "Mpca 23 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 23 Mlda 2 Accuracy 0.125\n",
            "Mpca 23 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 23 Mlda 4 Accuracy 0.4230769230769231\n",
            "Mpca 23 Mlda 5 Accuracy 0.5\n",
            "Mpca 23 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 23 Mlda 7 Accuracy 0.34615384615384615\n",
            "Mpca 23 Mlda 8 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 9 Accuracy 0.3173076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(22, 52 - 1) = 22 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 23 Mlda 10 Accuracy 0.3942307692307692\n",
            "Mpca 23 Mlda 11 Accuracy 0.36538461538461536\n",
            "Mpca 23 Mlda 12 Accuracy 0.38461538461538464\n",
            "Mpca 23 Mlda 13 Accuracy 0.28846153846153844\n",
            "Mpca 23 Mlda 14 Accuracy 0.3076923076923077\n",
            "Mpca 23 Mlda 15 Accuracy 0.28846153846153844\n",
            "Mpca 23 Mlda 16 Accuracy 0.2403846153846154\n",
            "Mpca 23 Mlda 17 Accuracy 0.2692307692307692\n",
            "Mpca 23 Mlda 18 Accuracy 0.3269230769230769\n",
            "Mpca 23 Mlda 19 Accuracy 0.33653846153846156\n",
            "Mpca 23 Mlda 20 Accuracy 0.3076923076923077\n",
            "Mpca 23 Mlda 21 Accuracy 0.3173076923076923\n",
            "Mpca 23 Mlda 22 Accuracy 0.28846153846153844\n",
            "Mpca 23 Mlda 23 Accuracy 0.2980769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 23 Mlda 24 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 25 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 26 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 27 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 28 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 29 Accuracy 0.2980769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 23 Mlda 30 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 31 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 32 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 33 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 34 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 35 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 36 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 37 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 38 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 39 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 40 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 41 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 42 Accuracy 0.2980769230769231\n",
            "Mpca"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 23 Mlda 43 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 44 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 45 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 46 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 47 Accuracy 0.2980769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 23 Mlda 48 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 49 Accuracy 0.2980769230769231\n",
            "Mpca 23 Mlda 50 Accuracy 0.2980769230769231\n",
            "Mpca 24 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 24 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 24 Mlda 3 Accuracy 0.3173076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(23, 52 - 1) = 23 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 24 Mlda 4 Accuracy 0.4519230769230769\n",
            "Mpca 24 Mlda 5 Accuracy 0.47115384615384615\n",
            "Mpca 24 Mlda 6 Accuracy 0.5480769230769231\n",
            "Mpca 24 Mlda 7 Accuracy 0.3076923076923077\n",
            "Mpca 24 Mlda 8 Accuracy 0.2980769230769231\n",
            "Mpca 24 Mlda 9 Accuracy 0.34615384615384615\n",
            "Mpca 24 Mlda 10 Accuracy 0.34615384615384615\n",
            "Mpca 24 Mlda 11 Accuracy 0.34615384615384615\n",
            "Mpca 24 Mlda 12 Accuracy 0.34615384615384615\n",
            "Mpca 24 Mlda 13 Accuracy 0.3173076923076923\n",
            "Mpca 24 Mlda 14 Accuracy 0.36538461538461536\n",
            "Mpca 24 Mlda 15 Accuracy 0.3557692307692308\n",
            "Mpca 24 Mlda 16 Accuracy 0.375\n",
            "Mpca 24 Mlda 17 Accuracy 0.3173076923076923\n",
            "Mpca 24 Mlda 18 Accuracy 0.3269230769230769\n",
            "Mpca 24 Mlda 19 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 20 Accuracy 0.40384615384615385\n",
            "Mpca 24 Mlda 21 Accuracy 0.375\n",
            "Mpca 24 Mlda 22 Accuracy 0.36538461538461536\n",
            "Mpca 24 Mlda 23 Accuracy 0.36538461538461536\n",
            "Mpca 24 Mlda 24 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 25 Accuracy 0.38461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 24 Mlda 26 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 27 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 28 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 29 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 30 Accuracy 0.38461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 24 Mlda 31 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 32 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 33 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 34 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 35 Accuracy 0.38461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 24 Mlda 36 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 37 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 38 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 39 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 40 Accuracy 0.38461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 24 Mlda 41 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 42 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 43 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 44 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 45 Accuracy 0.38461538461538464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(24, 52 - 1) = 24 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 24 Mlda 46 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 47 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 48 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 49 Accuracy 0.38461538461538464\n",
            "Mpca 24 Mlda 50 Accuracy 0.38461538461538464\n",
            "Mpca 25 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 25 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 25 Mlda 3 Accuracy 0.3173076923076923\n",
            "Mpca 25 Mlda 4 Accuracy 0.4230769230769231\n",
            "Mpca 25 Mlda 5 Accuracy 0.5\n",
            "Mpca 25 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 25 Mlda 7 Accuracy 0.3269230769230769\n",
            "Mpca 25 Mlda 8 Accuracy 0.2980769230769231\n",
            "Mpca 25 Mlda 9 Accuracy 0.36538461538461536\n",
            "Mpca 25 Mlda 10 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 11 Accuracy 0.4230769230769231\n",
            "Mpca 25 Mlda 12 Accuracy 0.375\n",
            "Mpca 25 Mlda 13 Accuracy 0.3269230769230769\n",
            "Mpca 25 Mlda 14 Accuracy 0.36538461538461536\n",
            "Mpca 25 Mlda 15 Accuracy 0.38461538461538464\n",
            "Mpca 25 Mlda 16 Accuracy 0.3942307692307692\n",
            "Mpca 25 Mlda 17 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 18 Accuracy 0.34615384615384615\n",
            "Mpca 25 Mlda 19 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 20 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 21 Accuracy 0.3942307692307692\n",
            "Mpca 25 Mlda 22 Accuracy 0.41346153846153844\n",
            "Mpca 25 Mlda 23 Accuracy 0.41346153846153844\n",
            "Mpca 25 Mlda 24 Accuracy 0.4230769230769231\n",
            "Mpca 25 Mlda 25 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 26 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 27 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 28 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 29 Accuracy 0.40384615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 25 Mlda 30 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 31 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 32 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 33 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 34 Accuracy 0.40384615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 25 Mlda 35 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 36 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 37 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 38 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 39 Accuracy 0.40384615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 25 Mlda 40 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 41 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 42 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 43 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 44 Accuracy 0.40384615384615385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 25 Mlda 45 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 46 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 47 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 48 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 49 Accuracy 0.40384615384615385\n",
            "Mpca 25 Mlda 50 Accuracy 0.40384615384615385\n",
            "Mpca 26 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 26 Mlda 2 Accuracy 0.09615384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(25, 52 - 1) = 25 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 26 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 26 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 26 Mlda 5 Accuracy 0.5096153846153846\n",
            "Mpca 26 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 26 Mlda 7 Accuracy 0.2980769230769231\n",
            "Mpca 26 Mlda 8 Accuracy 0.27884615384615385\n",
            "Mpca 26 Mlda 9 Accuracy 0.2980769230769231\n",
            "Mpca 26 Mlda 10 Accuracy 0.3557692307692308\n",
            "Mpca 26 Mlda 11 Accuracy 0.3942307692307692\n",
            "Mpca 26 Mlda 12 Accuracy 0.38461538461538464\n",
            "Mpca 26 Mlda 13 Accuracy 0.3557692307692308\n",
            "Mpca 26 Mlda 14 Accuracy 0.2692307692307692\n",
            "Mpca 26 Mlda 15 Accuracy 0.33653846153846156\n",
            "Mpca 26 Mlda 16 Accuracy 0.34615384615384615\n",
            "Mpca 26 Mlda 17 Accuracy 0.375\n",
            "Mpca 26 Mlda 18 Accuracy 0.34615384615384615\n",
            "Mpca 26 Mlda 19 Accuracy 0.3269230769230769\n",
            "Mpca 26 Mlda 20 Accuracy 0.36538461538461536\n",
            "Mpca 26 Mlda 21 Accuracy 0.375\n",
            "Mpca 26 Mlda 22 Accuracy 0.40384615384615385\n",
            "Mpca 26 Mlda 23 Accuracy 0.40384615384615385\n",
            "Mpca 26 Mlda 24 Accuracy 0.3942307692307692\n",
            "Mpca 26 Mlda 25 Accuracy 0.4326923076923077\n",
            "Mpca 26 Mlda 26 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 27 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 28 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 29 Accuracy 0.41346153846153844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 26 Mlda 30 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 31 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 32 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 33 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 34 Accuracy 0.41346153846153844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 26 Mlda 35 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 36 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 37 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 38 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 39 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 40 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 41 Accuracy 0.41346153846153844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 26 Mlda 42 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 43 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 44 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 45 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 46 Accuracy 0.41346153846153844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 26 Mlda 47 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 48 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 49 Accuracy 0.41346153846153844\n",
            "Mpca 26 Mlda 50 Accuracy 0.41346153846153844\n",
            "Mpca 27 Mlda 1 Accuracy 0.028846153846153848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(26, 52 - 1) = 26 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 27 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 27 Mlda 3 Accuracy 0.14423076923076922\n",
            "Mpca 27 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 27 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 27 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 27 Mlda 7 Accuracy 0.41346153846153844\n",
            "Mpca 27 Mlda 8 Accuracy 0.34615384615384615\n",
            "Mpca 27 Mlda 9 Accuracy 0.375\n",
            "Mpca 27 Mlda 10 Accuracy 0.375\n",
            "Mpca 27 Mlda 11 Accuracy 0.3942307692307692\n",
            "Mpca 27 Mlda 12 Accuracy 0.40384615384615385\n",
            "Mpca 27 Mlda 13 Accuracy 0.4326923076923077\n",
            "Mpca 27 Mlda 14 Accuracy 0.33653846153846156\n",
            "Mpca 27 Mlda 15 Accuracy 0.34615384615384615\n",
            "Mpca 27 Mlda 16 Accuracy 0.4230769230769231\n",
            "Mpca 27 Mlda 17 Accuracy 0.41346153846153844\n",
            "Mpca 27 Mlda 18 Accuracy 0.41346153846153844\n",
            "Mpca 27 Mlda 19 Accuracy 0.4230769230769231\n",
            "Mpca 27 Mlda 20 Accuracy 0.4326923076923077\n",
            "Mpca 27 Mlda 21 Accuracy 0.4326923076923077\n",
            "Mpca 27 Mlda 22 Accuracy 0.4807692307692308\n",
            "Mpca 27 Mlda 23 Accuracy 0.46153846153846156\n",
            "Mpca 27 Mlda 24 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 25 Accuracy 0.4423076923076923\n",
            "Mpca 27 Mlda 26 Accuracy 0.46153846153846156\n",
            "Mpca 27 Mlda 27 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 28 Accuracy 0.4519230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 27 Mlda 29 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 30 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 31 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 32 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 33 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 34 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 35 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 36 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 37 Accuracy 0.4519230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 27 Mlda 38 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 39 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 40 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 41 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 42 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 43 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 44 Accuracy 0.4519230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(27, 52 - 1) = 27 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 27 Mlda 45 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 46 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 47 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 48 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 49 Accuracy 0.4519230769230769\n",
            "Mpca 27 Mlda 50 Accuracy 0.4519230769230769\n",
            "Mpca 28 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 28 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 28 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 28 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 28 Mlda 5 Accuracy 0.375\n",
            "Mpca 28 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 28 Mlda 7 Accuracy 0.33653846153846156\n",
            "Mpca 28 Mlda 8 Accuracy 0.3173076923076923\n",
            "Mpca 28 Mlda 9 Accuracy 0.3557692307692308\n",
            "Mpca 28 Mlda 10 Accuracy 0.3942307692307692\n",
            "Mpca 28 Mlda 11 Accuracy 0.41346153846153844\n",
            "Mpca 28 Mlda 12 Accuracy 0.41346153846153844\n",
            "Mpca 28 Mlda 13 Accuracy 0.4423076923076923\n",
            "Mpca 28 Mlda 14 Accuracy 0.41346153846153844\n",
            "Mpca 28 Mlda 15 Accuracy 0.3942307692307692\n",
            "Mpca 28 Mlda 16 Accuracy 0.4326923076923077\n",
            "Mpca 28 Mlda 17 Accuracy 0.4423076923076923\n",
            "Mpca 28 Mlda 18 Accuracy 0.4326923076923077\n",
            "Mpca 28 Mlda 19 Accuracy 0.41346153846153844\n",
            "Mpca 28 Mlda 20 Accuracy 0.4230769230769231\n",
            "Mpca 28 Mlda 21 Accuracy 0.4230769230769231\n",
            "Mpca 28 Mlda 22 Accuracy 0.5096153846153846\n",
            "Mpca 28 Mlda 23 Accuracy 0.5096153846153846\n",
            "Mpca 28 Mlda 24 Accuracy 0.46153846153846156\n",
            "Mpca 28 Mlda 25 Accuracy 0.4807692307692308\n",
            "Mpca 28 Mlda 26 Accuracy 0.46153846153846156\n",
            "Mpca 28 Mlda 27 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 28 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 29 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 30 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 31 Accuracy 0.49038461538461536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 28 Mlda 32 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 33 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 34 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 35 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 36 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 37 Accuracy 0.49038461538461536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 28 Mlda 38 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 39 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 40 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 41 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 42 Accuracy 0.49038461538461536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 28 Mlda 43 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 44 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 45 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 46 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 47 Accuracy 0.49038461538461536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 28 Mlda 48 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 49 Accuracy 0.49038461538461536\n",
            "Mpca 28 Mlda 50 Accuracy 0.49038461538461536\n",
            "Mpca 29 Mlda 1 Accuracy 0.009615384615384616\n",
            "Mpca 29 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 29 Mlda 3 Accuracy 0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(28, 52 - 1) = 28 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 29 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 29 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 29 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 29 Mlda 7 Accuracy 0.3076923076923077\n",
            "Mpca 29 Mlda 8 Accuracy 0.3173076923076923\n",
            "Mpca 29 Mlda 9 Accuracy 0.33653846153846156\n",
            "Mpca 29 Mlda 10 Accuracy 0.36538461538461536\n",
            "Mpca 29 Mlda 11 Accuracy 0.4326923076923077\n",
            "Mpca 29 Mlda 12 Accuracy 0.4326923076923077\n",
            "Mpca 29 Mlda 13 Accuracy 0.5096153846153846\n",
            "Mpca 29 Mlda 14 Accuracy 0.4807692307692308\n",
            "Mpca 29 Mlda 15 Accuracy 0.4423076923076923\n",
            "Mpca 29 Mlda 16 Accuracy 0.4423076923076923\n",
            "Mpca 29 Mlda 17 Accuracy 0.47115384615384615\n",
            "Mpca 29 Mlda 18 Accuracy 0.4519230769230769\n",
            "Mpca 29 Mlda 19 Accuracy 0.41346153846153844\n",
            "Mpca 29 Mlda 20 Accuracy 0.4230769230769231\n",
            "Mpca 29 Mlda 21 Accuracy 0.46153846153846156\n",
            "Mpca 29 Mlda 22 Accuracy 0.49038461538461536\n",
            "Mpca 29 Mlda 23 Accuracy 0.5096153846153846\n",
            "Mpca 29 Mlda 24 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 25 Accuracy 0.49038461538461536\n",
            "Mpca 29 Mlda 26 Accuracy 0.5480769230769231\n",
            "Mpca 29 Mlda 27 Accuracy 0.5192307692307693\n",
            "Mpca 29 Mlda 28 Accuracy 0.5192307692307693\n",
            "Mpca 29 Mlda 29 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 30 Accuracy 0.5288461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 29 Mlda 31 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 32 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 33 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 34 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 35 Accuracy 0.5288461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 29 Mlda 36 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 37 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 38 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 39 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 40 Accuracy 0.5288461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 29 Mlda 41 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 42 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 43 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 44 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 45 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 46 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 47 Accuracy 0.5288461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(29, 52 - 1) = 29 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 29 Mlda 48 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 49 Accuracy 0.5288461538461539\n",
            "Mpca 29 Mlda 50 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 30 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 30 Mlda 3 Accuracy 0.25\n",
            "Mpca 30 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 30 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 30 Mlda 6 Accuracy 0.5\n",
            "Mpca 30 Mlda 7 Accuracy 0.28846153846153844\n",
            "Mpca 30 Mlda 8 Accuracy 0.34615384615384615\n",
            "Mpca 30 Mlda 9 Accuracy 0.3557692307692308\n",
            "Mpca 30 Mlda 10 Accuracy 0.375\n",
            "Mpca 30 Mlda 11 Accuracy 0.40384615384615385\n",
            "Mpca 30 Mlda 12 Accuracy 0.46153846153846156\n",
            "Mpca 30 Mlda 13 Accuracy 0.5\n",
            "Mpca 30 Mlda 14 Accuracy 0.5096153846153846\n",
            "Mpca 30 Mlda 15 Accuracy 0.4807692307692308\n",
            "Mpca 30 Mlda 16 Accuracy 0.5\n",
            "Mpca 30 Mlda 17 Accuracy 0.5192307692307693\n",
            "Mpca 30 Mlda 18 Accuracy 0.4326923076923077\n",
            "Mpca 30 Mlda 19 Accuracy 0.47115384615384615\n",
            "Mpca 30 Mlda 20 Accuracy 0.47115384615384615\n",
            "Mpca 30 Mlda 21 Accuracy 0.47115384615384615\n",
            "Mpca 30 Mlda 22 Accuracy 0.4807692307692308\n",
            "Mpca 30 Mlda 23 Accuracy 0.5\n",
            "Mpca 30 Mlda 24 Accuracy 0.5096153846153846\n",
            "Mpca 30 Mlda 25 Accuracy 0.5096153846153846\n",
            "Mpca 30 Mlda 26 Accuracy 0.4807692307692308\n",
            "Mpca 30 Mlda 27 Accuracy 0.5480769230769231\n",
            "Mpca 30 Mlda 28 Accuracy 0.5673076923076923\n",
            "Mpca 30 Mlda 29 Accuracy 0.5384615384615384\n",
            "Mpca 30 Mlda 30 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 31 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 32 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 33 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 34 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 35 Accuracy 0.5288461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 30 Mlda 36 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 37 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 38 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 39 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 40 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 41 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 42 Accuracy 0.5288461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 30 Mlda 43 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 44 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 45 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 46 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 47 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 48 Accuracy 0.5288461538461539\n",
            "Mpca 30 Mlda 49 Accuracy 0.5288461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(30, 52 - 1) = 30 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 30 Mlda 50 Accuracy 0.5288461538461539\n",
            "Mpca 31 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 31 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 31 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 31 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 31 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 31 Mlda 6 Accuracy 0.5288461538461539\n",
            "Mpca 31 Mlda 7 Accuracy 0.33653846153846156\n",
            "Mpca 31 Mlda 8 Accuracy 0.375\n",
            "Mpca 31 Mlda 9 Accuracy 0.375\n",
            "Mpca 31 Mlda 10 Accuracy 0.41346153846153844\n",
            "Mpca 31 Mlda 11 Accuracy 0.4519230769230769\n",
            "Mpca 31 Mlda 12 Accuracy 0.47115384615384615\n",
            "Mpca 31 Mlda 13 Accuracy 0.4519230769230769\n",
            "Mpca 31 Mlda 14 Accuracy 0.40384615384615385\n",
            "Mpca 31 Mlda 15 Accuracy 0.4423076923076923\n",
            "Mpca 31 Mlda 16 Accuracy 0.47115384615384615\n",
            "Mpca 31 Mlda 17 Accuracy 0.4807692307692308\n",
            "Mpca 31 Mlda 18 Accuracy 0.5192307692307693\n",
            "Mpca 31 Mlda 19 Accuracy 0.46153846153846156\n",
            "Mpca 31 Mlda 20 Accuracy 0.4519230769230769\n",
            "Mpca 31 Mlda 21 Accuracy 0.4423076923076923\n",
            "Mpca 31 Mlda 22 Accuracy 0.47115384615384615\n",
            "Mpca 31 Mlda 23 Accuracy 0.4807692307692308\n",
            "Mpca 31 Mlda 24 Accuracy 0.5288461538461539\n",
            "Mpca 31 Mlda 25 Accuracy 0.5192307692307693\n",
            "Mpca 31 Mlda 26 Accuracy 0.5288461538461539\n",
            "Mpca 31 Mlda 27 Accuracy 0.5192307692307693\n",
            "Mpca 31 Mlda 28 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 29 Accuracy 0.5673076923076923\n",
            "Mpca 31 Mlda 30 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 31 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 32 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 33 Accuracy 0.5769230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 31 Mlda 34 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 35 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 36 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 37 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 38 Accuracy 0.5769230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 31 Mlda 39 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 40 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 41 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 42 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 43 Accuracy 0.5769230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 31 Mlda 44 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 45 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 46 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 47 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 48 Accuracy 0.5769230769230769\n",
            "Mpca 31 Mlda 49 Accuracy 0.5769230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(31, 52 - 1) = 31 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 31 Mlda 50 Accuracy 0.5769230769230769\n",
            "Mpca 32 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 32 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 32 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 32 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 32 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 32 Mlda 6 Accuracy 0.5192307692307693\n",
            "Mpca 32 Mlda 7 Accuracy 0.4519230769230769\n",
            "Mpca 32 Mlda 8 Accuracy 0.40384615384615385\n",
            "Mpca 32 Mlda 9 Accuracy 0.4423076923076923\n",
            "Mpca 32 Mlda 10 Accuracy 0.4326923076923077\n",
            "Mpca 32 Mlda 11 Accuracy 0.47115384615384615\n",
            "Mpca 32 Mlda 12 Accuracy 0.47115384615384615\n",
            "Mpca 32 Mlda 13 Accuracy 0.5\n",
            "Mpca 32 Mlda 14 Accuracy 0.4230769230769231\n",
            "Mpca 32 Mlda 15 Accuracy 0.4423076923076923\n",
            "Mpca 32 Mlda 16 Accuracy 0.47115384615384615\n",
            "Mpca 32 Mlda 17 Accuracy 0.5288461538461539\n",
            "Mpca 32 Mlda 18 Accuracy 0.5480769230769231\n",
            "Mpca 32 Mlda 19 Accuracy 0.46153846153846156\n",
            "Mpca 32 Mlda 20 Accuracy 0.5\n",
            "Mpca 32 Mlda 21 Accuracy 0.4423076923076923\n",
            "Mpca 32 Mlda 22 Accuracy 0.49038461538461536\n",
            "Mpca 32 Mlda 23 Accuracy 0.5192307692307693\n",
            "Mpca 32 Mlda 24 Accuracy 0.5192307692307693\n",
            "Mpca 32 Mlda 25 Accuracy 0.5576923076923077\n",
            "Mpca 32 Mlda 26 Accuracy 0.5480769230769231\n",
            "Mpca 32 Mlda 27 Accuracy 0.5673076923076923\n",
            "Mpca 32 Mlda 28 Accuracy 0.5673076923076923\n",
            "Mpca 32 Mlda 29 Accuracy 0.625\n",
            "Mpca 32 Mlda 30 Accuracy 0.6153846153846154\n",
            "Mpca 32 Mlda 31 Accuracy 0.6057692307692307\n",
            "Mpca 32 Mlda 32 Accuracy 0.625\n",
            "Mpca 32 Mlda 33 Accuracy 0.625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 32 Mlda 34 Accuracy 0.625\n",
            "Mpca 32 Mlda 35 Accuracy 0.625\n",
            "Mpca 32 Mlda 36 Accuracy 0.625\n",
            "Mpca 32 Mlda 37 Accuracy 0.625\n",
            "Mpca 32 Mlda 38 Accuracy 0.625\n",
            "Mpca 32 Mlda 39 Accuracy 0.625\n",
            "Mpca 32 Mlda 40 Accuracy 0.625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 32 Mlda 41 Accuracy 0.625\n",
            "Mpca 32 Mlda 42 Accuracy 0.625\n",
            "Mpca 32 Mlda 43 Accuracy 0.625\n",
            "Mpca 32 Mlda 44 Accuracy 0.625\n",
            "Mpca 32 Mlda 45 Accuracy 0.625\n",
            "Mpca 32 Mlda 46 Accuracy 0.625\n",
            "Mpca 32 Mlda 47 Accuracy 0.625\n",
            "Mpca 32 Mlda 48 Accuracy 0.625\n",
            "Mpca 32 Mlda 49 Accuracy 0.625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(32, 52 - 1) = 32 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 32 Mlda 50 Accuracy 0.625\n",
            "Mpca 33 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 33 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 33 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 33 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 33 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 33 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 33 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 33 Mlda 8 Accuracy 0.38461538461538464\n",
            "Mpca 33 Mlda 9 Accuracy 0.4230769230769231\n",
            "Mpca 33 Mlda 10 Accuracy 0.4519230769230769\n",
            "Mpca 33 Mlda 11 Accuracy 0.5\n",
            "Mpca 33 Mlda 12 Accuracy 0.46153846153846156\n",
            "Mpca 33 Mlda 13 Accuracy 0.5384615384615384\n",
            "Mpca 33 Mlda 14 Accuracy 0.4326923076923077\n",
            "Mpca 33 Mlda 15 Accuracy 0.47115384615384615\n",
            "Mpca 33 Mlda 16 Accuracy 0.49038461538461536\n",
            "Mpca 33 Mlda 17 Accuracy 0.5384615384615384\n",
            "Mpca 33 Mlda 18 Accuracy 0.5576923076923077\n",
            "Mpca 33 Mlda 19 Accuracy 0.5096153846153846\n",
            "Mpca 33 Mlda 20 Accuracy 0.5192307692307693\n",
            "Mpca 33 Mlda 21 Accuracy 0.47115384615384615\n",
            "Mpca 33 Mlda 22 Accuracy 0.5\n",
            "Mpca 33 Mlda 23 Accuracy 0.5096153846153846\n",
            "Mpca 33 Mlda 24 Accuracy 0.5384615384615384\n",
            "Mpca 33 Mlda 25 Accuracy 0.5576923076923077\n",
            "Mpca 33 Mlda 26 Accuracy 0.5576923076923077\n",
            "Mpca 33 Mlda 27 Accuracy 0.5769230769230769\n",
            "Mpca 33 Mlda 28 Accuracy 0.5673076923076923\n",
            "Mpca 33 Mlda 29 Accuracy 0.6057692307692307\n",
            "Mpca 33 Mlda 30 Accuracy 0.5961538461538461\n",
            "Mpca 33 Mlda 31 Accuracy 0.5961538461538461\n",
            "Mpca 33 Mlda 32 Accuracy 0.5961538461538461\n",
            "Mpca 33 Mlda 33 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 34 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 35 Accuracy 0.6153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 33 Mlda 36 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 37 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 38 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 39 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 40 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 41 Accuracy 0.6153846153846154\n",
            "Mpca"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 33 Mlda 42 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 43 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 44 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 45 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 46 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 47 Accuracy 0.6153846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(33, 52 - 1) = 33 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 33 Mlda 48 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 49 Accuracy 0.6153846153846154\n",
            "Mpca 33 Mlda 50 Accuracy 0.6153846153846154\n",
            "Mpca 34 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 34 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 34 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 34 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 34 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 34 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 34 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 34 Mlda 8 Accuracy 0.46153846153846156\n",
            "Mpca 34 Mlda 9 Accuracy 0.4326923076923077\n",
            "Mpca 34 Mlda 10 Accuracy 0.5192307692307693\n",
            "Mpca 34 Mlda 11 Accuracy 0.5\n",
            "Mpca 34 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 34 Mlda 13 Accuracy 0.5480769230769231\n",
            "Mpca 34 Mlda 14 Accuracy 0.5096153846153846\n",
            "Mpca 34 Mlda 15 Accuracy 0.5576923076923077\n",
            "Mpca 34 Mlda 16 Accuracy 0.5384615384615384\n",
            "Mpca 34 Mlda 17 Accuracy 0.5769230769230769\n",
            "Mpca 34 Mlda 18 Accuracy 0.6153846153846154\n",
            "Mpca 34 Mlda 19 Accuracy 0.6346153846153846\n",
            "Mpca 34 Mlda 20 Accuracy 0.5480769230769231\n",
            "Mpca 34 Mlda 21 Accuracy 0.5096153846153846\n",
            "Mpca 34 Mlda 22 Accuracy 0.5576923076923077\n",
            "Mpca 34 Mlda 23 Accuracy 0.5576923076923077\n",
            "Mpca 34 Mlda 24 Accuracy 0.5480769230769231\n",
            "Mpca 34 Mlda 25 Accuracy 0.5480769230769231\n",
            "Mpca 34 Mlda 26 Accuracy 0.5865384615384616\n",
            "Mpca 34 Mlda 27 Accuracy 0.5576923076923077\n",
            "Mpca 34 Mlda 28 Accuracy 0.5576923076923077\n",
            "Mpca 34 Mlda 29 Accuracy 0.5865384615384616\n",
            "Mpca 34 Mlda 30 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 31 Accuracy 0.6442307692307693\n",
            "Mpca 34 Mlda 32 Accuracy 0.6346153846153846\n",
            "Mpca 34 Mlda 33 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 34 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 35 Accuracy 0.6057692307692307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 34 Mlda 36 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 37 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 38 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 39 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 40 Accuracy 0.6057692307692307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 34 Mlda 41 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 42 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 43 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 44 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 45 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 46 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 47 Accuracy 0.6057692307692307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(34, 52 - 1) = 34 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 34 Mlda 48 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 49 Accuracy 0.6057692307692307\n",
            "Mpca 34 Mlda 50 Accuracy 0.6057692307692307\n",
            "Mpca 35 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 35 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 35 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 35 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 35 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 35 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 35 Mlda 7 Accuracy 0.6057692307692307\n",
            "Mpca 35 Mlda 8 Accuracy 0.4519230769230769\n",
            "Mpca 35 Mlda 9 Accuracy 0.5\n",
            "Mpca 35 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 35 Mlda 11 Accuracy 0.5096153846153846\n",
            "Mpca 35 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 35 Mlda 13 Accuracy 0.5288461538461539\n",
            "Mpca 35 Mlda 14 Accuracy 0.5096153846153846\n",
            "Mpca 35 Mlda 15 Accuracy 0.5576923076923077\n",
            "Mpca 35 Mlda 16 Accuracy 0.5480769230769231\n",
            "Mpca 35 Mlda 17 Accuracy 0.5576923076923077\n",
            "Mpca 35 Mlda 18 Accuracy 0.5961538461538461\n",
            "Mpca 35 Mlda 19 Accuracy 0.6057692307692307\n",
            "Mpca 35 Mlda 20 Accuracy 0.5961538461538461\n",
            "Mpca 35 Mlda 21 Accuracy 0.5769230769230769\n",
            "Mpca 35 Mlda 22 Accuracy 0.5384615384615384\n",
            "Mpca 35 Mlda 23 Accuracy 0.5673076923076923\n",
            "Mpca 35 Mlda 24 Accuracy 0.5769230769230769\n",
            "Mpca 35 Mlda 25 Accuracy 0.5576923076923077\n",
            "Mpca 35 Mlda 26 Accuracy 0.5673076923076923\n",
            "Mpca 35 Mlda 27 Accuracy 0.5961538461538461\n",
            "Mpca 35 Mlda 28 Accuracy 0.6057692307692307\n",
            "Mpca 35 Mlda 29 Accuracy 0.625\n",
            "Mpca 35 Mlda 30 Accuracy 0.6057692307692307\n",
            "Mpca 35 Mlda 31 Accuracy 0.625\n",
            "Mpca 35 Mlda 32 Accuracy 0.6346153846153846\n",
            "Mpca 35 Mlda 33 Accuracy 0.6442307692307693\n",
            "Mpca 35 Mlda 34 Accuracy 0.6442307692307693\n",
            "Mpca 35 Mlda 35 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 36 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 37 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 38 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 39 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 40 Accuracy 0.6538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 35 Mlda 41 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 42 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 43 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 44 Accuracy 0.6538461538461539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 35 Mlda 45 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 46 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 47 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 48 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 49 Accuracy 0.6538461538461539\n",
            "Mpca 35 Mlda 50 Accuracy 0.6538461538461539\n",
            "Mpca 36 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 36 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 36 Mlda 3 Accuracy 0.20192307692307693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(35, 52 - 1) = 35 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 36 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 36 Mlda 5 Accuracy 0.5\n",
            "Mpca 36 Mlda 6 Accuracy 0.5\n",
            "Mpca 36 Mlda 7 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 8 Accuracy 0.4519230769230769\n",
            "Mpca 36 Mlda 9 Accuracy 0.4807692307692308\n",
            "Mpca 36 Mlda 10 Accuracy 0.5288461538461539\n",
            "Mpca 36 Mlda 11 Accuracy 0.5384615384615384\n",
            "Mpca 36 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 36 Mlda 13 Accuracy 0.6057692307692307\n",
            "Mpca 36 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 36 Mlda 15 Accuracy 0.5673076923076923\n",
            "Mpca 36 Mlda 16 Accuracy 0.5865384615384616\n",
            "Mpca 36 Mlda 17 Accuracy 0.5961538461538461\n",
            "Mpca 36 Mlda 18 Accuracy 0.6538461538461539\n",
            "Mpca 36 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 36 Mlda 20 Accuracy 0.625\n",
            "Mpca 36 Mlda 21 Accuracy 0.5576923076923077\n",
            "Mpca 36 Mlda 22 Accuracy 0.5480769230769231\n",
            "Mpca 36 Mlda 23 Accuracy 0.5576923076923077\n",
            "Mpca 36 Mlda 24 Accuracy 0.5576923076923077\n",
            "Mpca 36 Mlda 25 Accuracy 0.5865384615384616\n",
            "Mpca 36 Mlda 26 Accuracy 0.5961538461538461\n",
            "Mpca 36 Mlda 27 Accuracy 0.5961538461538461\n",
            "Mpca 36 Mlda 28 Accuracy 0.625\n",
            "Mpca 36 Mlda 29 Accuracy 0.625\n",
            "Mpca 36 Mlda 30 Accuracy 0.625\n",
            "Mpca 36 Mlda 31 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 32 Accuracy 0.6634615384615384\n",
            "Mpca 36 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 36 Mlda 34 Accuracy 0.6057692307692307\n",
            "Mpca 36 Mlda 35 Accuracy 0.6346153846153846\n",
            "Mpca 36 Mlda 36 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 37 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 38 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 39 Accuracy 0.6442307692307693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 36 Mlda 40 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 41 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 42 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 43 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 44 Accuracy 0.6442307692307693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(36, 52 - 1) = 36 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 36 Mlda 45 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 46 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 47 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 48 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 49 Accuracy 0.6442307692307693\n",
            "Mpca 36 Mlda 50 Accuracy 0.6442307692307693\n",
            "Mpca 37 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 37 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 37 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 37 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 37 Mlda 5 Accuracy 0.5\n",
            "Mpca 37 Mlda 6 Accuracy 0.5384615384615384\n",
            "Mpca 37 Mlda 7 Accuracy 0.6634615384615384\n",
            "Mpca 37 Mlda 8 Accuracy 0.4807692307692308\n",
            "Mpca 37 Mlda 9 Accuracy 0.4807692307692308\n",
            "Mpca 37 Mlda 10 Accuracy 0.5384615384615384\n",
            "Mpca 37 Mlda 11 Accuracy 0.5673076923076923\n",
            "Mpca 37 Mlda 12 Accuracy 0.5576923076923077\n",
            "Mpca 37 Mlda 13 Accuracy 0.5865384615384616\n",
            "Mpca 37 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 37 Mlda 15 Accuracy 0.5961538461538461\n",
            "Mpca 37 Mlda 16 Accuracy 0.5673076923076923\n",
            "Mpca 37 Mlda 17 Accuracy 0.6346153846153846\n",
            "Mpca 37 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 37 Mlda 19 Accuracy 0.6346153846153846\n",
            "Mpca 37 Mlda 20 Accuracy 0.6153846153846154\n",
            "Mpca 37 Mlda 21 Accuracy 0.5865384615384616\n",
            "Mpca 37 Mlda 22 Accuracy 0.5769230769230769\n",
            "Mpca 37 Mlda 23 Accuracy 0.5673076923076923\n",
            "Mpca 37 Mlda 24 Accuracy 0.625\n",
            "Mpca 37 Mlda 25 Accuracy 0.6057692307692307\n",
            "Mpca 37 Mlda 26 Accuracy 0.6057692307692307\n",
            "Mpca 37 Mlda 27 Accuracy 0.6057692307692307\n",
            "Mpca 37 Mlda 28 Accuracy 0.6057692307692307\n",
            "Mpca 37 Mlda 29 Accuracy 0.6057692307692307\n",
            "Mpca 37 Mlda 30 Accuracy 0.625\n",
            "Mpca 37 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 37 Mlda 32 Accuracy 0.6634615384615384\n",
            "Mpca 37 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 37 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 37 Mlda 35 Accuracy 0.6442307692307693\n",
            "Mpca 37 Mlda 36 Accuracy 0.6538461538461539\n",
            "Mpca 37 Mlda 37 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 38 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 39 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 40 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 41 Accuracy 0.6730769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 37 Mlda 42 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 43 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 44 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 45 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 46 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 47 Accuracy 0.6730769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 37 Mlda 48 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 49 Accuracy 0.6730769230769231\n",
            "Mpca 37 Mlda 50 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 38 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 38 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 38 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 38 Mlda 5 Accuracy 0.5096153846153846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(37, 52 - 1) = 37 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 38 Mlda 6 Accuracy 0.5384615384615384\n",
            "Mpca 38 Mlda 7 Accuracy 0.6634615384615384\n",
            "Mpca 38 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 38 Mlda 9 Accuracy 0.5\n",
            "Mpca 38 Mlda 10 Accuracy 0.5384615384615384\n",
            "Mpca 38 Mlda 11 Accuracy 0.5673076923076923\n",
            "Mpca 38 Mlda 12 Accuracy 0.5865384615384616\n",
            "Mpca 38 Mlda 13 Accuracy 0.6057692307692307\n",
            "Mpca 38 Mlda 14 Accuracy 0.625\n",
            "Mpca 38 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 38 Mlda 16 Accuracy 0.6153846153846154\n",
            "Mpca 38 Mlda 17 Accuracy 0.6442307692307693\n",
            "Mpca 38 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 38 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 38 Mlda 20 Accuracy 0.5961538461538461\n",
            "Mpca 38 Mlda 21 Accuracy 0.5961538461538461\n",
            "Mpca 38 Mlda 22 Accuracy 0.5865384615384616\n",
            "Mpca 38 Mlda 23 Accuracy 0.5865384615384616\n",
            "Mpca 38 Mlda 24 Accuracy 0.5865384615384616\n",
            "Mpca 38 Mlda 25 Accuracy 0.6057692307692307\n",
            "Mpca 38 Mlda 26 Accuracy 0.6442307692307693\n",
            "Mpca 38 Mlda 27 Accuracy 0.6442307692307693\n",
            "Mpca 38 Mlda 28 Accuracy 0.625\n",
            "Mpca 38 Mlda 29 Accuracy 0.6057692307692307\n",
            "Mpca 38 Mlda 30 Accuracy 0.6153846153846154\n",
            "Mpca 38 Mlda 31 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 32 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 33 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 34 Accuracy 0.6634615384615384\n",
            "Mpca 38 Mlda 35 Accuracy 0.6826923076923077\n",
            "Mpca 38 Mlda 36 Accuracy 0.6442307692307693\n",
            "Mpca 38 Mlda 37 Accuracy 0.6634615384615384\n",
            "Mpca 38 Mlda 38 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 39 Accuracy 0.6730769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 38 Mlda 40 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 41 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 42 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 43 Accuracy 0.6730769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 38 Mlda 44 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 45 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 46 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 47 Accuracy 0.6730769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(38, 52 - 1) = 38 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 38 Mlda 48 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 49 Accuracy 0.6730769230769231\n",
            "Mpca 38 Mlda 50 Accuracy 0.6730769230769231\n",
            "Mpca 39 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 39 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 39 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 39 Mlda 4 Accuracy 0.375\n",
            "Mpca 39 Mlda 5 Accuracy 0.5288461538461539\n",
            "Mpca 39 Mlda 6 Accuracy 0.5673076923076923\n",
            "Mpca 39 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 39 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 39 Mlda 9 Accuracy 0.5096153846153846\n",
            "Mpca 39 Mlda 10 Accuracy 0.5576923076923077\n",
            "Mpca 39 Mlda 11 Accuracy 0.5865384615384616\n",
            "Mpca 39 Mlda 12 Accuracy 0.625\n",
            "Mpca 39 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 39 Mlda 14 Accuracy 0.6730769230769231\n",
            "Mpca 39 Mlda 15 Accuracy 0.6442307692307693\n",
            "Mpca 39 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 39 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 39 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 39 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 39 Mlda 20 Accuracy 0.625\n",
            "Mpca 39 Mlda 21 Accuracy 0.6057692307692307\n",
            "Mpca 39 Mlda 22 Accuracy 0.5865384615384616\n",
            "Mpca 39 Mlda 23 Accuracy 0.5865384615384616\n",
            "Mpca 39 Mlda 24 Accuracy 0.5865384615384616\n",
            "Mpca 39 Mlda 25 Accuracy 0.6153846153846154\n",
            "Mpca 39 Mlda 26 Accuracy 0.625\n",
            "Mpca 39 Mlda 27 Accuracy 0.6442307692307693\n",
            "Mpca 39 Mlda 28 Accuracy 0.6057692307692307\n",
            "Mpca 39 Mlda 29 Accuracy 0.625\n",
            "Mpca 39 Mlda 30 Accuracy 0.6346153846153846\n",
            "Mpca 39 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 39 Mlda 32 Accuracy 0.6826923076923077\n",
            "Mpca 39 Mlda 33 Accuracy 0.6923076923076923\n",
            "Mpca 39 Mlda 34 Accuracy 0.6538461538461539\n",
            "Mpca 39 Mlda 35 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 36 Accuracy 0.6923076923076923\n",
            "Mpca 39 Mlda 37 Accuracy 0.6538461538461539\n",
            "Mpca 39 Mlda 38 Accuracy 0.6730769230769231\n",
            "Mpca 39 Mlda 39 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 40 Accuracy 0.6634615384615384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 39 Mlda 41 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 42 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 43 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 44 Accuracy 0.6634615384615384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 39 Mlda 45 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 46 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 47 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 48 Accuracy 0.6634615384615384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 52 - 1) = 39 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 39 Mlda 49 Accuracy 0.6634615384615384\n",
            "Mpca 39 Mlda 50 Accuracy 0.6634615384615384\n",
            "Mpca 40 Mlda 1 Accuracy 0.009615384615384616\n",
            "Mpca 40 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 40 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 40 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 40 Mlda 5 Accuracy 0.5288461538461539\n",
            "Mpca 40 Mlda 6 Accuracy 0.5769230769230769\n",
            "Mpca 40 Mlda 7 Accuracy 0.6923076923076923\n",
            "Mpca 40 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 40 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 40 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 40 Mlda 11 Accuracy 0.5865384615384616\n",
            "Mpca 40 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 40 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 40 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 40 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 40 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 40 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 40 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 40 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 40 Mlda 20 Accuracy 0.6057692307692307\n",
            "Mpca 40 Mlda 21 Accuracy 0.5961538461538461\n",
            "Mpca 40 Mlda 22 Accuracy 0.5961538461538461\n",
            "Mpca 40 Mlda 23 Accuracy 0.5865384615384616\n",
            "Mpca 40 Mlda 24 Accuracy 0.5865384615384616\n",
            "Mpca 40 Mlda 25 Accuracy 0.5865384615384616\n",
            "Mpca 40 Mlda 26 Accuracy 0.6346153846153846\n",
            "Mpca 40 Mlda 27 Accuracy 0.6634615384615384\n",
            "Mpca 40 Mlda 28 Accuracy 0.6442307692307693\n",
            "Mpca 40 Mlda 29 Accuracy 0.6538461538461539\n",
            "Mpca 40 Mlda 30 Accuracy 0.6442307692307693\n",
            "Mpca 40 Mlda 31 Accuracy 0.625\n",
            "Mpca 40 Mlda 32 Accuracy 0.6730769230769231\n",
            "Mpca 40 Mlda 33 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 34 Accuracy 0.6730769230769231\n",
            "Mpca 40 Mlda 35 Accuracy 0.6634615384615384\n",
            "Mpca 40 Mlda 36 Accuracy 0.6634615384615384\n",
            "Mpca 40 Mlda 37 Accuracy 0.7019230769230769\n",
            "Mpca 40 Mlda 38 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 39 Accuracy 0.6730769230769231\n",
            "Mpca 40 Mlda 40 Accuracy 0.6826923076923077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 40 Mlda 41 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 42 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 43 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 44 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 45 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 46 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 47 Accuracy 0.6826923076923077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(40, 52 - 1) = 40 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 40 Mlda 48 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 49 Accuracy 0.6826923076923077\n",
            "Mpca 40 Mlda 50 Accuracy 0.6826923076923077\n",
            "Mpca 41 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 41 Mlda 2 Accuracy 0.125\n",
            "Mpca 41 Mlda 3 Accuracy 0.25\n",
            "Mpca 41 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 41 Mlda 5 Accuracy 0.5480769230769231\n",
            "Mpca 41 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 41 Mlda 7 Accuracy 0.6442307692307693\n",
            "Mpca 41 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 41 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 41 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 41 Mlda 11 Accuracy 0.625\n",
            "Mpca 41 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 41 Mlda 13 Accuracy 0.6538461538461539\n",
            "Mpca 41 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 41 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 41 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 41 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 41 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 41 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 41 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 41 Mlda 21 Accuracy 0.5961538461538461\n",
            "Mpca 41 Mlda 22 Accuracy 0.6057692307692307\n",
            "Mpca 41 Mlda 23 Accuracy 0.5961538461538461\n",
            "Mpca 41 Mlda 24 Accuracy 0.6057692307692307\n",
            "Mpca 41 Mlda 25 Accuracy 0.5961538461538461\n",
            "Mpca 41 Mlda 26 Accuracy 0.625\n",
            "Mpca 41 Mlda 27 Accuracy 0.6346153846153846\n",
            "Mpca 41 Mlda 28 Accuracy 0.6346153846153846\n",
            "Mpca 41 Mlda 29 Accuracy 0.6538461538461539\n",
            "Mpca 41 Mlda 30 Accuracy 0.6538461538461539\n",
            "Mpca 41 Mlda 31 Accuracy 0.625\n",
            "Mpca 41 Mlda 32 Accuracy 0.6730769230769231\n",
            "Mpca 41 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 41 Mlda 34 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 35 Accuracy 0.6826923076923077\n",
            "Mpca 41 Mlda 36 Accuracy 0.6826923076923077\n",
            "Mpca 41 Mlda 37 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 38 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 39 Accuracy 0.7019230769230769\n",
            "Mpca 41 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 41 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 42 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 43 Accuracy 0.6923076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 41 Mlda 44 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 45 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 46 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 47 Accuracy 0.6923076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 41 Mlda 48 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 49 Accuracy 0.6923076923076923\n",
            "Mpca 41 Mlda 50 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(41, 52 - 1) = 41 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 42 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 42 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 42 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 42 Mlda 5 Accuracy 0.5192307692307693\n",
            "Mpca 42 Mlda 6 Accuracy 0.6153846153846154\n",
            "Mpca 42 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 42 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 42 Mlda 9 Accuracy 0.5384615384615384\n",
            "Mpca 42 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 42 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 42 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 42 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 42 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 42 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 42 Mlda 18 Accuracy 0.7019230769230769\n",
            "Mpca 42 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 42 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 21 Accuracy 0.6442307692307693\n",
            "Mpca 42 Mlda 22 Accuracy 0.6153846153846154\n",
            "Mpca 42 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 42 Mlda 24 Accuracy 0.6153846153846154\n",
            "Mpca 42 Mlda 25 Accuracy 0.6153846153846154\n",
            "Mpca 42 Mlda 26 Accuracy 0.6442307692307693\n",
            "Mpca 42 Mlda 27 Accuracy 0.6346153846153846\n",
            "Mpca 42 Mlda 28 Accuracy 0.6442307692307693\n",
            "Mpca 42 Mlda 29 Accuracy 0.6346153846153846\n",
            "Mpca 42 Mlda 30 Accuracy 0.625\n",
            "Mpca 42 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 42 Mlda 32 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 42 Mlda 34 Accuracy 0.6634615384615384\n",
            "Mpca 42 Mlda 35 Accuracy 0.6730769230769231\n",
            "Mpca 42 Mlda 36 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 37 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 38 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 39 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 42 Mlda 41 Accuracy 0.6826923076923077\n",
            "Mpca 42 Mlda 42 Accuracy 0.7211538461538461\n",
            "Mpca 42 Mlda 43 Accuracy 0.7211538461538461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 42 Mlda 44 Accuracy 0.7211538461538461\n",
            "Mpca 42 Mlda 45 Accuracy 0.7211538461538461\n",
            "Mpca 42 Mlda 46 Accuracy 0.7211538461538461\n",
            "Mpca 42 Mlda 47 Accuracy 0.7211538461538461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(42, 52 - 1) = 42 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 42 Mlda 48 Accuracy 0.7211538461538461\n",
            "Mpca 42 Mlda 49 Accuracy 0.7211538461538461\n",
            "Mpca 42 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 43 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 43 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 43 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 43 Mlda 4 Accuracy 0.41346153846153844\n",
            "Mpca 43 Mlda 5 Accuracy 0.5096153846153846\n",
            "Mpca 43 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 43 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 43 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 43 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 43 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 43 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 43 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 43 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 43 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 43 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 43 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 43 Mlda 17 Accuracy 0.7019230769230769\n",
            "Mpca 43 Mlda 18 Accuracy 0.6923076923076923\n",
            "Mpca 43 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 43 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 43 Mlda 21 Accuracy 0.6442307692307693\n",
            "Mpca 43 Mlda 22 Accuracy 0.6634615384615384\n",
            "Mpca 43 Mlda 23 Accuracy 0.6442307692307693\n",
            "Mpca 43 Mlda 24 Accuracy 0.6730769230769231\n",
            "Mpca 43 Mlda 25 Accuracy 0.6730769230769231\n",
            "Mpca 43 Mlda 26 Accuracy 0.6442307692307693\n",
            "Mpca 43 Mlda 27 Accuracy 0.625\n",
            "Mpca 43 Mlda 28 Accuracy 0.6346153846153846\n",
            "Mpca 43 Mlda 29 Accuracy 0.6442307692307693\n",
            "Mpca 43 Mlda 30 Accuracy 0.6634615384615384\n",
            "Mpca 43 Mlda 31 Accuracy 0.6923076923076923\n",
            "Mpca 43 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 43 Mlda 33 Accuracy 0.7115384615384616\n",
            "Mpca 43 Mlda 34 Accuracy 0.6923076923076923\n",
            "Mpca 43 Mlda 35 Accuracy 0.6923076923076923\n",
            "Mpca 43 Mlda 36 Accuracy 0.6730769230769231\n",
            "Mpca 43 Mlda 37 Accuracy 0.6730769230769231\n",
            "Mpca 43 Mlda 38 Accuracy 0.6634615384615384\n",
            "Mpca 43 Mlda 39 Accuracy 0.6730769230769231\n",
            "Mpca 43 Mlda 40 Accuracy 0.6826923076923077\n",
            "Mpca 43 Mlda 41 Accuracy 0.6923076923076923\n",
            "Mpca 43 Mlda 42 Accuracy 0.6923076923076923\n",
            "Mpca 43 Mlda 43 Accuracy 0.7115384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(43, 52 - 1) = 43 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(43, 52 - 1) = 43 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(43, 52 - 1) = 43 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(43, 52 - 1) = 43 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(43, 52 - 1) = 43 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 43 Mlda 44 Accuracy 0.7115384615384616\n",
            "Mpca 43 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 43 Mlda 46 Accuracy 0.7115384615384616\n",
            "Mpca 43 Mlda 47 Accuracy 0.7115384615384616\n",
            "Mpca 43 Mlda 48 Accuracy 0.7115384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(43, 52 - 1) = 43 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(43, 52 - 1) = 43 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 43 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 43 Mlda 50 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 44 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 44 Mlda 3 Accuracy 0.25\n",
            "Mpca 44 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 44 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 44 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 44 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 44 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 44 Mlda 9 Accuracy 0.5384615384615384\n",
            "Mpca 44 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 44 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 44 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 44 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 44 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 44 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 44 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 44 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 44 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 44 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 44 Mlda 21 Accuracy 0.6923076923076923\n",
            "Mpca 44 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 44 Mlda 23 Accuracy 0.6442307692307693\n",
            "Mpca 44 Mlda 24 Accuracy 0.6442307692307693\n",
            "Mpca 44 Mlda 25 Accuracy 0.6634615384615384\n",
            "Mpca 44 Mlda 26 Accuracy 0.6538461538461539\n",
            "Mpca 44 Mlda 27 Accuracy 0.6634615384615384\n",
            "Mpca 44 Mlda 28 Accuracy 0.6634615384615384\n",
            "Mpca 44 Mlda 29 Accuracy 0.6826923076923077\n",
            "Mpca 44 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 44 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 44 Mlda 33 Accuracy 0.75\n",
            "Mpca 44 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 44 Mlda 35 Accuracy 0.6730769230769231\n",
            "Mpca 44 Mlda 36 Accuracy 0.7019230769230769\n",
            "Mpca 44 Mlda 37 Accuracy 0.6730769230769231\n",
            "Mpca 44 Mlda 38 Accuracy 0.7019230769230769\n",
            "Mpca 44 Mlda 39 Accuracy 0.6826923076923077\n",
            "Mpca 44 Mlda 40 Accuracy 0.7019230769230769\n",
            "Mpca 44 Mlda 41 Accuracy 0.6826923076923077\n",
            "Mpca 44 Mlda 42 Accuracy 0.6730769230769231\n",
            "Mpca 44 Mlda 43 Accuracy 0.6730769230769231\n",
            "Mpca 44 Mlda 44 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 46 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 47 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 48 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 44 Mlda 50 Accuracy 0.7115384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(44, 52 - 1) = 44 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(44, 52 - 1) = 44 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(44, 52 - 1) = 44 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(44, 52 - 1) = 44 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(44, 52 - 1) = 44 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(44, 52 - 1) = 44 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 45 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 45 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 45 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 45 Mlda 4 Accuracy 0.375\n",
            "Mpca 45 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 45 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 45 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 45 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 45 Mlda 9 Accuracy 0.5288461538461539\n",
            "Mpca 45 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 45 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 45 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 45 Mlda 13 Accuracy 0.6538461538461539\n",
            "Mpca 45 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 45 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 45 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 45 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 45 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 45 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 45 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 45 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 45 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 45 Mlda 23 Accuracy 0.6153846153846154\n",
            "Mpca 45 Mlda 24 Accuracy 0.6442307692307693\n",
            "Mpca 45 Mlda 25 Accuracy 0.6634615384615384\n",
            "Mpca 45 Mlda 26 Accuracy 0.6442307692307693\n",
            "Mpca 45 Mlda 27 Accuracy 0.6634615384615384\n",
            "Mpca 45 Mlda 28 Accuracy 0.6634615384615384\n",
            "Mpca 45 Mlda 29 Accuracy 0.6923076923076923\n",
            "Mpca 45 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 45 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 45 Mlda 32 Accuracy 0.75\n",
            "Mpca 45 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 45 Mlda 34 Accuracy 0.7115384615384616\n",
            "Mpca 45 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 45 Mlda 36 Accuracy 0.6730769230769231\n",
            "Mpca 45 Mlda 37 Accuracy 0.6826923076923077\n",
            "Mpca 45 Mlda 38 Accuracy 0.6826923076923077\n",
            "Mpca 45 Mlda 39 Accuracy 0.6634615384615384\n",
            "Mpca 45 Mlda 40 Accuracy 0.6538461538461539\n",
            "Mpca 45 Mlda 41 Accuracy 0.6826923076923077\n",
            "Mpca 45 Mlda 42 Accuracy 0.6826923076923077\n",
            "Mpca 45 Mlda 43 Accuracy 0.6730769230769231\n",
            "Mpca 45 Mlda 44 Accuracy 0.6730769230769231\n",
            "Mpca 45 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 45 Mlda 46 Accuracy 0.7115384615384616\n",
            "Mpca 45 Mlda 47 Accuracy 0.7115384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(45, 52 - 1) = 45 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(45, 52 - 1) = 45 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(45, 52 - 1) = 45 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(45, 52 - 1) = 45 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 45 Mlda 48 Accuracy 0.7115384615384616\n",
            "Mpca 45 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 45 Mlda 50 Accuracy 0.7115384615384616\n",
            "Mpca 46 Mlda 1 Accuracy 0.009615384615384616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(45, 52 - 1) = 45 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 46 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 46 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 46 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 46 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 46 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 46 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 46 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 46 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 46 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 46 Mlda 11 Accuracy 0.625\n",
            "Mpca 46 Mlda 12 Accuracy 0.6057692307692307\n",
            "Mpca 46 Mlda 13 Accuracy 0.6442307692307693\n",
            "Mpca 46 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 46 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 46 Mlda 16 Accuracy 0.75\n",
            "Mpca 46 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 46 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 46 Mlda 19 Accuracy 0.75\n",
            "Mpca 46 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 46 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 46 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 46 Mlda 23 Accuracy 0.6730769230769231\n",
            "Mpca 46 Mlda 24 Accuracy 0.7019230769230769\n",
            "Mpca 46 Mlda 25 Accuracy 0.7307692307692307\n",
            "Mpca 46 Mlda 26 Accuracy 0.6923076923076923\n",
            "Mpca 46 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 46 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 46 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 46 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 46 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 46 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 46 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 46 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 46 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 46 Mlda 36 Accuracy 0.6826923076923077\n",
            "Mpca 46 Mlda 37 Accuracy 0.6923076923076923\n",
            "Mpca 46 Mlda 38 Accuracy 0.7019230769230769\n",
            "Mpca 46 Mlda 39 Accuracy 0.7019230769230769\n",
            "Mpca 46 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 46 Mlda 41 Accuracy 0.6923076923076923\n",
            "Mpca 46 Mlda 42 Accuracy 0.7115384615384616\n",
            "Mpca 46 Mlda 43 Accuracy 0.7019230769230769\n",
            "Mpca 46 Mlda 44 Accuracy 0.7211538461538461\n",
            "Mpca 46 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 46 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 46 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 46 Mlda 48 Accuracy 0.7403846153846154\n",
            "Mpca 46 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 46 Mlda 50 Accuracy 0.7403846153846154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(46, 52 - 1) = 46 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(46, 52 - 1) = 46 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(46, 52 - 1) = 46 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(46, 52 - 1) = 46 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 47 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 47 Mlda 2 Accuracy 0.125\n",
            "Mpca 47 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 47 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 47 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 47 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 47 Mlda 7 Accuracy 0.5\n",
            "Mpca 47 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 47 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 47 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 47 Mlda 11 Accuracy 0.625\n",
            "Mpca 47 Mlda 12 Accuracy 0.625\n",
            "Mpca 47 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 47 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 47 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 47 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 47 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 47 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 47 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 47 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 21 Accuracy 0.75\n",
            "Mpca 47 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 47 Mlda 24 Accuracy 0.7019230769230769\n",
            "Mpca 47 Mlda 25 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 26 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 27 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 28 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 47 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 47 Mlda 32 Accuracy 0.6923076923076923\n",
            "Mpca 47 Mlda 33 Accuracy 0.6923076923076923\n",
            "Mpca 47 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 47 Mlda 35 Accuracy 0.6923076923076923\n",
            "Mpca 47 Mlda 36 Accuracy 0.6826923076923077\n",
            "Mpca 47 Mlda 37 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 47 Mlda 39 Accuracy 0.7211538461538461\n",
            "Mpca 47 Mlda 40 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 41 Accuracy 0.75\n",
            "Mpca 47 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 47 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 47 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 47 Mlda 45 Accuracy 0.7403846153846154\n",
            "Mpca 47 Mlda 46 Accuracy 0.7211538461538461\n",
            "Mpca 47 Mlda 47 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 47"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(47, 52 - 1) = 47 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(47, 52 - 1) = 47 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(47, 52 - 1) = 47 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Mlda 49 Accuracy 0.7307692307692307\n",
            "Mpca 47 Mlda 50 Accuracy 0.7307692307692307\n",
            "Mpca 48 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 48 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 48 Mlda 3 Accuracy 0.16346153846153846\n",
            "Mpca 48 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 48 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 48 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 48 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 48 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 48 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 48 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 48 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 48 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 48 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 48 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 48 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 48 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 48 Mlda 17 Accuracy 0.75\n",
            "Mpca 48 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 48 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 48 Mlda 20 Accuracy 0.75\n",
            "Mpca 48 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 48 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 48 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 48 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 48 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 48 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 48 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 48 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 48 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 48 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 48 Mlda 31 Accuracy 0.7019230769230769\n",
            "Mpca 48 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 48 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 48 Mlda 34 Accuracy 0.7115384615384616\n",
            "Mpca 48 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 48 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 48 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 48 Mlda 38 Accuracy 0.7307692307692307\n",
            "Mpca 48 Mlda 39 Accuracy 0.7211538461538461\n",
            "Mpca 48 Mlda 40 Accuracy 0.7403846153846154\n",
            "Mpca 48 Mlda 41 Accuracy 0.7403846153846154\n",
            "Mpca 48 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 48 Mlda 43 Accuracy 0.75\n",
            "Mpca 48 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 48 Mlda 45 Accuracy 0.7211538461538461\n",
            "Mpca 48 Mlda 46 Accuracy 0.75\n",
            "Mpca 48 Mlda 47 Accuracy 0.7211538461538461\n",
            "Mpca 48 Mlda 48 Accuracy 0.7019230769230769\n",
            "Mpca 48 Mlda 49 Accuracy 0.7019230769230769\n",
            "Mpca 48 Mlda 50 Accuracy 0.7019230769230769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(48, 52 - 1) = 48 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(48, 52 - 1) = 48 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 49 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 49 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 49 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 49 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 49 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 49 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 49 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 49 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 49 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 49 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 49 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 49 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 49 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 49 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 49 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 49 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 49 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 49 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 49 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 49 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 49 Mlda 21 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 49 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 49 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 49 Mlda 30 Accuracy 0.7019230769230769\n",
            "Mpca 49 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 49 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 49 Mlda 33 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 49 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 49 Mlda 36 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 37 Accuracy 0.7019230769230769\n",
            "Mpca 49 Mlda 38 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 39 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 41 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 42 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 43 Accuracy 0.7211538461538461\n",
            "Mpca 49 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 49 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 49 Mlda 46 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 47 Accuracy 0.6923076923076923\n",
            "Mpca 49 Mlda 48 Accuracy 0.7019230769230769\n",
            "Mpca 49 Mlda 49 Accuracy 0.7019230769230769\n",
            "Mpca 49 Mlda 50 Accuracy 0.7019230769230769\n",
            "Mpca 50 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 50 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 50 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 50 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 50 Mlda 5 Accuracy 0.4230769230769231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(49, 52 - 1) = 49 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mpca 50 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 50 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 50 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 50 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 50 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 50 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 50 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 50 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 50 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 50 Mlda 16 Accuracy 0.75\n",
            "Mpca 50 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 50 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 50 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 50 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 50 Mlda 21 Accuracy 0.6538461538461539\n",
            "Mpca 50 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 50 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 50 Mlda 24 Accuracy 0.7115384615384616\n",
            "Mpca 50 Mlda 25 Accuracy 0.7307692307692307\n",
            "Mpca 50 Mlda 26 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 27 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 28 Accuracy 0.7403846153846154\n",
            "Mpca 50 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 50 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 50 Mlda 32 Accuracy 0.75\n",
            "Mpca 50 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 50 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 37 Accuracy 0.7115384615384616\n",
            "Mpca 50 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 50 Mlda 39 Accuracy 0.7403846153846154\n",
            "Mpca 50 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 50 Mlda 41 Accuracy 0.7115384615384616\n",
            "Mpca 50 Mlda 42 Accuracy 0.7211538461538461\n",
            "Mpca 50 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 50 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 50 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 50 Mlda 46 Accuracy 0.75\n",
            "Mpca 50 Mlda 47 Accuracy 0.7115384615384616\n",
            "Mpca 50 Mlda 48 Accuracy 0.7019230769230769\n",
            "Mpca 50 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 50 Mlda 50 Accuracy 0.7115384615384616\n",
            "Mpca 51 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 51 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 51 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 51 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 51 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 51 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 51 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 51 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 51 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 51 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 51 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 51 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 51 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 51 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 51 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 51 Mlda 16 Accuracy 0.75\n",
            "Mpca 51 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 51 Mlda 18 Accuracy 0.75\n",
            "Mpca 51 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 51 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 51 Mlda 21 Accuracy 0.6538461538461539\n",
            "Mpca 51 Mlda 22 Accuracy 0.6730769230769231\n",
            "Mpca 51 Mlda 23 Accuracy 0.6730769230769231\n",
            "Mpca 51 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 51 Mlda 25 Accuracy 0.7115384615384616\n",
            "Mpca 51 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 51 Mlda 27 Accuracy 0.7115384615384616\n",
            "Mpca 51 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 51 Mlda 29 Accuracy 0.75\n",
            "Mpca 51 Mlda 30 Accuracy 0.7403846153846154\n",
            "Mpca 51 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 51 Mlda 32 Accuracy 0.75\n",
            "Mpca 51 Mlda 33 Accuracy 0.7115384615384616\n",
            "Mpca 51 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 51 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 51 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 51 Mlda 37 Accuracy 0.7019230769230769\n",
            "Mpca 51 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 51 Mlda 39 Accuracy 0.7211538461538461\n",
            "Mpca 51 Mlda 40 Accuracy 0.7211538461538461\n",
            "Mpca 51 Mlda 41 Accuracy 0.7115384615384616\n",
            "Mpca 51 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 51 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 51 Mlda 44 Accuracy 0.75\n",
            "Mpca 51 Mlda 45 Accuracy 0.75\n",
            "Mpca 51 Mlda 46 Accuracy 0.7596153846153846\n",
            "Mpca 51 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 51 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 51 Mlda 49 Accuracy 0.7307692307692307\n",
            "Mpca 51 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 52 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 52 Mlda 2 Accuracy 0.057692307692307696\n",
            "Mpca 52 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 52 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 52 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 52 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 52 Mlda 7 Accuracy 0.4519230769230769\n",
            "Mpca 52 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 52 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 52 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 52 Mlda 11 Accuracy 0.6057692307692307\n",
            "Mpca 52 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 52 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 52 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 52 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 52 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 52 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 52 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 52 Mlda 19 Accuracy 0.75\n",
            "Mpca 52 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 52 Mlda 21 Accuracy 0.6730769230769231\n",
            "Mpca 52 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 52 Mlda 23 Accuracy 0.7019230769230769\n",
            "Mpca 52 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 52 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 52 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 52 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 52 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 52 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 52 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 52 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 52 Mlda 32 Accuracy 0.7692307692307693\n",
            "Mpca 52 Mlda 33 Accuracy 0.75\n",
            "Mpca 52 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 52 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 52 Mlda 36 Accuracy 0.75\n",
            "Mpca 52 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 52 Mlda 38 Accuracy 0.7019230769230769\n",
            "Mpca 52 Mlda 39 Accuracy 0.7019230769230769\n",
            "Mpca 52 Mlda 40 Accuracy 0.7115384615384616\n",
            "Mpca 52 Mlda 41 Accuracy 0.6923076923076923\n",
            "Mpca 52 Mlda 42 Accuracy 0.7115384615384616\n",
            "Mpca 52 Mlda 43 Accuracy 0.7115384615384616\n",
            "Mpca 52 Mlda 44 Accuracy 0.75\n",
            "Mpca 52 Mlda 45 Accuracy 0.7596153846153846\n",
            "Mpca 52 Mlda 46 Accuracy 0.7596153846153846\n",
            "Mpca 52 Mlda 47 Accuracy 0.7211538461538461\n",
            "Mpca 52 Mlda 48 Accuracy 0.7115384615384616\n",
            "Mpca 52 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 52 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 53 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 53 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 53 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 53 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 53 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 53 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 53 Mlda 7 Accuracy 0.5\n",
            "Mpca 53 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 53 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 53 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 53 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 53 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 53 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 53 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 53 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 53 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 53 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 53 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 53 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 53 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 53 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 53 Mlda 22 Accuracy 0.6826923076923077\n",
            "Mpca 53 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 53 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 53 Mlda 25 Accuracy 0.75\n",
            "Mpca 53 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 53 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 53 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 53 Mlda 29 Accuracy 0.7403846153846154\n",
            "Mpca 53 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 53 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 53 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 53 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 53 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 53 Mlda 35 Accuracy 0.75\n",
            "Mpca 53 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 53 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 53 Mlda 38 Accuracy 0.75\n",
            "Mpca 53 Mlda 39 Accuracy 0.7403846153846154\n",
            "Mpca 53 Mlda 40 Accuracy 0.7115384615384616\n",
            "Mpca 53 Mlda 41 Accuracy 0.7115384615384616\n",
            "Mpca 53 Mlda 42 Accuracy 0.7019230769230769\n",
            "Mpca 53 Mlda 43 Accuracy 0.7115384615384616\n",
            "Mpca 53 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 53 Mlda 45 Accuracy 0.75\n",
            "Mpca 53 Mlda 46 Accuracy 0.75\n",
            "Mpca 53 Mlda 47 Accuracy 0.75\n",
            "Mpca 53 Mlda 48 Accuracy 0.7019230769230769\n",
            "Mpca 53 Mlda 49 Accuracy 0.7019230769230769\n",
            "Mpca 53 Mlda 50 Accuracy 0.7019230769230769\n",
            "Mpca 54 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 54 Mlda 2 Accuracy 0.125\n",
            "Mpca 54 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 54 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 54 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 54 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 54 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 54 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 54 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 54 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 54 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 54 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 54 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 54 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 54 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 54 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 54 Mlda 17 Accuracy 0.75\n",
            "Mpca 54 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 54 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 54 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 54 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 54 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 54 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 54 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 54 Mlda 25 Accuracy 0.7211538461538461\n",
            "Mpca 54 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 54 Mlda 27 Accuracy 0.75\n",
            "Mpca 54 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 54 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 54 Mlda 30 Accuracy 0.7596153846153846\n",
            "Mpca 54 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 54 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 54 Mlda 33 Accuracy 0.7692307692307693\n",
            "Mpca 54 Mlda 34 Accuracy 0.75\n",
            "Mpca 54 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 54 Mlda 36 Accuracy 0.7403846153846154\n",
            "Mpca 54 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 54 Mlda 38 Accuracy 0.7307692307692307\n",
            "Mpca 54 Mlda 39 Accuracy 0.7307692307692307\n",
            "Mpca 54 Mlda 40 Accuracy 0.75\n",
            "Mpca 54 Mlda 41 Accuracy 0.7403846153846154\n",
            "Mpca 54 Mlda 42 Accuracy 0.75\n",
            "Mpca 54 Mlda 43 Accuracy 0.75\n",
            "Mpca 54 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 54 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 54 Mlda 46 Accuracy 0.75\n",
            "Mpca 54 Mlda 47 Accuracy 0.7596153846153846\n",
            "Mpca 54 Mlda 48 Accuracy 0.7403846153846154\n",
            "Mpca 54 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 54 Mlda 50 Accuracy 0.7307692307692307\n",
            "Mpca 55 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 55 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 55 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 55 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 55 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 55 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 55 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 55 Mlda 8 Accuracy 0.47115384615384615\n",
            "Mpca 55 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 55 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 55 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 55 Mlda 12 Accuracy 0.5961538461538461\n",
            "Mpca 55 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 55 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 55 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 55 Mlda 16 Accuracy 0.6826923076923077\n",
            "Mpca 55 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 55 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 55 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 55 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 55 Mlda 22 Accuracy 0.75\n",
            "Mpca 55 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 24 Accuracy 0.7115384615384616\n",
            "Mpca 55 Mlda 25 Accuracy 0.7115384615384616\n",
            "Mpca 55 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 55 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 55 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 55 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 55 Mlda 30 Accuracy 0.75\n",
            "Mpca 55 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 55 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 55 Mlda 33 Accuracy 0.75\n",
            "Mpca 55 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 55 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 55 Mlda 36 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 39 Accuracy 0.75\n",
            "Mpca 55 Mlda 40 Accuracy 0.75\n",
            "Mpca 55 Mlda 41 Accuracy 0.75\n",
            "Mpca 55 Mlda 42 Accuracy 0.75\n",
            "Mpca 55 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 55 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 55 Mlda 45 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 55 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 55 Mlda 49 Accuracy 0.7019230769230769\n",
            "Mpca 55 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 56 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 56 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 56 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 56 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 56 Mlda 5 Accuracy 0.49038461538461536\n",
            "Mpca 56 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 56 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 56 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 56 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 56 Mlda 10 Accuracy 0.5384615384615384\n",
            "Mpca 56 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 56 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 56 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 56 Mlda 14 Accuracy 0.6442307692307693\n",
            "Mpca 56 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 56 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 56 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 56 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 56 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 56 Mlda 20 Accuracy 0.7019230769230769\n",
            "Mpca 56 Mlda 21 Accuracy 0.7115384615384616\n",
            "Mpca 56 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 56 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 56 Mlda 24 Accuracy 0.7307692307692307\n",
            "Mpca 56 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 56 Mlda 26 Accuracy 0.75\n",
            "Mpca 56 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 56 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 56 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 56 Mlda 30 Accuracy 0.7211538461538461\n",
            "Mpca 56 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 56 Mlda 32 Accuracy 0.7403846153846154\n",
            "Mpca 56 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 56 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 56 Mlda 35 Accuracy 0.75\n",
            "Mpca 56 Mlda 36 Accuracy 0.75\n",
            "Mpca 56 Mlda 37 Accuracy 0.75\n",
            "Mpca 56 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 56 Mlda 39 Accuracy 0.75\n",
            "Mpca 56 Mlda 40 Accuracy 0.7403846153846154\n",
            "Mpca 56 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 56 Mlda 42 Accuracy 0.7211538461538461\n",
            "Mpca 56 Mlda 43 Accuracy 0.75\n",
            "Mpca 56 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 56 Mlda 45 Accuracy 0.75\n",
            "Mpca 56 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 56 Mlda 47 Accuracy 0.7211538461538461\n",
            "Mpca 56 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 56 Mlda 49 Accuracy 0.7211538461538461\n",
            "Mpca 56 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 57 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 57 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 57 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 57 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 57 Mlda 5 Accuracy 0.5\n",
            "Mpca 57 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 57 Mlda 7 Accuracy 0.5\n",
            "Mpca 57 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 57 Mlda 9 Accuracy 0.5096153846153846\n",
            "Mpca 57 Mlda 10 Accuracy 0.5384615384615384\n",
            "Mpca 57 Mlda 11 Accuracy 0.625\n",
            "Mpca 57 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 57 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 57 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 57 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 57 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 57 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 57 Mlda 21 Accuracy 0.7019230769230769\n",
            "Mpca 57 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 57 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 57 Mlda 24 Accuracy 0.7115384615384616\n",
            "Mpca 57 Mlda 25 Accuracy 0.75\n",
            "Mpca 57 Mlda 26 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 57 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 57 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 57 Mlda 30 Accuracy 0.7596153846153846\n",
            "Mpca 57 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 57 Mlda 33 Accuracy 0.75\n",
            "Mpca 57 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 57 Mlda 35 Accuracy 0.75\n",
            "Mpca 57 Mlda 36 Accuracy 0.75\n",
            "Mpca 57 Mlda 37 Accuracy 0.75\n",
            "Mpca 57 Mlda 38 Accuracy 0.7596153846153846\n",
            "Mpca 57 Mlda 39 Accuracy 0.7403846153846154\n",
            "Mpca 57 Mlda 40 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 41 Accuracy 0.7211538461538461\n",
            "Mpca 57 Mlda 42 Accuracy 0.7115384615384616\n",
            "Mpca 57 Mlda 43 Accuracy 0.75\n",
            "Mpca 57 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 45 Accuracy 0.7403846153846154\n",
            "Mpca 57 Mlda 46 Accuracy 0.75\n",
            "Mpca 57 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 57 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 57 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 57 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 58 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 58 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 58 Mlda 3 Accuracy 0.25\n",
            "Mpca 58 Mlda 4 Accuracy 0.375\n",
            "Mpca 58 Mlda 5 Accuracy 0.5096153846153846\n",
            "Mpca 58 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 58 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 58 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 58 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 58 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 58 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 58 Mlda 12 Accuracy 0.625\n",
            "Mpca 58 Mlda 13 Accuracy 0.6538461538461539\n",
            "Mpca 58 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 58 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 58 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 58 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 58 Mlda 18 Accuracy 0.7019230769230769\n",
            "Mpca 58 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 58 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 58 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 58 Mlda 22 Accuracy 0.75\n",
            "Mpca 58 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 58 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 58 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 58 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 58 Mlda 27 Accuracy 0.7403846153846154\n",
            "Mpca 58 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 58 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 58 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 58 Mlda 31 Accuracy 0.75\n",
            "Mpca 58 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 58 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 58 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 58 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 58 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 58 Mlda 37 Accuracy 0.75\n",
            "Mpca 58 Mlda 38 Accuracy 0.7692307692307693\n",
            "Mpca 58 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 58 Mlda 40 Accuracy 0.75\n",
            "Mpca 58 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 58 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 58 Mlda 43 Accuracy 0.7307692307692307\n",
            "Mpca 58 Mlda 44 Accuracy 0.7211538461538461\n",
            "Mpca 58 Mlda 45 Accuracy 0.7403846153846154\n",
            "Mpca 58 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 58 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 58 Mlda 48 Accuracy 0.7211538461538461\n",
            "Mpca 58 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 58 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 59 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 59 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 59 Mlda 3 Accuracy 0.25\n",
            "Mpca 59 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 59 Mlda 5 Accuracy 0.47115384615384615\n",
            "Mpca 59 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 59 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 59 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 59 Mlda 9 Accuracy 0.625\n",
            "Mpca 59 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 59 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 59 Mlda 12 Accuracy 0.6153846153846154\n",
            "Mpca 59 Mlda 13 Accuracy 0.6442307692307693\n",
            "Mpca 59 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 59 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 59 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 59 Mlda 17 Accuracy 0.7019230769230769\n",
            "Mpca 59 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 59 Mlda 19 Accuracy 0.75\n",
            "Mpca 59 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 59 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 59 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 59 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 59 Mlda 24 Accuracy 0.75\n",
            "Mpca 59 Mlda 25 Accuracy 0.75\n",
            "Mpca 59 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 59 Mlda 27 Accuracy 0.7307692307692307\n",
            "Mpca 59 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 59 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 59 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 59 Mlda 31 Accuracy 0.7596153846153846\n",
            "Mpca 59 Mlda 32 Accuracy 0.7692307692307693\n",
            "Mpca 59 Mlda 33 Accuracy 0.7692307692307693\n",
            "Mpca 59 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 59 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 59 Mlda 36 Accuracy 0.7788461538461539\n",
            "Mpca 59 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 59 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 59 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 59 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 59 Mlda 41 Accuracy 0.7788461538461539\n",
            "Mpca 59 Mlda 42 Accuracy 0.7211538461538461\n",
            "Mpca 59 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 59 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 59 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 59 Mlda 46 Accuracy 0.7307692307692307\n",
            "Mpca 59 Mlda 47 Accuracy 0.7307692307692307\n",
            "Mpca 59 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 59 Mlda 49 Accuracy 0.7307692307692307\n",
            "Mpca 59 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 60 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 60 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 60 Mlda 3 Accuracy 0.25\n",
            "Mpca 60 Mlda 4 Accuracy 0.375\n",
            "Mpca 60 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 60 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 60 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 60 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 60 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 60 Mlda 10 Accuracy 0.5576923076923077\n",
            "Mpca 60 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 60 Mlda 12 Accuracy 0.625\n",
            "Mpca 60 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 60 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 60 Mlda 15 Accuracy 0.6730769230769231\n",
            "Mpca 60 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 60 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 60 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 60 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 60 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 60 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 60 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 60 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 60 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 60 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 60 Mlda 26 Accuracy 0.75\n",
            "Mpca 60 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 60 Mlda 28 Accuracy 0.7403846153846154\n",
            "Mpca 60 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 60 Mlda 30 Accuracy 0.75\n",
            "Mpca 60 Mlda 31 Accuracy 0.7596153846153846\n",
            "Mpca 60 Mlda 32 Accuracy 0.7692307692307693\n",
            "Mpca 60 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 60 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 60 Mlda 35 Accuracy 0.7692307692307693\n",
            "Mpca 60 Mlda 36 Accuracy 0.7788461538461539\n",
            "Mpca 60 Mlda 37 Accuracy 0.75\n",
            "Mpca 60 Mlda 38 Accuracy 0.7596153846153846\n",
            "Mpca 60 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 60 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 60 Mlda 41 Accuracy 0.75\n",
            "Mpca 60 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 60 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 60 Mlda 44 Accuracy 0.7211538461538461\n",
            "Mpca 60 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 60 Mlda 46 Accuracy 0.7307692307692307\n",
            "Mpca 60 Mlda 47 Accuracy 0.75\n",
            "Mpca 60 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 60 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 60 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 61 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 61 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 61 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 61 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 61 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 61 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 61 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 61 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 61 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 61 Mlda 10 Accuracy 0.5673076923076923\n",
            "Mpca 61 Mlda 11 Accuracy 0.625\n",
            "Mpca 61 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 61 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 61 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 61 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 61 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 61 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 61 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 61 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 61 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 61 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 61 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 61 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 61 Mlda 24 Accuracy 0.75\n",
            "Mpca 61 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 61 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 61 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 61 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 61 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 61 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 61 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 61 Mlda 32 Accuracy 0.7788461538461539\n",
            "Mpca 61 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 61 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 61 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 61 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 61 Mlda 37 Accuracy 0.7692307692307693\n",
            "Mpca 61 Mlda 38 Accuracy 0.7596153846153846\n",
            "Mpca 61 Mlda 39 Accuracy 0.75\n",
            "Mpca 61 Mlda 40 Accuracy 0.7692307692307693\n",
            "Mpca 61 Mlda 41 Accuracy 0.7788461538461539\n",
            "Mpca 61 Mlda 42 Accuracy 0.75\n",
            "Mpca 61 Mlda 43 Accuracy 0.75\n",
            "Mpca 61 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 61 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 61 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 61 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 61 Mlda 48 Accuracy 0.7403846153846154\n",
            "Mpca 61 Mlda 49 Accuracy 0.75\n",
            "Mpca 61 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 62 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 62 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 62 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 62 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 62 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 62 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 62 Mlda 7 Accuracy 0.5\n",
            "Mpca 62 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 62 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 62 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 62 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 62 Mlda 12 Accuracy 0.625\n",
            "Mpca 62 Mlda 13 Accuracy 0.625\n",
            "Mpca 62 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 62 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 62 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 62 Mlda 17 Accuracy 0.6923076923076923\n",
            "Mpca 62 Mlda 18 Accuracy 0.7019230769230769\n",
            "Mpca 62 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 62 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 62 Mlda 21 Accuracy 0.75\n",
            "Mpca 62 Mlda 22 Accuracy 0.75\n",
            "Mpca 62 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 62 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 62 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 62 Mlda 26 Accuracy 0.75\n",
            "Mpca 62 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 62 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 62 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 62 Mlda 30 Accuracy 0.7596153846153846\n",
            "Mpca 62 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 62 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 62 Mlda 33 Accuracy 0.7596153846153846\n",
            "Mpca 62 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 62 Mlda 35 Accuracy 0.7692307692307693\n",
            "Mpca 62 Mlda 36 Accuracy 0.7788461538461539\n",
            "Mpca 62 Mlda 37 Accuracy 0.7692307692307693\n",
            "Mpca 62 Mlda 38 Accuracy 0.75\n",
            "Mpca 62 Mlda 39 Accuracy 0.75\n",
            "Mpca 62 Mlda 40 Accuracy 0.75\n",
            "Mpca 62 Mlda 41 Accuracy 0.75\n",
            "Mpca 62 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 62 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 62 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 62 Mlda 45 Accuracy 0.7211538461538461\n",
            "Mpca 62 Mlda 46 Accuracy 0.7115384615384616\n",
            "Mpca 62 Mlda 47 Accuracy 0.7211538461538461\n",
            "Mpca 62 Mlda 48 Accuracy 0.7211538461538461\n",
            "Mpca 62 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 62 Mlda 50 Accuracy 0.7307692307692307\n",
            "Mpca 63 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 63 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 63 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 63 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 63 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 63 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 63 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 63 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 63 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 63 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 63 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 63 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 63 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 63 Mlda 14 Accuracy 0.6346153846153846\n",
            "Mpca 63 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 63 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 63 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 63 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 63 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 63 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 63 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 63 Mlda 25 Accuracy 0.75\n",
            "Mpca 63 Mlda 26 Accuracy 0.75\n",
            "Mpca 63 Mlda 27 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 28 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 29 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 30 Accuracy 0.75\n",
            "Mpca 63 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 63 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 63 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 63 Mlda 35 Accuracy 0.7692307692307693\n",
            "Mpca 63 Mlda 36 Accuracy 0.7692307692307693\n",
            "Mpca 63 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 63 Mlda 38 Accuracy 0.7307692307692307\n",
            "Mpca 63 Mlda 39 Accuracy 0.75\n",
            "Mpca 63 Mlda 40 Accuracy 0.7596153846153846\n",
            "Mpca 63 Mlda 41 Accuracy 0.75\n",
            "Mpca 63 Mlda 42 Accuracy 0.75\n",
            "Mpca 63 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 63 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 63 Mlda 45 Accuracy 0.7211538461538461\n",
            "Mpca 63 Mlda 46 Accuracy 0.7211538461538461\n",
            "Mpca 63 Mlda 47 Accuracy 0.7019230769230769\n",
            "Mpca 63 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 63 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 63 Mlda 50 Accuracy 0.7307692307692307\n",
            "Mpca 64 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 64 Mlda 2 Accuracy 0.125\n",
            "Mpca 64 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 64 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 64 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 64 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 64 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 64 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 64 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 64 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 64 Mlda 11 Accuracy 0.625\n",
            "Mpca 64 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 64 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 64 Mlda 14 Accuracy 0.6442307692307693\n",
            "Mpca 64 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 64 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 64 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 64 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 64 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 64 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 64 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 64 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 64 Mlda 23 Accuracy 0.75\n",
            "Mpca 64 Mlda 24 Accuracy 0.75\n",
            "Mpca 64 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 64 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 30 Accuracy 0.7403846153846154\n",
            "Mpca 64 Mlda 31 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 32 Accuracy 0.7692307692307693\n",
            "Mpca 64 Mlda 33 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 64 Mlda 36 Accuracy 0.75\n",
            "Mpca 64 Mlda 37 Accuracy 0.75\n",
            "Mpca 64 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 64 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 64 Mlda 40 Accuracy 0.7692307692307693\n",
            "Mpca 64 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 64 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 64 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 64 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 64 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 64 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 64 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 64 Mlda 48 Accuracy 0.75\n",
            "Mpca 64 Mlda 49 Accuracy 0.75\n",
            "Mpca 64 Mlda 50 Accuracy 0.75\n",
            "Mpca 65 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 65 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 65 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 65 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 65 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 65 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 65 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 65 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 65 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 65 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 65 Mlda 11 Accuracy 0.625\n",
            "Mpca 65 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 65 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 65 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 65 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 65 Mlda 16 Accuracy 0.6538461538461539\n",
            "Mpca 65 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 65 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 65 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 65 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 65 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 65 Mlda 22 Accuracy 0.75\n",
            "Mpca 65 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 65 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 65 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 65 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 65 Mlda 27 Accuracy 0.75\n",
            "Mpca 65 Mlda 28 Accuracy 0.75\n",
            "Mpca 65 Mlda 29 Accuracy 0.75\n",
            "Mpca 65 Mlda 30 Accuracy 0.7596153846153846\n",
            "Mpca 65 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 65 Mlda 32 Accuracy 0.7692307692307693\n",
            "Mpca 65 Mlda 33 Accuracy 0.7692307692307693\n",
            "Mpca 65 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 65 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 65 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 65 Mlda 37 Accuracy 0.75\n",
            "Mpca 65 Mlda 38 Accuracy 0.75\n",
            "Mpca 65 Mlda 39 Accuracy 0.7692307692307693\n",
            "Mpca 65 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 65 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 65 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 65 Mlda 43 Accuracy 0.7692307692307693\n",
            "Mpca 65 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 65 Mlda 45 Accuracy 0.7692307692307693\n",
            "Mpca 65 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 65 Mlda 47 Accuracy 0.7596153846153846\n",
            "Mpca 65 Mlda 48 Accuracy 0.7980769230769231\n",
            "Mpca 65 Mlda 49 Accuracy 0.7788461538461539\n",
            "Mpca 65 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 66 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 66 Mlda 2 Accuracy 0.125\n",
            "Mpca 66 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 66 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 66 Mlda 5 Accuracy 0.5096153846153846\n",
            "Mpca 66 Mlda 6 Accuracy 0.5865384615384616\n",
            "Mpca 66 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 66 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 66 Mlda 9 Accuracy 0.5384615384615384\n",
            "Mpca 66 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 66 Mlda 11 Accuracy 0.625\n",
            "Mpca 66 Mlda 12 Accuracy 0.625\n",
            "Mpca 66 Mlda 13 Accuracy 0.6057692307692307\n",
            "Mpca 66 Mlda 14 Accuracy 0.6442307692307693\n",
            "Mpca 66 Mlda 15 Accuracy 0.6538461538461539\n",
            "Mpca 66 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 66 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 66 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 66 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 66 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 66 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 66 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 66 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 66 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 66 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 66 Mlda 26 Accuracy 0.7211538461538461\n",
            "Mpca 66 Mlda 27 Accuracy 0.75\n",
            "Mpca 66 Mlda 28 Accuracy 0.75\n",
            "Mpca 66 Mlda 29 Accuracy 0.7307692307692307\n",
            "Mpca 66 Mlda 30 Accuracy 0.75\n",
            "Mpca 66 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 66 Mlda 32 Accuracy 0.7788461538461539\n",
            "Mpca 66 Mlda 33 Accuracy 0.75\n",
            "Mpca 66 Mlda 34 Accuracy 0.7403846153846154\n",
            "Mpca 66 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 66 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 66 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 66 Mlda 38 Accuracy 0.75\n",
            "Mpca 66 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 66 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 66 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 66 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 66 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 66 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 66 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 66 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 66 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 66 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 66 Mlda 49 Accuracy 0.7692307692307693\n",
            "Mpca 66 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 67 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 67 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 67 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 67 Mlda 4 Accuracy 0.375\n",
            "Mpca 67 Mlda 5 Accuracy 0.49038461538461536\n",
            "Mpca 67 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 67 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 67 Mlda 8 Accuracy 0.47115384615384615\n",
            "Mpca 67 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 67 Mlda 10 Accuracy 0.5576923076923077\n",
            "Mpca 67 Mlda 11 Accuracy 0.6057692307692307\n",
            "Mpca 67 Mlda 12 Accuracy 0.5865384615384616\n",
            "Mpca 67 Mlda 13 Accuracy 0.625\n",
            "Mpca 67 Mlda 14 Accuracy 0.625\n",
            "Mpca 67 Mlda 15 Accuracy 0.6538461538461539\n",
            "Mpca 67 Mlda 16 Accuracy 0.6634615384615384\n",
            "Mpca 67 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 67 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 67 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 67 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 67 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 67 Mlda 22 Accuracy 0.75\n",
            "Mpca 67 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 67 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 67 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 67 Mlda 26 Accuracy 0.75\n",
            "Mpca 67 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 67 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 67 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 67 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 67 Mlda 31 Accuracy 0.7692307692307693\n",
            "Mpca 67 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 67 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 67 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 67 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 67 Mlda 36 Accuracy 0.7788461538461539\n",
            "Mpca 67 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 67 Mlda 38 Accuracy 0.7692307692307693\n",
            "Mpca 67 Mlda 39 Accuracy 0.75\n",
            "Mpca 67 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 67 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 67 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 67 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 67 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 67 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 67 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 67 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 67 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 67 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 67 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 68 Mlda 1 Accuracy 0.009615384615384616\n",
            "Mpca 68 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 68 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 68 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 68 Mlda 5 Accuracy 0.49038461538461536\n",
            "Mpca 68 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 68 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 68 Mlda 8 Accuracy 0.4807692307692308\n",
            "Mpca 68 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 68 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 68 Mlda 11 Accuracy 0.625\n",
            "Mpca 68 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 68 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 68 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 68 Mlda 15 Accuracy 0.6730769230769231\n",
            "Mpca 68 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 68 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 68 Mlda 18 Accuracy 0.6923076923076923\n",
            "Mpca 68 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 68 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 68 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 68 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 68 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 68 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 68 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 68 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 68 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 68 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 68 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 68 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 68 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 68 Mlda 32 Accuracy 0.7788461538461539\n",
            "Mpca 68 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 68 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 68 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 68 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 68 Mlda 37 Accuracy 0.7692307692307693\n",
            "Mpca 68 Mlda 38 Accuracy 0.7596153846153846\n",
            "Mpca 68 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 68 Mlda 40 Accuracy 0.7884615384615384\n",
            "Mpca 68 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 68 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 68 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 68 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 68 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 68 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 68 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 68 Mlda 48 Accuracy 0.7980769230769231\n",
            "Mpca 68 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 68 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 69 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 69 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 69 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 69 Mlda 4 Accuracy 0.375\n",
            "Mpca 69 Mlda 5 Accuracy 0.49038461538461536\n",
            "Mpca 69 Mlda 6 Accuracy 0.5673076923076923\n",
            "Mpca 69 Mlda 7 Accuracy 0.5961538461538461\n",
            "Mpca 69 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 69 Mlda 9 Accuracy 0.5288461538461539\n",
            "Mpca 69 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 69 Mlda 11 Accuracy 0.625\n",
            "Mpca 69 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 69 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 69 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 69 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 69 Mlda 16 Accuracy 0.6826923076923077\n",
            "Mpca 69 Mlda 17 Accuracy 0.7019230769230769\n",
            "Mpca 69 Mlda 18 Accuracy 0.7019230769230769\n",
            "Mpca 69 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 69 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 69 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 69 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 69 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 69 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 69 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 69 Mlda 26 Accuracy 0.75\n",
            "Mpca 69 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 69 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 69 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 69 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 69 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 69 Mlda 32 Accuracy 0.7788461538461539\n",
            "Mpca 69 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 69 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 69 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 69 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 69 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 69 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 69 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 69 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 69 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 69 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 69 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 69 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 69 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 69 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 69 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 69 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 69 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 69 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 70 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 70 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 70 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 70 Mlda 5 Accuracy 0.5\n",
            "Mpca 70 Mlda 6 Accuracy 0.5673076923076923\n",
            "Mpca 70 Mlda 7 Accuracy 0.5865384615384616\n",
            "Mpca 70 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 70 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 70 Mlda 10 Accuracy 0.5673076923076923\n",
            "Mpca 70 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 70 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 70 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 70 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 70 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 70 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 70 Mlda 17 Accuracy 0.6923076923076923\n",
            "Mpca 70 Mlda 18 Accuracy 0.6923076923076923\n",
            "Mpca 70 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 70 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 70 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 70 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 70 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 70 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 70 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 70 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 70 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 70 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 70 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 70 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 70 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 70 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 70 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 70 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 70 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 70 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 70 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 70 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 70 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 70 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 70 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 70 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 70 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 70 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 71 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 71 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 71 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 71 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 71 Mlda 5 Accuracy 0.5\n",
            "Mpca 71 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 71 Mlda 7 Accuracy 0.5769230769230769\n",
            "Mpca 71 Mlda 8 Accuracy 0.5\n",
            "Mpca 71 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 71 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 71 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 71 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 71 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 71 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 71 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 71 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 71 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 71 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 71 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 71 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 71 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 71 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 71 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 71 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 71 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 71 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 71 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 71 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 71 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 71 Mlda 30 Accuracy 0.7596153846153846\n",
            "Mpca 71 Mlda 31 Accuracy 0.7596153846153846\n",
            "Mpca 71 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 71 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 71 Mlda 34 Accuracy 0.7788461538461539\n",
            "Mpca 71 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 71 Mlda 36 Accuracy 0.7788461538461539\n",
            "Mpca 71 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 71 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 71 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 71 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 71 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 71 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 71 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 71 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 71 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 71 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 71 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 71 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 71 Mlda 49 Accuracy 0.8076923076923077\n",
            "Mpca 71 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 72 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 72 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 72 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 72 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 72 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 72 Mlda 6 Accuracy 0.5\n",
            "Mpca 72 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 72 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 72 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 72 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 72 Mlda 11 Accuracy 0.625\n",
            "Mpca 72 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 72 Mlda 13 Accuracy 0.6442307692307693\n",
            "Mpca 72 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 72 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 72 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 72 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 72 Mlda 18 Accuracy 0.75\n",
            "Mpca 72 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 72 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 72 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 72 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 72 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 72 Mlda 24 Accuracy 0.75\n",
            "Mpca 72 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 72 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 72 Mlda 27 Accuracy 0.7211538461538461\n",
            "Mpca 72 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 72 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 72 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 72 Mlda 31 Accuracy 0.7692307692307693\n",
            "Mpca 72 Mlda 32 Accuracy 0.7692307692307693\n",
            "Mpca 72 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 72 Mlda 34 Accuracy 0.7884615384615384\n",
            "Mpca 72 Mlda 35 Accuracy 0.7692307692307693\n",
            "Mpca 72 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 72 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 72 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 72 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 72 Mlda 40 Accuracy 0.7884615384615384\n",
            "Mpca 72 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 72 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 72 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 72 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 72 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 72 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 72 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 72 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 72 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 72 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 73 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 73 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 73 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 73 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 73 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 73 Mlda 6 Accuracy 0.5288461538461539\n",
            "Mpca 73 Mlda 7 Accuracy 0.5961538461538461\n",
            "Mpca 73 Mlda 8 Accuracy 0.6442307692307693\n",
            "Mpca 73 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 73 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 73 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 73 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 73 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 73 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 73 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 73 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 73 Mlda 17 Accuracy 0.75\n",
            "Mpca 73 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 73 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 73 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 73 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 73 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 73 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 73 Mlda 24 Accuracy 0.75\n",
            "Mpca 73 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 73 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 73 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 73 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 73 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 73 Mlda 32 Accuracy 0.7788461538461539\n",
            "Mpca 73 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 34 Accuracy 0.7788461538461539\n",
            "Mpca 73 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 73 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 73 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 73 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 73 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 73 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 73 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 73 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 48 Accuracy 0.7980769230769231\n",
            "Mpca 73 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 73 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 74 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 74 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 74 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 74 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 74 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 74 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 74 Mlda 7 Accuracy 0.6346153846153846\n",
            "Mpca 74 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 74 Mlda 9 Accuracy 0.5384615384615384\n",
            "Mpca 74 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 74 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 74 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 74 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 74 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 74 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 74 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 74 Mlda 17 Accuracy 0.75\n",
            "Mpca 74 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 74 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 74 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 74 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 74 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 74 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 74 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 74 Mlda 25 Accuracy 0.75\n",
            "Mpca 74 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 74 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 74 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 74 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 74 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 74 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 74 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 74 Mlda 34 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 74 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 74 Mlda 41 Accuracy 0.7788461538461539\n",
            "Mpca 74 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 74 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 45 Accuracy 0.7692307692307693\n",
            "Mpca 74 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 74 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 74 Mlda 49 Accuracy 0.8076923076923077\n",
            "Mpca 74 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 75 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 75 Mlda 2 Accuracy 0.21153846153846154\n",
            "Mpca 75 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 75 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 75 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 75 Mlda 6 Accuracy 0.5673076923076923\n",
            "Mpca 75 Mlda 7 Accuracy 0.6153846153846154\n",
            "Mpca 75 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 75 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 75 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 75 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 75 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 75 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 75 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 75 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 75 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 75 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 75 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 75 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 75 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 75 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 75 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 75 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 75 Mlda 24 Accuracy 0.75\n",
            "Mpca 75 Mlda 25 Accuracy 0.75\n",
            "Mpca 75 Mlda 26 Accuracy 0.75\n",
            "Mpca 75 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 75 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 75 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 75 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 75 Mlda 32 Accuracy 0.7788461538461539\n",
            "Mpca 75 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 75 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 75 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 75 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 75 Mlda 40 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 75 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 75 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 75 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 45 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 46 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 75 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 75 Mlda 49 Accuracy 0.8076923076923077\n",
            "Mpca 75 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 76 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 76 Mlda 2 Accuracy 0.2403846153846154\n",
            "Mpca 76 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 76 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 76 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 76 Mlda 6 Accuracy 0.5384615384615384\n",
            "Mpca 76 Mlda 7 Accuracy 0.6057692307692307\n",
            "Mpca 76 Mlda 8 Accuracy 0.4423076923076923\n",
            "Mpca 76 Mlda 9 Accuracy 0.5288461538461539\n",
            "Mpca 76 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 76 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 76 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 76 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 76 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 76 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 76 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 76 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 76 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 76 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 76 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 76 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 76 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 76 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 76 Mlda 24 Accuracy 0.7307692307692307\n",
            "Mpca 76 Mlda 25 Accuracy 0.7307692307692307\n",
            "Mpca 76 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 76 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 76 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 76 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 76 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 76 Mlda 33 Accuracy 0.7692307692307693\n",
            "Mpca 76 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 76 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 76 Mlda 36 Accuracy 0.7692307692307693\n",
            "Mpca 76 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 76 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 76 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 76 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 76 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 76 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 76 Mlda 47 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 76 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 76 Mlda 50 Accuracy 0.7980769230769231\n",
            "Mpca 77 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 77 Mlda 2 Accuracy 0.19230769230769232\n",
            "Mpca 77 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 77 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 77 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 77 Mlda 6 Accuracy 0.5288461538461539\n",
            "Mpca 77 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 77 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 77 Mlda 9 Accuracy 0.5384615384615384\n",
            "Mpca 77 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 77 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 77 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 77 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 77 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 77 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 77 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 77 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 77 Mlda 18 Accuracy 0.75\n",
            "Mpca 77 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 77 Mlda 20 Accuracy 0.75\n",
            "Mpca 77 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 77 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 77 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 77 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 77 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 77 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 77 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 77 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 77 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 77 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 77 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 77 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 34 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 36 Accuracy 0.7692307692307693\n",
            "Mpca 77 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 77 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 77 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 77 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 77 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 77 Mlda 45 Accuracy 0.7884615384615384\n",
            "Mpca 77 Mlda 46 Accuracy 0.7884615384615384\n",
            "Mpca 77 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 77 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 77 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 77 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 78 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 78 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 78 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 78 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 78 Mlda 6 Accuracy 0.5288461538461539\n",
            "Mpca 78 Mlda 7 Accuracy 0.5865384615384616\n",
            "Mpca 78 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 78 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 78 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 78 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 78 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 78 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 78 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 78 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 78 Mlda 16 Accuracy 0.75\n",
            "Mpca 78 Mlda 17 Accuracy 0.75\n",
            "Mpca 78 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 78 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 78 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 78 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 78 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 78 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 78 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 78 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 78 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 78 Mlda 27 Accuracy 0.75\n",
            "Mpca 78 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 78 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 78 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 78 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 78 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 45 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 78 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 78 Mlda 49 Accuracy 0.7692307692307693\n",
            "Mpca 78 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 79 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 79 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 79 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 79 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 79 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 79 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 79 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 79 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 79 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 79 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 79 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 79 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 79 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 79 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 79 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 79 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 79 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 79 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 79 Mlda 19 Accuracy 0.7019230769230769\n",
            "Mpca 79 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 79 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 79 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 79 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 79 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 79 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 79 Mlda 26 Accuracy 0.75\n",
            "Mpca 79 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 79 Mlda 28 Accuracy 0.7403846153846154\n",
            "Mpca 79 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 79 Mlda 30 Accuracy 0.7596153846153846\n",
            "Mpca 79 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 79 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 79 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 79 Mlda 34 Accuracy 0.7884615384615384\n",
            "Mpca 79 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 79 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 79 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 79 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 79 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 79 Mlda 40 Accuracy 0.7884615384615384\n",
            "Mpca 79 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 79 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 79 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 79 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 79 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 79 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 79 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 79 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 79 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 79 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 80 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 80 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 80 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 80 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 80 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 80 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 80 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 80 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 80 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 80 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 80 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 80 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 80 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 80 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 80 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 80 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 80 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 80 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 80 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 80 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 80 Mlda 21 Accuracy 0.75\n",
            "Mpca 80 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 80 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 80 Mlda 24 Accuracy 0.75\n",
            "Mpca 80 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 80 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 80 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 80 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 80 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 80 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 80 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 80 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 80 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 80 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 80 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 80 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 80 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 80 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 80 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 80 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 80 Mlda 48 Accuracy 0.7692307692307693\n",
            "Mpca 80 Mlda 49 Accuracy 0.7788461538461539\n",
            "Mpca 80 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 81 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 81 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 81 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 81 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 81 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 81 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 81 Mlda 8 Accuracy 0.6346153846153846\n",
            "Mpca 81 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 81 Mlda 10 Accuracy 0.625\n",
            "Mpca 81 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 81 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 81 Mlda 13 Accuracy 0.6538461538461539\n",
            "Mpca 81 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 81 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 81 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 81 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 81 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 81 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 81 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 81 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 81 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 81 Mlda 23 Accuracy 0.7307692307692307\n",
            "Mpca 81 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 81 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 81 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 81 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 81 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 81 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 81 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 81 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 81 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 81 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 81 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 81 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 81 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 81 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 81 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 81 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 81 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 81 Mlda 48 Accuracy 0.7692307692307693\n",
            "Mpca 81 Mlda 49 Accuracy 0.7788461538461539\n",
            "Mpca 81 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 82 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 82 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 82 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 82 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 82 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 82 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 82 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 82 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 82 Mlda 10 Accuracy 0.625\n",
            "Mpca 82 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 82 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 82 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 82 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 82 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 82 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 82 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 82 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 82 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 82 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 82 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 82 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 82 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 82 Mlda 24 Accuracy 0.7307692307692307\n",
            "Mpca 82 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 82 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 82 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 82 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 82 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 82 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 82 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 82 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 82 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 82 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 82 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 82 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 82 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 82 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 82 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 82 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 82 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 82 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 82 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 82 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 83 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 83 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 83 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 83 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 83 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 83 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 83 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 83 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 83 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 83 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 83 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 83 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 83 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 83 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 83 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 83 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 83 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 83 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 83 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 83 Mlda 20 Accuracy 0.75\n",
            "Mpca 83 Mlda 21 Accuracy 0.75\n",
            "Mpca 83 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 83 Mlda 23 Accuracy 0.7307692307692307\n",
            "Mpca 83 Mlda 24 Accuracy 0.7307692307692307\n",
            "Mpca 83 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 83 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 83 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 83 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 83 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 83 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 83 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 83 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 83 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 83 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 83 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 83 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 83 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 83 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 83 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 83 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 83 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 83 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 83 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 83 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 83 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 83 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 83 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 83 Mlda 48 Accuracy 0.7692307692307693\n",
            "Mpca 83 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 83 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 84 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 84 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 84 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 84 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 84 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 84 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 84 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 84 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 84 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 84 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 84 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 84 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 84 Mlda 13 Accuracy 0.6538461538461539\n",
            "Mpca 84 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 84 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 84 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 84 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 84 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 84 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 84 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 84 Mlda 21 Accuracy 0.75\n",
            "Mpca 84 Mlda 22 Accuracy 0.75\n",
            "Mpca 84 Mlda 23 Accuracy 0.75\n",
            "Mpca 84 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 84 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 84 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 84 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 84 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 84 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 84 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 84 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 84 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 84 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 84 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 84 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 84 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 84 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 84 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 84 Mlda 39 Accuracy 0.7692307692307693\n",
            "Mpca 84 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 84 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 84 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 84 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 84 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 84 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 84 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 84 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 84 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 84 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 84 Mlda 50 Accuracy 0.7980769230769231\n",
            "Mpca 85 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 85 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 85 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 85 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 85 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 85 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 85 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 85 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 85 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 85 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 85 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 85 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 85 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 85 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 85 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 85 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 85 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 85 Mlda 18 Accuracy 0.75\n",
            "Mpca 85 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 85 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 85 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 85 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 85 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 85 Mlda 24 Accuracy 0.75\n",
            "Mpca 85 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 85 Mlda 26 Accuracy 0.75\n",
            "Mpca 85 Mlda 27 Accuracy 0.75\n",
            "Mpca 85 Mlda 28 Accuracy 0.75\n",
            "Mpca 85 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 85 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 85 Mlda 31 Accuracy 0.7692307692307693\n",
            "Mpca 85 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 85 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 85 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 85 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 85 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 85 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 85 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 85 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 85 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 85 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 85 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 85 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 86 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 86 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 86 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 86 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 86 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 86 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 86 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 86 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 86 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 86 Mlda 10 Accuracy 0.625\n",
            "Mpca 86 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 86 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 86 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 86 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 86 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 86 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 86 Mlda 17 Accuracy 0.75\n",
            "Mpca 86 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 86 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 86 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 86 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 86 Mlda 22 Accuracy 0.75\n",
            "Mpca 86 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 86 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 86 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 86 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 86 Mlda 27 Accuracy 0.75\n",
            "Mpca 86 Mlda 28 Accuracy 0.7403846153846154\n",
            "Mpca 86 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 86 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 86 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 86 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 86 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 86 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 86 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 86 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 86 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 86 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 86 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 86 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 86 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 86 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 87 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 87 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 87 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 87 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 87 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 87 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 87 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 87 Mlda 8 Accuracy 0.6346153846153846\n",
            "Mpca 87 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 87 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 87 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 87 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 87 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 87 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 87 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 87 Mlda 16 Accuracy 0.75\n",
            "Mpca 87 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 87 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 87 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 87 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 87 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 87 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 87 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 87 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 87 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 87 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 87 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 87 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 87 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 87 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 87 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 87 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 87 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 87 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 87 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 87 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 87 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 87 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 87 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 87 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 87 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 87 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 87 Mlda 50 Accuracy 0.7980769230769231\n",
            "Mpca 88 Mlda 1 Accuracy 0.009615384615384616\n",
            "Mpca 88 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 88 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 88 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 88 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 88 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 88 Mlda 7 Accuracy 0.5\n",
            "Mpca 88 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 88 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 88 Mlda 10 Accuracy 0.625\n",
            "Mpca 88 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 88 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 88 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 88 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 88 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 88 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 88 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 88 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 88 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 88 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 88 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 88 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 88 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 88 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 88 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 88 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 88 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 88 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 88 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 88 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 88 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 88 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 88 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 88 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 88 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 88 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 88 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 88 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 88 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 88 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 88 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 88 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 49 Accuracy 0.8076923076923077\n",
            "Mpca 88 Mlda 50 Accuracy 0.7980769230769231\n",
            "Mpca 89 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 89 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 89 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 89 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 89 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 89 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 89 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 89 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 89 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 89 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 89 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 89 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 89 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 89 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 89 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 89 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 89 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 89 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 89 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 89 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 89 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 89 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 89 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 89 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 89 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 89 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 89 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 89 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 89 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 89 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 89 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 89 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 89 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 89 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 89 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 89 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 89 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 89 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 89 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 89 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 89 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 89 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 90 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 90 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 90 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 90 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 90 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 90 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 90 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 90 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 90 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 90 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 90 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 90 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 90 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 90 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 90 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 90 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 90 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 90 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 90 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 90 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 90 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 90 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 90 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 90 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 90 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 90 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 90 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 90 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 90 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 90 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 90 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 90 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 90 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 90 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 90 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 90 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 90 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 90 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 90 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 90 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 90 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 90 Mlda 50 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 91 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 91 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 91 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 91 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 91 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 91 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 91 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 91 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 91 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 91 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 91 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 91 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 91 Mlda 14 Accuracy 0.75\n",
            "Mpca 91 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 91 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 91 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 91 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 91 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 91 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 91 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 91 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 91 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 91 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 91 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 91 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 91 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 91 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 91 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 91 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 91 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 91 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 91 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 91 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 91 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 91 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 91 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 91 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 91 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 91 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 91 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 91 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 91 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 91 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 92 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 92 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 92 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 92 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 92 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 92 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 92 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 92 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 92 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 92 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 92 Mlda 11 Accuracy 0.7403846153846154\n",
            "Mpca 92 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 92 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 92 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 92 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 92 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 92 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 92 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 92 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 92 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 92 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 92 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 92 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 92 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 92 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 92 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 92 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 92 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 92 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 92 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 92 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 92 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 92 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 92 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 92 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 92 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 92 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 92 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 92 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 92 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 92 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 92 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 92 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 92 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 92 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 92 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 92 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 92 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 92 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 92 Mlda 50 Accuracy 0.7788461538461539\n",
            "Mpca 93 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 93 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 93 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 93 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 93 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 93 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 93 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 93 Mlda 8 Accuracy 0.5\n",
            "Mpca 93 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 93 Mlda 10 Accuracy 0.6923076923076923\n",
            "Mpca 93 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 93 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 93 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 93 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 93 Mlda 15 Accuracy 0.75\n",
            "Mpca 93 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 93 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 93 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 93 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 93 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 93 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 93 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 93 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 93 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 93 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 93 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 93 Mlda 27 Accuracy 0.7403846153846154\n",
            "Mpca 93 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 93 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 93 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 93 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 93 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 93 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 93 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 93 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 93 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 93 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 93 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 93 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 93 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 93 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 93 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 93 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 93 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 93 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 93 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 93 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 93 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 93 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 93 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 94 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 94 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 94 Mlda 3 Accuracy 0.25\n",
            "Mpca 94 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 94 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 94 Mlda 6 Accuracy 0.5\n",
            "Mpca 94 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 94 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 94 Mlda 9 Accuracy 0.6730769230769231\n",
            "Mpca 94 Mlda 10 Accuracy 0.6923076923076923\n",
            "Mpca 94 Mlda 11 Accuracy 0.7403846153846154\n",
            "Mpca 94 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 94 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 94 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 94 Mlda 15 Accuracy 0.75\n",
            "Mpca 94 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 94 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 94 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 94 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 94 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 94 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 94 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 94 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 94 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 94 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 94 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 94 Mlda 27 Accuracy 0.75\n",
            "Mpca 94 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 94 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 94 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 94 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 94 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 94 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 94 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 94 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 94 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 94 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 94 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 94 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 94 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 94 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 94 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 94 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 95 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 95 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 95 Mlda 3 Accuracy 0.25\n",
            "Mpca 95 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 95 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 95 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 95 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 95 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 95 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 95 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 95 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 95 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 95 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 95 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 95 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 95 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 95 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 95 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 95 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 95 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 95 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 95 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 95 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 95 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 95 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 95 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 95 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 95 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 95 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 95 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 95 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 95 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 95 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 95 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 95 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 95 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 95 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 95 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 95 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 95 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 95 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 95 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 95 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 95 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 95 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 95 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 95 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 95 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 95 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 95 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 96 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 96 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 96 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 96 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 96 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 96 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 96 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 96 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 96 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 96 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 96 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 96 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 96 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 96 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 96 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 96 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 96 Mlda 17 Accuracy 0.75\n",
            "Mpca 96 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 96 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 96 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 96 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 96 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 96 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 96 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 96 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 96 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 96 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 96 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 96 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 96 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 96 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 96 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 96 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 96 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 96 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 96 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 96 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 96 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 96 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 96 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 96 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 96 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 96 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 97 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 97 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 97 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 97 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 97 Mlda 5 Accuracy 0.375\n",
            "Mpca 97 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 97 Mlda 7 Accuracy 0.5\n",
            "Mpca 97 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 97 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 97 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 97 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 97 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 97 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 97 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 97 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 97 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 97 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 97 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 97 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 97 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 97 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 97 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 97 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 97 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 97 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 97 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 97 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 97 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 97 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 97 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 97 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 97 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 97 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 97 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 97 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 97 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 97 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 97 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 97 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 97 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 97 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 97 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 97 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 98 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 98 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 98 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 98 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 98 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 98 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 98 Mlda 7 Accuracy 0.4230769230769231\n",
            "Mpca 98 Mlda 8 Accuracy 0.4807692307692308\n",
            "Mpca 98 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 98 Mlda 10 Accuracy 0.625\n",
            "Mpca 98 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 98 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 98 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 98 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 98 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 98 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 98 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 98 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 98 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 98 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 98 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 98 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 98 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 98 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 98 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 98 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 98 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 98 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 98 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 98 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 98 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 98 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 98 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 98 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 99 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 99 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 99 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 99 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 99 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 99 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 99 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 99 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 99 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 99 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 99 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 99 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 99 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 99 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 99 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 99 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 99 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 99 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 99 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 99 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 99 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 99 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 99 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 99 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 99 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 99 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 99 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 99 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 99 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 99 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 99 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 99 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 99 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 99 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 99 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 99 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 99 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 99 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 99 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 99 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 100 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 100 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 100 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 100 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 100 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 100 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 100 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 100 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 100 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 100 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 100 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 100 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 100 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 100 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 100 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 100 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 100 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 100 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 100 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 100 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 100 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 100 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 100 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 100 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 100 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 100 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 100 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 100 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 100 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 100 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 100 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 100 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 100 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 100 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 100 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 100 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 100 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 100 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 100 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 100 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 100 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 100 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 101 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 101 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 101 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 101 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 101 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 101 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 101 Mlda 8 Accuracy 0.5\n",
            "Mpca 101 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 101 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 101 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 101 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 101 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 101 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 101 Mlda 15 Accuracy 0.75\n",
            "Mpca 101 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 101 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 101 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 101 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 101 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 101 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 101 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 101 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 101 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 101 Mlda 25 Accuracy 0.75\n",
            "Mpca 101 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 101 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 101 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 101 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 101 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 101 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 101 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 101 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 101 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 101 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 101 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 101 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 101 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 101 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 101 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 101 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 101 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 101 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 102 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 102 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 102 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 102 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 102 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 102 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 102 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 102 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 102 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 102 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 102 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 102 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 102 Mlda 13 Accuracy 0.75\n",
            "Mpca 102 Mlda 14 Accuracy 0.75\n",
            "Mpca 102 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 102 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 102 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 102 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 102 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 102 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 102 Mlda 21 Accuracy 0.75\n",
            "Mpca 102 Mlda 22 Accuracy 0.75\n",
            "Mpca 102 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 102 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 102 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 102 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 102 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 102 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 102 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 102 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 102 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 102 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 102 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 102 Mlda 34 Accuracy 0.7884615384615384\n",
            "Mpca 102 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 102 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 102 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 102 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 102 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 102 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 102 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 102 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 102 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 102 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 102 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 102 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 102 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 102 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 102 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 102 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 103 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 103 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 103 Mlda 4 Accuracy 0.41346153846153844\n",
            "Mpca 103 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 103 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 103 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 103 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 103 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 103 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 103 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 103 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 103 Mlda 13 Accuracy 0.7596153846153846\n",
            "Mpca 103 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 103 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 103 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 103 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 103 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 103 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 103 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 103 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 103 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 103 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 103 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 103 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 103 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 103 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 103 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 103 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 103 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 103 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 103 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 103 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 103 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 103 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 103 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 103 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 103 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 103 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 103 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 103 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 103 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 103 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 103 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 104 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 104 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 104 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 104 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 104 Mlda 5 Accuracy 0.375\n",
            "Mpca 104 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 104 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 104 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 104 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 104 Mlda 10 Accuracy 0.625\n",
            "Mpca 104 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 104 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 104 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 104 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 104 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 104 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 104 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 104 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 104 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 104 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 104 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 104 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 104 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 104 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 104 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 104 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 104 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 104 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 104 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 104 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 104 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 104 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 104 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 105 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 105 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 105 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 105 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 105 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 105 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 105 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 105 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 105 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 105 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 105 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 105 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 105 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 105 Mlda 14 Accuracy 0.75\n",
            "Mpca 105 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 105 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 105 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 105 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 105 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 105 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 105 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 105 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 105 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 105 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 105 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 105 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 105 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 105 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 105 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 105 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 105 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 105 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 105 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 105 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 105 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 105 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 105 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 105 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 105 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 105 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 105 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 105 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 105 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 105 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 105 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 105 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 105 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 105 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 105 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 105 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 106 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 106 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 106 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 106 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 106 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 106 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 106 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 106 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 106 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 106 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 106 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 106 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 106 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 106 Mlda 14 Accuracy 0.75\n",
            "Mpca 106 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 106 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 106 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 106 Mlda 18 Accuracy 0.75\n",
            "Mpca 106 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 106 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 106 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 106 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 106 Mlda 23 Accuracy 0.8173076923076923\n",
            "Mpca 106 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 106 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 106 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 106 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 106 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 106 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 106 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 106 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 106 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 106 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 106 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 106 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 106 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 106 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 106 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 106 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 106 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 106 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 106 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 106 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 106 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 106 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 106 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 106 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 106 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 106 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 106 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 107 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 107 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 107 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 107 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 107 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 107 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 107 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 107 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 107 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 107 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 107 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 107 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 107 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 107 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 107 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 107 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 107 Mlda 17 Accuracy 0.75\n",
            "Mpca 107 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 107 Mlda 19 Accuracy 0.75\n",
            "Mpca 107 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 107 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 107 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 107 Mlda 23 Accuracy 0.8173076923076923\n",
            "Mpca 107 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 107 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 107 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 107 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 107 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 107 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 107 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 107 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 107 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 107 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 107 Mlda 34 Accuracy 0.8846153846153846\n",
            "Mpca 107 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 107 Mlda 36 Accuracy 0.875\n",
            "Mpca 107 Mlda 37 Accuracy 0.875\n",
            "Mpca 107 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 107 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 107 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 107 Mlda 41 Accuracy 0.875\n",
            "Mpca 107 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 107 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 107 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 107 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 107 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 107 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 107 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 107 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 107 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 108 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 108 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 108 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 108 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 108 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 108 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 108 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 108 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 108 Mlda 9 Accuracy 0.625\n",
            "Mpca 108 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 108 Mlda 11 Accuracy 0.625\n",
            "Mpca 108 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 108 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 108 Mlda 14 Accuracy 0.75\n",
            "Mpca 108 Mlda 15 Accuracy 0.75\n",
            "Mpca 108 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 108 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 108 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 108 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 108 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 108 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 108 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 108 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 108 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 108 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 108 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 108 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 108 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 108 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 108 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 108 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 108 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 108 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 108 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 108 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 108 Mlda 36 Accuracy 0.875\n",
            "Mpca 108 Mlda 37 Accuracy 0.875\n",
            "Mpca 108 Mlda 38 Accuracy 0.875\n",
            "Mpca 108 Mlda 39 Accuracy 0.875\n",
            "Mpca 108 Mlda 40 Accuracy 0.875\n",
            "Mpca 108 Mlda 41 Accuracy 0.8846153846153846\n",
            "Mpca 108 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 108 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 108 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 108 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 108 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 108 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 108 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 108 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 108 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 109 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 109 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 109 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 109 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 109 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 109 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 109 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 109 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 109 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 109 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 109 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 109 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 109 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 109 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 109 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 109 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 109 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 109 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 109 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 109 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 109 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 109 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 109 Mlda 23 Accuracy 0.8557692307692307\n",
            "Mpca 109 Mlda 24 Accuracy 0.8461538461538461\n",
            "Mpca 109 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 109 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 109 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 109 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 109 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 109 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 109 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 109 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 109 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 109 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 109 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 109 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 109 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 109 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 109 Mlda 39 Accuracy 0.875\n",
            "Mpca 109 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 109 Mlda 41 Accuracy 0.8846153846153846\n",
            "Mpca 109 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 109 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 109 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 109 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 109 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 109 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 109 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 109 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 109 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 110 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 110 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 110 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 110 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 110 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 110 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 110 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 110 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 110 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 110 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 110 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 110 Mlda 13 Accuracy 0.7596153846153846\n",
            "Mpca 110 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 110 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 110 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 110 Mlda 17 Accuracy 0.7884615384615384\n",
            "Mpca 110 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 110 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 110 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 110 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 110 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 110 Mlda 23 Accuracy 0.8653846153846154\n",
            "Mpca 110 Mlda 24 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 25 Accuracy 0.8365384615384616\n",
            "Mpca 110 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 110 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 110 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 110 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 110 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 110 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 110 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 110 Mlda 33 Accuracy 0.8653846153846154\n",
            "Mpca 110 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 110 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 110 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 110 Mlda 39 Accuracy 0.875\n",
            "Mpca 110 Mlda 40 Accuracy 0.875\n",
            "Mpca 110 Mlda 41 Accuracy 0.875\n",
            "Mpca 110 Mlda 42 Accuracy 0.875\n",
            "Mpca 110 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 110 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 110 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 110 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 110 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 111 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 111 Mlda 2 Accuracy 0.23076923076923078\n",
            "Mpca 111 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 111 Mlda 4 Accuracy 0.41346153846153844\n",
            "Mpca 111 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 111 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 111 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 111 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 111 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 111 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 111 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 111 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 111 Mlda 13 Accuracy 0.75\n",
            "Mpca 111 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 111 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 111 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 111 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 111 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 111 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 111 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 111 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 111 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 111 Mlda 23 Accuracy 0.8461538461538461\n",
            "Mpca 111 Mlda 24 Accuracy 0.8365384615384616\n",
            "Mpca 111 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 111 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 111 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 111 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 111 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 111 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 111 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 111 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 111 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 111 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 111 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 111 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 111 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 111 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 111 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 111 Mlda 40 Accuracy 0.875\n",
            "Mpca 111 Mlda 41 Accuracy 0.875\n",
            "Mpca 111 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 111 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 111 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 111 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 111 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 111 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 111 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 111 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 111 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 112 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 112 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 112 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 112 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 112 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 112 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 112 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 112 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 112 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 112 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 112 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 112 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 112 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 112 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 112 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 112 Mlda 17 Accuracy 0.8269230769230769\n",
            "Mpca 112 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 112 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 112 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 112 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 112 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 112 Mlda 23 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 24 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 25 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 112 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 112 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 112 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 112 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 112 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 112 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 112 Mlda 40 Accuracy 0.875\n",
            "Mpca 112 Mlda 41 Accuracy 0.875\n",
            "Mpca 112 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 112 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 112 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 112 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 112 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 113 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 113 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 113 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 113 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 113 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 113 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 113 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 113 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 113 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 113 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 113 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 113 Mlda 13 Accuracy 0.7596153846153846\n",
            "Mpca 113 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 113 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 113 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 113 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 113 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 113 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 113 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 113 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 113 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 113 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 113 Mlda 24 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 25 Accuracy 0.8365384615384616\n",
            "Mpca 113 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 113 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 113 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 113 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 113 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 113 Mlda 31 Accuracy 0.8557692307692307\n",
            "Mpca 113 Mlda 32 Accuracy 0.8557692307692307\n",
            "Mpca 113 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 113 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 113 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 113 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 113 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 113 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 113 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 113 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 114 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 114 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 114 Mlda 4 Accuracy 0.375\n",
            "Mpca 114 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 114 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 114 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 114 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 114 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 114 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 114 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 114 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 114 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 114 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 114 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 114 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 114 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 114 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 114 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 114 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 114 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 114 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 114 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 114 Mlda 24 Accuracy 0.8557692307692307\n",
            "Mpca 114 Mlda 25 Accuracy 0.8557692307692307\n",
            "Mpca 114 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 114 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 114 Mlda 28 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 29 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 114 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 114 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 114 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 114 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 114 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 114 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 114 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 115 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 115 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 115 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 115 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 115 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 115 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 115 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 115 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 115 Mlda 10 Accuracy 0.7019230769230769\n",
            "Mpca 115 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 115 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 115 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 115 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 115 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 115 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 115 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 115 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 115 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 115 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 115 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 115 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 115 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 115 Mlda 24 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 25 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 26 Accuracy 0.8557692307692307\n",
            "Mpca 115 Mlda 27 Accuracy 0.8557692307692307\n",
            "Mpca 115 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 115 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 115 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 115 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 115 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 115 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 115 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 115 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 115 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 115 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 115 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 115 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 115 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 115 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 115 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 116 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 116 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 116 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 116 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 116 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 116 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 116 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 116 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 116 Mlda 10 Accuracy 0.7115384615384616\n",
            "Mpca 116 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 116 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 116 Mlda 13 Accuracy 0.75\n",
            "Mpca 116 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 116 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 116 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 116 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 116 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 116 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 116 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 116 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 116 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 116 Mlda 23 Accuracy 0.8173076923076923\n",
            "Mpca 116 Mlda 24 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 25 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 116 Mlda 27 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 28 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 29 Accuracy 0.8653846153846154\n",
            "Mpca 116 Mlda 30 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 116 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 116 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 116 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 116 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 116 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 116 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 116 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 117 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 117 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 117 Mlda 3 Accuracy 0.25\n",
            "Mpca 117 Mlda 4 Accuracy 0.41346153846153844\n",
            "Mpca 117 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 117 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 117 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 117 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 117 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 117 Mlda 10 Accuracy 0.7211538461538461\n",
            "Mpca 117 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 117 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 117 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 117 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 117 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 117 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 117 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 117 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 117 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 117 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 117 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 117 Mlda 22 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 24 Accuracy 0.8557692307692307\n",
            "Mpca 117 Mlda 25 Accuracy 0.8461538461538461\n",
            "Mpca 117 Mlda 26 Accuracy 0.8461538461538461\n",
            "Mpca 117 Mlda 27 Accuracy 0.8461538461538461\n",
            "Mpca 117 Mlda 28 Accuracy 0.8557692307692307\n",
            "Mpca 117 Mlda 29 Accuracy 0.8653846153846154\n",
            "Mpca 117 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 117 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 117 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 117 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 117 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 117 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 117 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 117 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 117 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 117 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 117 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 117 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 117 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 117 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 117 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 118 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 118 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 118 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 118 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 118 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 118 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 118 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 118 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 118 Mlda 10 Accuracy 0.6923076923076923\n",
            "Mpca 118 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 118 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 118 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 118 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 118 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 118 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 118 Mlda 17 Accuracy 0.7884615384615384\n",
            "Mpca 118 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 118 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 118 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 118 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 118 Mlda 22 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 24 Accuracy 0.8653846153846154\n",
            "Mpca 118 Mlda 25 Accuracy 0.8653846153846154\n",
            "Mpca 118 Mlda 26 Accuracy 0.8557692307692307\n",
            "Mpca 118 Mlda 27 Accuracy 0.8653846153846154\n",
            "Mpca 118 Mlda 28 Accuracy 0.8461538461538461\n",
            "Mpca 118 Mlda 29 Accuracy 0.8557692307692307\n",
            "Mpca 118 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 118 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 118 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 118 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 118 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 118 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 118 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 118 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 118 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 118 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 118 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 119 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 119 Mlda 3 Accuracy 0.25\n",
            "Mpca 119 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 119 Mlda 5 Accuracy 0.375\n",
            "Mpca 119 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 119 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 119 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 119 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 119 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 119 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 119 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 119 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 119 Mlda 14 Accuracy 0.8173076923076923\n",
            "Mpca 119 Mlda 15 Accuracy 0.7980769230769231\n",
            "Mpca 119 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 119 Mlda 17 Accuracy 0.7884615384615384\n",
            "Mpca 119 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 119 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 119 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 119 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 119 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 23 Accuracy 0.8461538461538461\n",
            "Mpca 119 Mlda 24 Accuracy 0.8461538461538461\n",
            "Mpca 119 Mlda 25 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 29 Accuracy 0.8557692307692307\n",
            "Mpca 119 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 119 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 119 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 119 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 119 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 119 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 120 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 120 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 120 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 120 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 120 Mlda 5 Accuracy 0.375\n",
            "Mpca 120 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 120 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 120 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 120 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 120 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 120 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 120 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 120 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 120 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 120 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 120 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 120 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 120 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 120 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 120 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 120 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 120 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 120 Mlda 23 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 24 Accuracy 0.8269230769230769\n",
            "Mpca 120 Mlda 25 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 26 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 29 Accuracy 0.8653846153846154\n",
            "Mpca 120 Mlda 30 Accuracy 0.8557692307692307\n",
            "Mpca 120 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 120 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 120 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 120 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 120 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 120 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 120 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 120 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 121 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 121 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 121 Mlda 4 Accuracy 0.4230769230769231\n",
            "Mpca 121 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 121 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 121 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 121 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 121 Mlda 9 Accuracy 0.6538461538461539\n",
            "Mpca 121 Mlda 10 Accuracy 0.6923076923076923\n",
            "Mpca 121 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 121 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 121 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 121 Mlda 14 Accuracy 0.8173076923076923\n",
            "Mpca 121 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 121 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 121 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 121 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 121 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 121 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 121 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 121 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 121 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 121 Mlda 25 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 29 Accuracy 0.8557692307692307\n",
            "Mpca 121 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 121 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 121 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 121 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 121 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 121 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 121 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 122 Mlda 2 Accuracy 0.125\n",
            "Mpca 122 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 122 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 122 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 122 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 122 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 122 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 122 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 122 Mlda 10 Accuracy 0.7019230769230769\n",
            "Mpca 122 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 122 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 122 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 122 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 122 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 122 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 122 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 122 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 122 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 122 Mlda 20 Accuracy 0.8365384615384616\n",
            "Mpca 122 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 122 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 122 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 24 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 25 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 122 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 122 Mlda 29 Accuracy 0.8653846153846154\n",
            "Mpca 122 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 122 Mlda 32 Accuracy 0.8557692307692307\n",
            "Mpca 122 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 122 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 122 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 122 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 122 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 122 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 122 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 122 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 122 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 123 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 123 Mlda 2 Accuracy 0.125\n",
            "Mpca 123 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 123 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 123 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 123 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 123 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 123 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 123 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 123 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 123 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 123 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 123 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 123 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 123 Mlda 15 Accuracy 0.8173076923076923\n",
            "Mpca 123 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 123 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 123 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 123 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 123 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 123 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 123 Mlda 22 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 24 Accuracy 0.8269230769230769\n",
            "Mpca 123 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 123 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 123 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 123 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 123 Mlda 29 Accuracy 0.8846153846153846\n",
            "Mpca 123 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 123 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 123 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 123 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 123 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 124 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 124 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 124 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 124 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 124 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 124 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 124 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 124 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 124 Mlda 10 Accuracy 0.7019230769230769\n",
            "Mpca 124 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 124 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 124 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 124 Mlda 14 Accuracy 0.8173076923076923\n",
            "Mpca 124 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 124 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 124 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 124 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 124 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 124 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 124 Mlda 21 Accuracy 0.8269230769230769\n",
            "Mpca 124 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 124 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 124 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 124 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 124 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 27 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 28 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 29 Accuracy 0.875\n",
            "Mpca 124 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 32 Accuracy 0.8557692307692307\n",
            "Mpca 124 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 124 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 124 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 124 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 124 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 124 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 124 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 124 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 125 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 125 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 125 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 125 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 125 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 125 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 125 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 125 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 125 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 125 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 125 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 125 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 125 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 125 Mlda 15 Accuracy 0.8173076923076923\n",
            "Mpca 125 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 125 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 125 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 125 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 21 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 125 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 27 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 28 Accuracy 0.8557692307692307\n",
            "Mpca 125 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 125 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 125 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 125 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 125 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 125 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 125 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 126 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 126 Mlda 3 Accuracy 0.3076923076923077\n",
            "Mpca 126 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 126 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 126 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 126 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 126 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 126 Mlda 9 Accuracy 0.6730769230769231\n",
            "Mpca 126 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 126 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 126 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 126 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 126 Mlda 14 Accuracy 0.8173076923076923\n",
            "Mpca 126 Mlda 15 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 17 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 126 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 126 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 126 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 126 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 23 Accuracy 0.8173076923076923\n",
            "Mpca 126 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 126 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 126 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 28 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 29 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 30 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 126 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 126 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 126 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 126 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 126 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 126 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 126 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 126 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 126 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 126 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 126 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 126 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 126 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 127 Mlda 2 Accuracy 0.125\n",
            "Mpca 127 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 127 Mlda 4 Accuracy 0.41346153846153844\n",
            "Mpca 127 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 127 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 127 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 127 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 127 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 127 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 127 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 127 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 127 Mlda 13 Accuracy 0.75\n",
            "Mpca 127 Mlda 14 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 15 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 17 Accuracy 0.8365384615384616\n",
            "Mpca 127 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 127 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 127 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 127 Mlda 22 Accuracy 0.8365384615384616\n",
            "Mpca 127 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 127 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 127 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 127 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 127 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 29 Accuracy 0.8461538461538461\n",
            "Mpca 127 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 127 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 127 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 127 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 127 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 127 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 127 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 127 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 127 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 127 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 127 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 127 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 127 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 127 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 128 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 128 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 128 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 128 Mlda 4 Accuracy 0.46153846153846156\n",
            "Mpca 128 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 128 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 128 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 128 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 128 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 128 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 128 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 128 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 128 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 128 Mlda 14 Accuracy 0.8173076923076923\n",
            "Mpca 128 Mlda 15 Accuracy 0.8269230769230769\n",
            "Mpca 128 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 128 Mlda 17 Accuracy 0.8365384615384616\n",
            "Mpca 128 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 128 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 128 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 128 Mlda 21 Accuracy 0.8365384615384616\n",
            "Mpca 128 Mlda 22 Accuracy 0.8557692307692307\n",
            "Mpca 128 Mlda 23 Accuracy 0.8461538461538461\n",
            "Mpca 128 Mlda 24 Accuracy 0.8365384615384616\n",
            "Mpca 128 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 128 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 128 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 128 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 128 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 128 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 128 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 128 Mlda 32 Accuracy 0.8557692307692307\n",
            "Mpca 128 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 128 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 128 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 128 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 128 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 128 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 128 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 128 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 128 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 128 Mlda 42 Accuracy 0.875\n",
            "Mpca 128 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 128 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 128 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 128 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 128 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 128 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 128 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 128 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 129 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 129 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 129 Mlda 4 Accuracy 0.46153846153846156\n",
            "Mpca 129 Mlda 5 Accuracy 0.47115384615384615\n",
            "Mpca 129 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 129 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 129 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 129 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 129 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 129 Mlda 11 Accuracy 0.75\n",
            "Mpca 129 Mlda 12 Accuracy 0.7788461538461539\n",
            "Mpca 129 Mlda 13 Accuracy 0.7980769230769231\n",
            "Mpca 129 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 129 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 129 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 129 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 129 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 129 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 129 Mlda 20 Accuracy 0.8365384615384616\n",
            "Mpca 129 Mlda 21 Accuracy 0.8365384615384616\n",
            "Mpca 129 Mlda 22 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 23 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 24 Accuracy 0.8269230769230769\n",
            "Mpca 129 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 129 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 129 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 129 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 129 Mlda 29 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 129 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 129 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 129 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 129 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 129 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 129 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 129 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 129 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 129 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 129 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 129 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 129 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 130 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 130 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 130 Mlda 3 Accuracy 0.3076923076923077\n",
            "Mpca 130 Mlda 4 Accuracy 0.46153846153846156\n",
            "Mpca 130 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 130 Mlda 6 Accuracy 0.5\n",
            "Mpca 130 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 130 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 130 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 130 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 130 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 130 Mlda 12 Accuracy 0.75\n",
            "Mpca 130 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 130 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 130 Mlda 15 Accuracy 0.7980769230769231\n",
            "Mpca 130 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 130 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 130 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 130 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 130 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 130 Mlda 21 Accuracy 0.8365384615384616\n",
            "Mpca 130 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 130 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 130 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 130 Mlda 25 Accuracy 0.8365384615384616\n",
            "Mpca 130 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 130 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 130 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 130 Mlda 29 Accuracy 0.8461538461538461\n",
            "Mpca 130 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 130 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 130 Mlda 32 Accuracy 0.8653846153846154\n",
            "Mpca 130 Mlda 33 Accuracy 0.8653846153846154\n",
            "Mpca 130 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 130 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 130 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 130 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 130 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 130 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 130 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 130 Mlda 41 Accuracy 0.875\n",
            "Mpca 130 Mlda 42 Accuracy 0.875\n",
            "Mpca 130 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 130 Mlda 44 Accuracy 0.8846153846153846\n",
            "Mpca 130 Mlda 45 Accuracy 0.875\n",
            "Mpca 130 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 130 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 130 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 130 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 130 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 131 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 131 Mlda 2 Accuracy 0.125\n",
            "Mpca 131 Mlda 3 Accuracy 0.3269230769230769\n",
            "Mpca 131 Mlda 4 Accuracy 0.46153846153846156\n",
            "Mpca 131 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 131 Mlda 6 Accuracy 0.5288461538461539\n",
            "Mpca 131 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 131 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 131 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 131 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 131 Mlda 11 Accuracy 0.75\n",
            "Mpca 131 Mlda 12 Accuracy 0.7692307692307693\n",
            "Mpca 131 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 131 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 131 Mlda 15 Accuracy 0.7980769230769231\n",
            "Mpca 131 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 131 Mlda 17 Accuracy 0.8269230769230769\n",
            "Mpca 131 Mlda 18 Accuracy 0.8269230769230769\n",
            "Mpca 131 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 131 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 131 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 131 Mlda 22 Accuracy 0.8365384615384616\n",
            "Mpca 131 Mlda 23 Accuracy 0.8461538461538461\n",
            "Mpca 131 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 131 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 131 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 131 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 131 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 131 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 131 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 131 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 131 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 131 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 131 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 131 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 131 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 131 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 131 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 131 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 131 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 131 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 131 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 131 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 131 Mlda 44 Accuracy 0.875\n",
            "Mpca 131 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 131 Mlda 46 Accuracy 0.8846153846153846\n",
            "Mpca 131 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 131 Mlda 48 Accuracy 0.875\n",
            "Mpca 131 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 131 Mlda 50 Accuracy 0.875\n",
            "Mpca 132 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 132 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 132 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 132 Mlda 4 Accuracy 0.49038461538461536\n",
            "Mpca 132 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 132 Mlda 6 Accuracy 0.5288461538461539\n",
            "Mpca 132 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 132 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 132 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 132 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 132 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 132 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 132 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 132 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 132 Mlda 15 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 132 Mlda 17 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 132 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 132 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 132 Mlda 21 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 132 Mlda 23 Accuracy 0.8173076923076923\n",
            "Mpca 132 Mlda 24 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 132 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 132 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 132 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 132 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 132 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 132 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 132 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 132 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 132 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 132 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 132 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 132 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 132 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 132 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 132 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 132 Mlda 44 Accuracy 0.8942307692307693\n",
            "Mpca 132 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 132 Mlda 46 Accuracy 0.8846153846153846\n",
            "Mpca 132 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 132 Mlda 48 Accuracy 0.875\n",
            "Mpca 132 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 132 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 133 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 133 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 133 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 133 Mlda 4 Accuracy 0.4423076923076923\n",
            "Mpca 133 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 133 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 133 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 133 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 133 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 133 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 133 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 133 Mlda 12 Accuracy 0.75\n",
            "Mpca 133 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 133 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 133 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 133 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 133 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 133 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 133 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 133 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 133 Mlda 21 Accuracy 0.8365384615384616\n",
            "Mpca 133 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 133 Mlda 23 Accuracy 0.8173076923076923\n",
            "Mpca 133 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 133 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 133 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 133 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 133 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 133 Mlda 29 Accuracy 0.8461538461538461\n",
            "Mpca 133 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 133 Mlda 31 Accuracy 0.8557692307692307\n",
            "Mpca 133 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 133 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 133 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 133 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 133 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 133 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 133 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 133 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 133 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 133 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 133 Mlda 42 Accuracy 0.8846153846153846\n",
            "Mpca 133 Mlda 43 Accuracy 0.8942307692307693\n",
            "Mpca 133 Mlda 44 Accuracy 0.8942307692307693\n",
            "Mpca 133 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 133 Mlda 46 Accuracy 0.8942307692307693\n",
            "Mpca 133 Mlda 47 Accuracy 0.8846153846153846\n",
            "Mpca 133 Mlda 48 Accuracy 0.8942307692307693\n",
            "Mpca 133 Mlda 49 Accuracy 0.8942307692307693\n",
            "Mpca 133 Mlda 50 Accuracy 0.8942307692307693\n",
            "Mpca 134 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 134 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 134 Mlda 3 Accuracy 0.3173076923076923\n",
            "Mpca 134 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 134 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 134 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 134 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 134 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 134 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 134 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 134 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 134 Mlda 12 Accuracy 0.7596153846153846\n",
            "Mpca 134 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 134 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 134 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 134 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 134 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 134 Mlda 18 Accuracy 0.8269230769230769\n",
            "Mpca 134 Mlda 19 Accuracy 0.8269230769230769\n",
            "Mpca 134 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 134 Mlda 21 Accuracy 0.8269230769230769\n",
            "Mpca 134 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 134 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 134 Mlda 24 Accuracy 0.8365384615384616\n",
            "Mpca 134 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 134 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 134 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 134 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 134 Mlda 29 Accuracy 0.8461538461538461\n",
            "Mpca 134 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 134 Mlda 31 Accuracy 0.8557692307692307\n",
            "Mpca 134 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 134 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 134 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 134 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 134 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 134 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 134 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 134 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 134 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 134 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 134 Mlda 42 Accuracy 0.8846153846153846\n",
            "Mpca 134 Mlda 43 Accuracy 0.8846153846153846\n",
            "Mpca 134 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 134 Mlda 45 Accuracy 0.8942307692307693\n",
            "Mpca 134 Mlda 46 Accuracy 0.8942307692307693\n",
            "Mpca 134 Mlda 47 Accuracy 0.8942307692307693\n",
            "Mpca 134 Mlda 48 Accuracy 0.8942307692307693\n",
            "Mpca 134 Mlda 49 Accuracy 0.8942307692307693\n",
            "Mpca 134 Mlda 50 Accuracy 0.9038461538461539\n",
            "Mpca 135 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 135 Mlda 2 Accuracy 0.125\n",
            "Mpca 135 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 135 Mlda 4 Accuracy 0.4230769230769231\n",
            "Mpca 135 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 135 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 135 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 135 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 135 Mlda 9 Accuracy 0.6730769230769231\n",
            "Mpca 135 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 135 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 135 Mlda 12 Accuracy 0.7692307692307693\n",
            "Mpca 135 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 135 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 135 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 135 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 135 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 135 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 135 Mlda 19 Accuracy 0.8269230769230769\n",
            "Mpca 135 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 135 Mlda 21 Accuracy 0.8269230769230769\n",
            "Mpca 135 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 135 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 135 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 135 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 135 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 135 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 135 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 135 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 135 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 135 Mlda 31 Accuracy 0.8653846153846154\n",
            "Mpca 135 Mlda 32 Accuracy 0.8653846153846154\n",
            "Mpca 135 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 135 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 135 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 135 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 135 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 135 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 135 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 135 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 135 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 135 Mlda 42 Accuracy 0.8846153846153846\n",
            "Mpca 135 Mlda 43 Accuracy 0.875\n",
            "Mpca 135 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 135 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 135 Mlda 46 Accuracy 0.8846153846153846\n",
            "Mpca 135 Mlda 47 Accuracy 0.8942307692307693\n",
            "Mpca 135 Mlda 48 Accuracy 0.8942307692307693\n",
            "Mpca 135 Mlda 49 Accuracy 0.8942307692307693\n",
            "Mpca 135 Mlda 50 Accuracy 0.8942307692307693\n",
            "Mpca 136 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 136 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 136 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 136 Mlda 4 Accuracy 0.41346153846153844\n",
            "Mpca 136 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 136 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 136 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 136 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 136 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 136 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 136 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 136 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 136 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 136 Mlda 14 Accuracy 0.7788461538461539\n",
            "Mpca 136 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 136 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 136 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 136 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 136 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 136 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 136 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 136 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 136 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 136 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 136 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 136 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 136 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 136 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 136 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 136 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 136 Mlda 31 Accuracy 0.8557692307692307\n",
            "Mpca 136 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 136 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 136 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 136 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 136 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 136 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 136 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 136 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 136 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 136 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 136 Mlda 42 Accuracy 0.8846153846153846\n",
            "Mpca 136 Mlda 43 Accuracy 0.8846153846153846\n",
            "Mpca 136 Mlda 44 Accuracy 0.875\n",
            "Mpca 136 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 136 Mlda 46 Accuracy 0.8846153846153846\n",
            "Mpca 136 Mlda 47 Accuracy 0.8942307692307693\n",
            "Mpca 136 Mlda 48 Accuracy 0.9038461538461539\n",
            "Mpca 136 Mlda 49 Accuracy 0.8942307692307693\n",
            "Mpca 136 Mlda 50 Accuracy 0.8942307692307693\n",
            "Mpca 137 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 137 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 137 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 137 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 137 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 137 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 137 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 137 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 137 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 137 Mlda 10 Accuracy 0.625\n",
            "Mpca 137 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 137 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 137 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 137 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 137 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 137 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 137 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 137 Mlda 18 Accuracy 0.8269230769230769\n",
            "Mpca 137 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 137 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 137 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 137 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 137 Mlda 23 Accuracy 0.8365384615384616\n",
            "Mpca 137 Mlda 24 Accuracy 0.8269230769230769\n",
            "Mpca 137 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 137 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 137 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 137 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 137 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 137 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 137 Mlda 31 Accuracy 0.8557692307692307\n",
            "Mpca 137 Mlda 32 Accuracy 0.8557692307692307\n",
            "Mpca 137 Mlda 33 Accuracy 0.8653846153846154\n",
            "Mpca 137 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 137 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 137 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 137 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 137 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 137 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 137 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 137 Mlda 41 Accuracy 0.8653846153846154\n",
            "Mpca 137 Mlda 42 Accuracy 0.875\n",
            "Mpca 137 Mlda 43 Accuracy 0.8846153846153846\n",
            "Mpca 137 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 137 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 137 Mlda 46 Accuracy 0.875\n",
            "Mpca 137 Mlda 47 Accuracy 0.8942307692307693\n",
            "Mpca 137 Mlda 48 Accuracy 0.8942307692307693\n",
            "Mpca 137 Mlda 49 Accuracy 0.8942307692307693\n",
            "Mpca 137 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 138 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 138 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 138 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 138 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 138 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 138 Mlda 6 Accuracy 0.5\n",
            "Mpca 138 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 138 Mlda 8 Accuracy 0.625\n",
            "Mpca 138 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 138 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 138 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 138 Mlda 12 Accuracy 0.7692307692307693\n",
            "Mpca 138 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 138 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 138 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 138 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 138 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 138 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 138 Mlda 19 Accuracy 0.8269230769230769\n",
            "Mpca 138 Mlda 20 Accuracy 0.8269230769230769\n",
            "Mpca 138 Mlda 21 Accuracy 0.8365384615384616\n",
            "Mpca 138 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 138 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 138 Mlda 24 Accuracy 0.8461538461538461\n",
            "Mpca 138 Mlda 25 Accuracy 0.8461538461538461\n",
            "Mpca 138 Mlda 26 Accuracy 0.8365384615384616\n",
            "Mpca 138 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 138 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 138 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 138 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 138 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 138 Mlda 32 Accuracy 0.8557692307692307\n",
            "Mpca 138 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 138 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 138 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 138 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 138 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 138 Mlda 38 Accuracy 0.875\n",
            "Mpca 138 Mlda 39 Accuracy 0.875\n",
            "Mpca 138 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 138 Mlda 41 Accuracy 0.875\n",
            "Mpca 138 Mlda 42 Accuracy 0.875\n",
            "Mpca 138 Mlda 43 Accuracy 0.8846153846153846\n",
            "Mpca 138 Mlda 44 Accuracy 0.8846153846153846\n",
            "Mpca 138 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 138 Mlda 46 Accuracy 0.8846153846153846\n",
            "Mpca 138 Mlda 47 Accuracy 0.8846153846153846\n",
            "Mpca 138 Mlda 48 Accuracy 0.8942307692307693\n",
            "Mpca 138 Mlda 49 Accuracy 0.9038461538461539\n",
            "Mpca 138 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 139 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 139 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 139 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 139 Mlda 4 Accuracy 0.41346153846153844\n",
            "Mpca 139 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 139 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 139 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 139 Mlda 8 Accuracy 0.6346153846153846\n",
            "Mpca 139 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 139 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 139 Mlda 11 Accuracy 0.7211538461538461\n",
            "Mpca 139 Mlda 12 Accuracy 0.7596153846153846\n",
            "Mpca 139 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 139 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 139 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 139 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 139 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 139 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 139 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 139 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 139 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 139 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 139 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 139 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 139 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 139 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 139 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 139 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 139 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 139 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 139 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 139 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 139 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 139 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 139 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 139 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 139 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 139 Mlda 38 Accuracy 0.875\n",
            "Mpca 139 Mlda 39 Accuracy 0.875\n",
            "Mpca 139 Mlda 40 Accuracy 0.875\n",
            "Mpca 139 Mlda 41 Accuracy 0.875\n",
            "Mpca 139 Mlda 42 Accuracy 0.875\n",
            "Mpca 139 Mlda 43 Accuracy 0.875\n",
            "Mpca 139 Mlda 44 Accuracy 0.875\n",
            "Mpca 139 Mlda 45 Accuracy 0.875\n",
            "Mpca 139 Mlda 46 Accuracy 0.8846153846153846\n",
            "Mpca 139 Mlda 47 Accuracy 0.8846153846153846\n",
            "Mpca 139 Mlda 48 Accuracy 0.8846153846153846\n",
            "Mpca 139 Mlda 49 Accuracy 0.8942307692307693\n",
            "Mpca 139 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 140 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 140 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 140 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 140 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 140 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 140 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 140 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 140 Mlda 8 Accuracy 0.6346153846153846\n",
            "Mpca 140 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 140 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 140 Mlda 11 Accuracy 0.75\n",
            "Mpca 140 Mlda 12 Accuracy 0.7596153846153846\n",
            "Mpca 140 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 140 Mlda 14 Accuracy 0.8173076923076923\n",
            "Mpca 140 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 140 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 140 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 140 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 140 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 140 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 140 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 140 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 140 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 140 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 140 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 140 Mlda 26 Accuracy 0.8461538461538461\n",
            "Mpca 140 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 140 Mlda 28 Accuracy 0.8461538461538461\n",
            "Mpca 140 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 140 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 140 Mlda 31 Accuracy 0.8461538461538461\n",
            "Mpca 140 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 140 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 140 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 140 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 140 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 140 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 140 Mlda 38 Accuracy 0.875\n",
            "Mpca 140 Mlda 39 Accuracy 0.875\n",
            "Mpca 140 Mlda 40 Accuracy 0.875\n",
            "Mpca 140 Mlda 41 Accuracy 0.875\n",
            "Mpca 140 Mlda 42 Accuracy 0.875\n",
            "Mpca 140 Mlda 43 Accuracy 0.8846153846153846\n",
            "Mpca 140 Mlda 44 Accuracy 0.8846153846153846\n",
            "Mpca 140 Mlda 45 Accuracy 0.875\n",
            "Mpca 140 Mlda 46 Accuracy 0.8942307692307693\n",
            "Mpca 140 Mlda 47 Accuracy 0.8942307692307693\n",
            "Mpca 140 Mlda 48 Accuracy 0.8942307692307693\n",
            "Mpca 140 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 140 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 141 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 141 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 141 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 141 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 141 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 141 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 141 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 141 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 141 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 141 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 141 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 141 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 141 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 141 Mlda 14 Accuracy 0.7788461538461539\n",
            "Mpca 141 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 141 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 141 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 141 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 141 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 141 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 141 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 141 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 141 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 141 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 141 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 141 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 141 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 141 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 141 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 141 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 141 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 141 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 141 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 141 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 141 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 141 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 141 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 141 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 141 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 141 Mlda 40 Accuracy 0.875\n",
            "Mpca 141 Mlda 41 Accuracy 0.8653846153846154\n",
            "Mpca 141 Mlda 42 Accuracy 0.875\n",
            "Mpca 141 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 141 Mlda 44 Accuracy 0.875\n",
            "Mpca 141 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 141 Mlda 46 Accuracy 0.8846153846153846\n",
            "Mpca 141 Mlda 47 Accuracy 0.8942307692307693\n",
            "Mpca 141 Mlda 48 Accuracy 0.8846153846153846\n",
            "Mpca 141 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 141 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 142 Mlda 1 Accuracy 0.009615384615384616\n",
            "Mpca 142 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 142 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 142 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 142 Mlda 5 Accuracy 0.375\n",
            "Mpca 142 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 142 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 142 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 142 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 142 Mlda 10 Accuracy 0.625\n",
            "Mpca 142 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 142 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 142 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 142 Mlda 14 Accuracy 0.7692307692307693\n",
            "Mpca 142 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 142 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 142 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 142 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 142 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 142 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 142 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 142 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 142 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 142 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 142 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 142 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 142 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 142 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 142 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 142 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 142 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 142 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 142 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 142 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 142 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 142 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 142 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 142 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 142 Mlda 39 Accuracy 0.875\n",
            "Mpca 142 Mlda 40 Accuracy 0.875\n",
            "Mpca 142 Mlda 41 Accuracy 0.875\n",
            "Mpca 142 Mlda 42 Accuracy 0.875\n",
            "Mpca 142 Mlda 43 Accuracy 0.875\n",
            "Mpca 142 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 142 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 142 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 142 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 142 Mlda 48 Accuracy 0.875\n",
            "Mpca 142 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 142 Mlda 50 Accuracy 0.875\n",
            "Mpca 143 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 143 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 143 Mlda 3 Accuracy 0.25\n",
            "Mpca 143 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 143 Mlda 5 Accuracy 0.375\n",
            "Mpca 143 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 143 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 143 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 143 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 143 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 143 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 143 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 143 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 143 Mlda 14 Accuracy 0.7788461538461539\n",
            "Mpca 143 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 143 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 143 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 143 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 143 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 143 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 143 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 143 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 143 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 143 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 143 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 143 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 143 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 143 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 143 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 143 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 143 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 143 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 143 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 143 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 143 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 143 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 143 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 143 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 143 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 143 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 143 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 143 Mlda 42 Accuracy 0.875\n",
            "Mpca 143 Mlda 43 Accuracy 0.875\n",
            "Mpca 143 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 143 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 143 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 143 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 143 Mlda 48 Accuracy 0.875\n",
            "Mpca 143 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 143 Mlda 50 Accuracy 0.875\n",
            "Mpca 144 Mlda 1 Accuracy 0.009615384615384616\n",
            "Mpca 144 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 144 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 144 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 144 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 144 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 144 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 144 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 144 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 144 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 144 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 144 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 144 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 144 Mlda 14 Accuracy 0.7692307692307693\n",
            "Mpca 144 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 144 Mlda 16 Accuracy 0.7884615384615384\n",
            "Mpca 144 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 144 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 144 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 144 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 144 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 144 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 144 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 144 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 144 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 144 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 144 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 144 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 144 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 144 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 144 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 144 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 144 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 144 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 144 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 144 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 144 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 144 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 144 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 144 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 144 Mlda 41 Accuracy 0.8653846153846154\n",
            "Mpca 144 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 144 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 144 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 144 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 144 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 144 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 144 Mlda 48 Accuracy 0.875\n",
            "Mpca 144 Mlda 49 Accuracy 0.875\n",
            "Mpca 144 Mlda 50 Accuracy 0.875\n",
            "Mpca 145 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 145 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 145 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 145 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 145 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 145 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 145 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 145 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 145 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 145 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 145 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 145 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 145 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 145 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 145 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 145 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 145 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 145 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 145 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 145 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 145 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 145 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 145 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 145 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 145 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 145 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 145 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 145 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 145 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 145 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 145 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 145 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 145 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 145 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 145 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 145 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 145 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 145 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 145 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 145 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 145 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 145 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 145 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 145 Mlda 44 Accuracy 0.875\n",
            "Mpca 145 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 145 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 145 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 145 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 145 Mlda 49 Accuracy 0.875\n",
            "Mpca 145 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 146 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 146 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 146 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 146 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 146 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 146 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 146 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 146 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 146 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 146 Mlda 10 Accuracy 0.625\n",
            "Mpca 146 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 146 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 146 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 146 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 146 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 146 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 146 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 146 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 146 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 146 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 146 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 146 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 146 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 146 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 146 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 146 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 146 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 146 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 146 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 146 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 146 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 146 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 146 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 146 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 146 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 146 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 146 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 146 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 146 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 146 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 146 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 146 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 146 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 146 Mlda 44 Accuracy 0.8846153846153846\n",
            "Mpca 146 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 146 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 146 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 146 Mlda 48 Accuracy 0.8846153846153846\n",
            "Mpca 146 Mlda 49 Accuracy 0.875\n",
            "Mpca 146 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 147 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 147 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 147 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 147 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 147 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 147 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 147 Mlda 7 Accuracy 0.5\n",
            "Mpca 147 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 147 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 147 Mlda 10 Accuracy 0.625\n",
            "Mpca 147 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 147 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 147 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 147 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 147 Mlda 15 Accuracy 0.75\n",
            "Mpca 147 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 147 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 147 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 147 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 147 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 147 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 147 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 147 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 147 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 147 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 147 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 147 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 147 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 147 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 147 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 147 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 147 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 147 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 147 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 147 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 147 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 147 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 147 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 147 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 147 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 147 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 147 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 147 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 147 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 147 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 147 Mlda 46 Accuracy 0.875\n",
            "Mpca 147 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 147 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 147 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 147 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 148 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 148 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 148 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 148 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 148 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 148 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 148 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 148 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 148 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 148 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 148 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 148 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 148 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 148 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 148 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 148 Mlda 16 Accuracy 0.75\n",
            "Mpca 148 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 148 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 148 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 148 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 148 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 148 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 148 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 148 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 148 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 148 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 148 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 148 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 148 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 148 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 148 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 148 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 148 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 148 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 148 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 148 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 148 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 148 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 148 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 148 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 148 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 148 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 148 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 148 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 148 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 148 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 148 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 148 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 148 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 148 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 149 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 149 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 149 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 149 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 149 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 149 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 149 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 149 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 149 Mlda 9 Accuracy 0.625\n",
            "Mpca 149 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 149 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 149 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 149 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 149 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 149 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 149 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 149 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 149 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 149 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 149 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 149 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 149 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 149 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 149 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 149 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 149 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 149 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 149 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 149 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 149 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 149 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 149 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 149 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 149 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 149 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 149 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 149 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 149 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 149 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 149 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 149 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 149 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 149 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 149 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 149 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 149 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 149 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 149 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 149 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 149 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 150 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 150 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 150 Mlda 3 Accuracy 0.25\n",
            "Mpca 150 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 150 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 150 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 150 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 150 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 150 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 150 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 150 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 150 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 150 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 150 Mlda 14 Accuracy 0.7692307692307693\n",
            "Mpca 150 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 150 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 150 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 150 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 150 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 150 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 150 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 150 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 150 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 150 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 150 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 150 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 150 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 150 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 150 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 150 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 150 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 150 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 150 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 150 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 150 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 150 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 150 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 150 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 150 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 150 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 150 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 150 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 150 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 150 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 150 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 150 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 150 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 150 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 150 Mlda 49 Accuracy 0.875\n",
            "Mpca 150 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 151 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 151 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 151 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 151 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 151 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 151 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 151 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 151 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 151 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 151 Mlda 10 Accuracy 0.625\n",
            "Mpca 151 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 151 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 151 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 151 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 151 Mlda 15 Accuracy 0.75\n",
            "Mpca 151 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 151 Mlda 17 Accuracy 0.75\n",
            "Mpca 151 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 151 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 151 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 151 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 151 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 151 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 151 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 151 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 151 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 151 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 151 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 151 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 151 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 151 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 151 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 151 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 151 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 151 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 151 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 151 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 151 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 151 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 151 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 151 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 151 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 151 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 151 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 151 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 151 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 151 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 151 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 151 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 151 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 152 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 152 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 152 Mlda 3 Accuracy 0.25\n",
            "Mpca 152 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 152 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 152 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 152 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 152 Mlda 8 Accuracy 0.625\n",
            "Mpca 152 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 152 Mlda 10 Accuracy 0.625\n",
            "Mpca 152 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 152 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 152 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 152 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 152 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 152 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 152 Mlda 17 Accuracy 0.75\n",
            "Mpca 152 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 152 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 152 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 152 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 152 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 152 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 152 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 152 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 152 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 152 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 152 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 152 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 152 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 152 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 152 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 152 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 152 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 152 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 152 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 152 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 152 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 152 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 152 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 152 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 152 Mlda 49 Accuracy 0.875\n",
            "Mpca 152 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 153 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 153 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 153 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 153 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 153 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 153 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 153 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 153 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 153 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 153 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 153 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 153 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 153 Mlda 13 Accuracy 0.75\n",
            "Mpca 153 Mlda 14 Accuracy 0.7788461538461539\n",
            "Mpca 153 Mlda 15 Accuracy 0.7788461538461539\n",
            "Mpca 153 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 153 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 153 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 153 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 153 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 153 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 153 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 153 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 153 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 153 Mlda 25 Accuracy 0.8269230769230769\n",
            "Mpca 153 Mlda 26 Accuracy 0.8269230769230769\n",
            "Mpca 153 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 153 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 153 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 153 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 153 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 153 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 153 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 153 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 153 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 153 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 153 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 153 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 153 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 153 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 153 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 153 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 153 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 153 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 153 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 153 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 153 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 153 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 153 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 153 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 154 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 154 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 154 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 154 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 154 Mlda 5 Accuracy 0.375\n",
            "Mpca 154 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 154 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 154 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 154 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 154 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 154 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 154 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 154 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 154 Mlda 14 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 154 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 17 Accuracy 0.7980769230769231\n",
            "Mpca 154 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 154 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 154 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 154 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 154 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 154 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 154 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 154 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 154 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 154 Mlda 32 Accuracy 0.8557692307692307\n",
            "Mpca 154 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 154 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 154 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 154 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 154 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 154 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 154 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 154 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 154 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 154 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 154 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 154 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 154 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 154 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 154 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 154 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 154 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 154 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 155 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 155 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 155 Mlda 3 Accuracy 0.25\n",
            "Mpca 155 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 155 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 155 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 155 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 155 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 155 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 155 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 155 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 155 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 155 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 155 Mlda 14 Accuracy 0.8269230769230769\n",
            "Mpca 155 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 155 Mlda 16 Accuracy 0.8076923076923077\n",
            "Mpca 155 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 155 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 155 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 155 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 155 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 155 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 155 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 155 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 155 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 155 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 155 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 155 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 155 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 155 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 155 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 155 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 155 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 155 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 155 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 155 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 155 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 155 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 155 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 156 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 156 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 156 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 156 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 156 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 156 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 156 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 156 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 156 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 156 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 156 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 156 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 156 Mlda 13 Accuracy 0.7980769230769231\n",
            "Mpca 156 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 156 Mlda 15 Accuracy 0.7980769230769231\n",
            "Mpca 156 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 156 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 156 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 156 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 156 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 156 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 156 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 156 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 156 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 156 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 156 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 156 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 28 Accuracy 0.8461538461538461\n",
            "Mpca 156 Mlda 29 Accuracy 0.8557692307692307\n",
            "Mpca 156 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 156 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 156 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 156 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 156 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 156 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 156 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 156 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 156 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 156 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 156 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 156 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 156 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 156 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 156 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 157 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 157 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 157 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 157 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 157 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 157 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 157 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 157 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 157 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 157 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 157 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 157 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 157 Mlda 13 Accuracy 0.8076923076923077\n",
            "Mpca 157 Mlda 14 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 15 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 16 Accuracy 0.8365384615384616\n",
            "Mpca 157 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 18 Accuracy 0.8076923076923077\n",
            "Mpca 157 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 157 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 157 Mlda 23 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 157 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 157 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 157 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 157 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 157 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 157 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 157 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 157 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 157 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 157 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 157 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 157 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 157 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 157 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 157 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 157 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 157 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 157 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 157 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 157 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 157 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 157 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 157 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 158 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 158 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 158 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 158 Mlda 4 Accuracy 0.375\n",
            "Mpca 158 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 158 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 158 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 158 Mlda 8 Accuracy 0.625\n",
            "Mpca 158 Mlda 9 Accuracy 0.625\n",
            "Mpca 158 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 158 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 158 Mlda 12 Accuracy 0.75\n",
            "Mpca 158 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 158 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 158 Mlda 15 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 158 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 19 Accuracy 0.8269230769230769\n",
            "Mpca 158 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 158 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 158 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 158 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 158 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 158 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 158 Mlda 29 Accuracy 0.8461538461538461\n",
            "Mpca 158 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 158 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 158 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 158 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 158 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 158 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 158 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 158 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 158 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 158 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 158 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 158 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 158 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 158 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 158 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 158 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 158 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 158 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 158 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 158 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 159 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 159 Mlda 2 Accuracy 0.2403846153846154\n",
            "Mpca 159 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 159 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 159 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 159 Mlda 6 Accuracy 0.5\n",
            "Mpca 159 Mlda 7 Accuracy 0.5961538461538461\n",
            "Mpca 159 Mlda 8 Accuracy 0.6538461538461539\n",
            "Mpca 159 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 159 Mlda 10 Accuracy 0.6923076923076923\n",
            "Mpca 159 Mlda 11 Accuracy 0.7403846153846154\n",
            "Mpca 159 Mlda 12 Accuracy 0.7788461538461539\n",
            "Mpca 159 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 159 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 159 Mlda 15 Accuracy 0.8173076923076923\n",
            "Mpca 159 Mlda 16 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 17 Accuracy 0.8365384615384616\n",
            "Mpca 159 Mlda 18 Accuracy 0.8269230769230769\n",
            "Mpca 159 Mlda 19 Accuracy 0.8269230769230769\n",
            "Mpca 159 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 159 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 159 Mlda 22 Accuracy 0.8173076923076923\n",
            "Mpca 159 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 159 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 159 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 159 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 159 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 159 Mlda 28 Accuracy 0.8365384615384616\n",
            "Mpca 159 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 159 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 159 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 159 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 159 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 159 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 159 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 159 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 159 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 159 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 159 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 159 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 159 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 159 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 159 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 159 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 160 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 160 Mlda 2 Accuracy 0.21153846153846154\n",
            "Mpca 160 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 160 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 160 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 160 Mlda 6 Accuracy 0.5576923076923077\n",
            "Mpca 160 Mlda 7 Accuracy 0.6153846153846154\n",
            "Mpca 160 Mlda 8 Accuracy 0.6826923076923077\n",
            "Mpca 160 Mlda 9 Accuracy 0.6538461538461539\n",
            "Mpca 160 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 160 Mlda 11 Accuracy 0.7115384615384616\n",
            "Mpca 160 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 160 Mlda 13 Accuracy 0.7596153846153846\n",
            "Mpca 160 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 160 Mlda 15 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 160 Mlda 17 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 18 Accuracy 0.8269230769230769\n",
            "Mpca 160 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 160 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 160 Mlda 21 Accuracy 0.8269230769230769\n",
            "Mpca 160 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 160 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 160 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 160 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 160 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 160 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 160 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 160 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 160 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 160 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 160 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 160 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 160 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 160 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 160 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 160 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 160 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 160 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 160 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 160 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 160 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 160 Mlda 48 Accuracy 0.875\n",
            "Mpca 160 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 160 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 161 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 161 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 161 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 161 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 161 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 161 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 161 Mlda 7 Accuracy 0.5769230769230769\n",
            "Mpca 161 Mlda 8 Accuracy 0.6346153846153846\n",
            "Mpca 161 Mlda 9 Accuracy 0.6538461538461539\n",
            "Mpca 161 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 161 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 161 Mlda 12 Accuracy 0.7596153846153846\n",
            "Mpca 161 Mlda 13 Accuracy 0.7692307692307693\n",
            "Mpca 161 Mlda 14 Accuracy 0.7788461538461539\n",
            "Mpca 161 Mlda 15 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 16 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 17 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 18 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 161 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 161 Mlda 21 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 22 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 161 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 161 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 161 Mlda 27 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 28 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 161 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 161 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 161 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 161 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 161 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 161 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 161 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 161 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 161 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 161 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 161 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 161 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 161 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 161 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 161 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 162 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 162 Mlda 2 Accuracy 0.23076923076923078\n",
            "Mpca 162 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 162 Mlda 4 Accuracy 0.4326923076923077\n",
            "Mpca 162 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 162 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 162 Mlda 7 Accuracy 0.5865384615384616\n",
            "Mpca 162 Mlda 8 Accuracy 0.625\n",
            "Mpca 162 Mlda 9 Accuracy 0.6538461538461539\n",
            "Mpca 162 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 162 Mlda 11 Accuracy 0.7403846153846154\n",
            "Mpca 162 Mlda 12 Accuracy 0.75\n",
            "Mpca 162 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 162 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 162 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 162 Mlda 16 Accuracy 0.8557692307692307\n",
            "Mpca 162 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 162 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 162 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 162 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 162 Mlda 21 Accuracy 0.8173076923076923\n",
            "Mpca 162 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 162 Mlda 23 Accuracy 0.8269230769230769\n",
            "Mpca 162 Mlda 24 Accuracy 0.8269230769230769\n",
            "Mpca 162 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 162 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 162 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 162 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 162 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 162 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 162 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 162 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 162 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 162 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 162 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 162 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 162 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 162 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 162 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 162 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 162 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 162 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 162 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 162 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 162 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 162 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 162 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 162 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 162 Mlda 49 Accuracy 0.875\n",
            "Mpca 162 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 163 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 163 Mlda 2 Accuracy 0.19230769230769232\n",
            "Mpca 163 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 163 Mlda 4 Accuracy 0.4230769230769231\n",
            "Mpca 163 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 163 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 163 Mlda 7 Accuracy 0.5769230769230769\n",
            "Mpca 163 Mlda 8 Accuracy 0.6346153846153846\n",
            "Mpca 163 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 163 Mlda 10 Accuracy 0.6923076923076923\n",
            "Mpca 163 Mlda 11 Accuracy 0.75\n",
            "Mpca 163 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 163 Mlda 13 Accuracy 0.7788461538461539\n",
            "Mpca 163 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 163 Mlda 15 Accuracy 0.8269230769230769\n",
            "Mpca 163 Mlda 16 Accuracy 0.8557692307692307\n",
            "Mpca 163 Mlda 17 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 18 Accuracy 0.8269230769230769\n",
            "Mpca 163 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 163 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 163 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 163 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 163 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 163 Mlda 24 Accuracy 0.8173076923076923\n",
            "Mpca 163 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 163 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 163 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 163 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 163 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 163 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 163 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 163 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 163 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 163 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 163 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 163 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 163 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 163 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 163 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 163 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 163 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 163 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 163 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 163 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 164 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 164 Mlda 2 Accuracy 0.19230769230769232\n",
            "Mpca 164 Mlda 3 Accuracy 0.25\n",
            "Mpca 164 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 164 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 164 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 164 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 164 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 164 Mlda 9 Accuracy 0.6538461538461539\n",
            "Mpca 164 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 164 Mlda 11 Accuracy 0.7307692307692307\n",
            "Mpca 164 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 164 Mlda 13 Accuracy 0.7980769230769231\n",
            "Mpca 164 Mlda 14 Accuracy 0.7788461538461539\n",
            "Mpca 164 Mlda 15 Accuracy 0.8173076923076923\n",
            "Mpca 164 Mlda 16 Accuracy 0.8269230769230769\n",
            "Mpca 164 Mlda 17 Accuracy 0.8269230769230769\n",
            "Mpca 164 Mlda 18 Accuracy 0.8269230769230769\n",
            "Mpca 164 Mlda 19 Accuracy 0.8173076923076923\n",
            "Mpca 164 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 164 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 164 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 164 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 164 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 164 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 164 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 164 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 164 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 164 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 164 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 164 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 164 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 164 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 164 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 164 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 164 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 164 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 164 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 164 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 164 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 164 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 164 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 164 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 164 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 164 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 164 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 164 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 164 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 164 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 164 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 165 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 165 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 165 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 165 Mlda 4 Accuracy 0.4326923076923077\n",
            "Mpca 165 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 165 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 165 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 165 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 165 Mlda 9 Accuracy 0.625\n",
            "Mpca 165 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 165 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 165 Mlda 12 Accuracy 0.7596153846153846\n",
            "Mpca 165 Mlda 13 Accuracy 0.7884615384615384\n",
            "Mpca 165 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 165 Mlda 15 Accuracy 0.8173076923076923\n",
            "Mpca 165 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 165 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 165 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 165 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 165 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 165 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 165 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 165 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 165 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 165 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 165 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 165 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 165 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 165 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 165 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 165 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 165 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 165 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 165 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 165 Mlda 35 Accuracy 0.875\n",
            "Mpca 165 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 165 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 165 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 165 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 165 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 165 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 165 Mlda 42 Accuracy 0.875\n",
            "Mpca 165 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 165 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 165 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 165 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 165 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 165 Mlda 48 Accuracy 0.875\n",
            "Mpca 165 Mlda 49 Accuracy 0.875\n",
            "Mpca 165 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 166 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 166 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 166 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 166 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 166 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 166 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 166 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 166 Mlda 9 Accuracy 0.625\n",
            "Mpca 166 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 166 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 166 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 166 Mlda 13 Accuracy 0.75\n",
            "Mpca 166 Mlda 14 Accuracy 0.7980769230769231\n",
            "Mpca 166 Mlda 15 Accuracy 0.8269230769230769\n",
            "Mpca 166 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 166 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 166 Mlda 18 Accuracy 0.8173076923076923\n",
            "Mpca 166 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 166 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 166 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 166 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 166 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 166 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 166 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 166 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 166 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 166 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 166 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 166 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 166 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 166 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 166 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 166 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 166 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 166 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 166 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 41 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 45 Accuracy 0.875\n",
            "Mpca 166 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 166 Mlda 47 Accuracy 0.875\n",
            "Mpca 166 Mlda 48 Accuracy 0.875\n",
            "Mpca 166 Mlda 49 Accuracy 0.875\n",
            "Mpca 166 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 167 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 167 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 167 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 167 Mlda 5 Accuracy 0.47115384615384615\n",
            "Mpca 167 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 167 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 167 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 167 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 167 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 167 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 167 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 167 Mlda 13 Accuracy 0.75\n",
            "Mpca 167 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 167 Mlda 15 Accuracy 0.8076923076923077\n",
            "Mpca 167 Mlda 16 Accuracy 0.8173076923076923\n",
            "Mpca 167 Mlda 17 Accuracy 0.8173076923076923\n",
            "Mpca 167 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 167 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 167 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 167 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 167 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 167 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 167 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 167 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 167 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 167 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 167 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 167 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 167 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 167 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 167 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 167 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 167 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 167 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 37 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 167 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 167 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 167 Mlda 43 Accuracy 0.875\n",
            "Mpca 167 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 45 Accuracy 0.875\n",
            "Mpca 167 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 167 Mlda 47 Accuracy 0.875\n",
            "Mpca 167 Mlda 48 Accuracy 0.8846153846153846\n",
            "Mpca 167 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 167 Mlda 50 Accuracy 0.875\n",
            "Mpca 168 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 168 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 168 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 168 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 168 Mlda 5 Accuracy 0.5\n",
            "Mpca 168 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 168 Mlda 7 Accuracy 0.5865384615384616\n",
            "Mpca 168 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 168 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 168 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 168 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 168 Mlda 12 Accuracy 0.75\n",
            "Mpca 168 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 168 Mlda 14 Accuracy 0.7884615384615384\n",
            "Mpca 168 Mlda 15 Accuracy 0.7884615384615384\n",
            "Mpca 168 Mlda 16 Accuracy 0.7980769230769231\n",
            "Mpca 168 Mlda 17 Accuracy 0.8076923076923077\n",
            "Mpca 168 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 168 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 168 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 168 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 168 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 168 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 168 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 168 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 168 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 168 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 168 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 168 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 168 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 168 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 168 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 168 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 168 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 168 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 168 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 168 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 168 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 168 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 168 Mlda 47 Accuracy 0.8846153846153846\n",
            "Mpca 168 Mlda 48 Accuracy 0.8942307692307693\n",
            "Mpca 168 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 168 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 169 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 169 Mlda 2 Accuracy 0.22115384615384615\n",
            "Mpca 169 Mlda 3 Accuracy 0.25\n",
            "Mpca 169 Mlda 4 Accuracy 0.375\n",
            "Mpca 169 Mlda 5 Accuracy 0.5288461538461539\n",
            "Mpca 169 Mlda 6 Accuracy 0.5192307692307693\n",
            "Mpca 169 Mlda 7 Accuracy 0.5961538461538461\n",
            "Mpca 169 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 169 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 169 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 169 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 169 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 169 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 169 Mlda 14 Accuracy 0.75\n",
            "Mpca 169 Mlda 15 Accuracy 0.75\n",
            "Mpca 169 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 169 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 169 Mlda 18 Accuracy 0.7980769230769231\n",
            "Mpca 169 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 169 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 169 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 169 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 169 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 169 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 169 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 169 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 169 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 169 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 169 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 169 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 169 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 169 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 169 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 169 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 169 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 169 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 169 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 169 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 169 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 169 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 169 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 169 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 169 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 169 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 169 Mlda 45 Accuracy 0.875\n",
            "Mpca 169 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 169 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 169 Mlda 48 Accuracy 0.875\n",
            "Mpca 169 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 169 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 170 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 170 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 170 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 170 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 170 Mlda 5 Accuracy 0.5192307692307693\n",
            "Mpca 170 Mlda 6 Accuracy 0.5192307692307693\n",
            "Mpca 170 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 170 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 170 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 170 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 170 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 170 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 170 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 170 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 170 Mlda 15 Accuracy 0.7980769230769231\n",
            "Mpca 170 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 170 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 170 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 170 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 170 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 170 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 170 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 170 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 170 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 170 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 170 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 170 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 170 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 170 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 170 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 170 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 170 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 170 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 170 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 170 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 170 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 170 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 170 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 170 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 170 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 170 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 170 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 170 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 170 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 170 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 170 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 170 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 170 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 170 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 170 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 171 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 171 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 171 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 171 Mlda 4 Accuracy 0.4230769230769231\n",
            "Mpca 171 Mlda 5 Accuracy 0.5\n",
            "Mpca 171 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 171 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 171 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 171 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 171 Mlda 10 Accuracy 0.625\n",
            "Mpca 171 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 171 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 171 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 171 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 171 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 171 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 171 Mlda 17 Accuracy 0.75\n",
            "Mpca 171 Mlda 18 Accuracy 0.75\n",
            "Mpca 171 Mlda 19 Accuracy 0.75\n",
            "Mpca 171 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 171 Mlda 21 Accuracy 0.75\n",
            "Mpca 171 Mlda 22 Accuracy 0.75\n",
            "Mpca 171 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 171 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 171 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 171 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 171 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 171 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 171 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 171 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 171 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 171 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 171 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 171 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 171 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 171 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 171 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 171 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 171 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 171 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 171 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 171 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 171 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 171 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 171 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 171 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 171 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 171 Mlda 48 Accuracy 0.875\n",
            "Mpca 171 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 171 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 172 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 172 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 172 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 172 Mlda 4 Accuracy 0.4230769230769231\n",
            "Mpca 172 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 172 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 172 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 172 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 172 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 172 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 172 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 172 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 172 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 172 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 172 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 172 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 172 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 172 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 172 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 172 Mlda 20 Accuracy 0.75\n",
            "Mpca 172 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 172 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 172 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 172 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 172 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 172 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 172 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 172 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 172 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 172 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 172 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 172 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 172 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 172 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 172 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 172 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 172 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 172 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 172 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 172 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 172 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 172 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 172 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 172 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 172 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 172 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 172 Mlda 47 Accuracy 0.875\n",
            "Mpca 172 Mlda 48 Accuracy 0.8846153846153846\n",
            "Mpca 172 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 172 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 173 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 173 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 173 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 173 Mlda 4 Accuracy 0.40384615384615385\n",
            "Mpca 173 Mlda 5 Accuracy 0.4807692307692308\n",
            "Mpca 173 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 173 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 173 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 173 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 173 Mlda 10 Accuracy 0.625\n",
            "Mpca 173 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 173 Mlda 12 Accuracy 0.7307692307692307\n",
            "Mpca 173 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 173 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 173 Mlda 15 Accuracy 0.75\n",
            "Mpca 173 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 173 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 173 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 173 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 173 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 173 Mlda 21 Accuracy 0.75\n",
            "Mpca 173 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 173 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 173 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 173 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 173 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 173 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 173 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 173 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 173 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 173 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 173 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 173 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 173 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 173 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 173 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 173 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 173 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 173 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 173 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 173 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 173 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 173 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 173 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 173 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 173 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 173 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 173 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 173 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 173 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 174 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 174 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 174 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 174 Mlda 4 Accuracy 0.3942307692307692\n",
            "Mpca 174 Mlda 5 Accuracy 0.47115384615384615\n",
            "Mpca 174 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 174 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 174 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 174 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 174 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 174 Mlda 11 Accuracy 0.625\n",
            "Mpca 174 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 174 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 174 Mlda 14 Accuracy 0.75\n",
            "Mpca 174 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 174 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 174 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 174 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 174 Mlda 19 Accuracy 0.75\n",
            "Mpca 174 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 174 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 174 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 174 Mlda 23 Accuracy 0.75\n",
            "Mpca 174 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 174 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 174 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 174 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 174 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 174 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 174 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 174 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 174 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 174 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 174 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 40 Accuracy 0.7884615384615384\n",
            "Mpca 174 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 174 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 174 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 174 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 174 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 174 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 174 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 174 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 174 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 175 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 175 Mlda 2 Accuracy 0.19230769230769232\n",
            "Mpca 175 Mlda 3 Accuracy 0.3076923076923077\n",
            "Mpca 175 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 175 Mlda 5 Accuracy 0.47115384615384615\n",
            "Mpca 175 Mlda 6 Accuracy 0.375\n",
            "Mpca 175 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 175 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 175 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 175 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 175 Mlda 11 Accuracy 0.5961538461538461\n",
            "Mpca 175 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 175 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 175 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 175 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 175 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 175 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 175 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 175 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 175 Mlda 20 Accuracy 0.75\n",
            "Mpca 175 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 175 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 175 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 175 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 175 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 175 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 175 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 175 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 175 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 175 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 175 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 175 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 175 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 175 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 175 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 175 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 175 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 175 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 175 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 175 Mlda 40 Accuracy 0.7884615384615384\n",
            "Mpca 175 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 175 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 175 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 175 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 175 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 175 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 175 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 175 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 175 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 175 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 176 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 176 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 176 Mlda 3 Accuracy 0.3173076923076923\n",
            "Mpca 176 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 176 Mlda 5 Accuracy 0.46153846153846156\n",
            "Mpca 176 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 176 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 176 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 176 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 176 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 176 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 176 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 176 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 176 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 176 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 176 Mlda 16 Accuracy 0.75\n",
            "Mpca 176 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 176 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 176 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 176 Mlda 20 Accuracy 0.75\n",
            "Mpca 176 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 176 Mlda 22 Accuracy 0.75\n",
            "Mpca 176 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 176 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 176 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 176 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 176 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 176 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 176 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 176 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 176 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 176 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 176 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 176 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 176 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 176 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 176 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 176 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 176 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 176 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 176 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 176 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 176 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 176 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 176 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 176 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 176 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 176 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 176 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 176 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 177 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 177 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 177 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 177 Mlda 4 Accuracy 0.375\n",
            "Mpca 177 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 177 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 177 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 177 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 177 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 177 Mlda 10 Accuracy 0.5673076923076923\n",
            "Mpca 177 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 177 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 177 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 177 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 177 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 177 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 177 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 177 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 177 Mlda 19 Accuracy 0.75\n",
            "Mpca 177 Mlda 20 Accuracy 0.75\n",
            "Mpca 177 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 177 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 177 Mlda 23 Accuracy 0.75\n",
            "Mpca 177 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 177 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 177 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 177 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 177 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 177 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 177 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 177 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 177 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 177 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 177 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 177 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 177 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 177 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 177 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 177 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 177 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 177 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 177 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 177 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 177 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 177 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 177 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 177 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 177 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 177 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 177 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 178 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 178 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 178 Mlda 3 Accuracy 0.25\n",
            "Mpca 178 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 178 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 178 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 178 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 178 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 178 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 178 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 178 Mlda 11 Accuracy 0.5961538461538461\n",
            "Mpca 178 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 178 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 178 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 178 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 178 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 178 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 178 Mlda 18 Accuracy 0.75\n",
            "Mpca 178 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 178 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 178 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 178 Mlda 22 Accuracy 0.75\n",
            "Mpca 178 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 178 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 178 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 178 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 178 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 178 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 178 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 178 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 178 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 178 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 178 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 178 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 178 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 178 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 178 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 178 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 178 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 178 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 178 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 178 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 178 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 178 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 178 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 178 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 178 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 178 Mlda 48 Accuracy 0.875\n",
            "Mpca 178 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 178 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 179 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 179 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 179 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 179 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 179 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 179 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 179 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 179 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 179 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 179 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 179 Mlda 11 Accuracy 0.625\n",
            "Mpca 179 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 179 Mlda 13 Accuracy 0.6538461538461539\n",
            "Mpca 179 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 179 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 179 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 179 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 179 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 179 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 179 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 179 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 179 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 179 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 179 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 179 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 179 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 179 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 179 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 179 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 179 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 179 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 179 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 179 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 179 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 179 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 179 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 179 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 179 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 179 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 179 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 179 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 179 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 179 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 179 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 179 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 179 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 179 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 179 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 179 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 179 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 180 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 180 Mlda 2 Accuracy 0.23076923076923078\n",
            "Mpca 180 Mlda 3 Accuracy 0.25\n",
            "Mpca 180 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 180 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 180 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 180 Mlda 7 Accuracy 0.5\n",
            "Mpca 180 Mlda 8 Accuracy 0.5\n",
            "Mpca 180 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 180 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 180 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 180 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 180 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 180 Mlda 14 Accuracy 0.75\n",
            "Mpca 180 Mlda 15 Accuracy 0.75\n",
            "Mpca 180 Mlda 16 Accuracy 0.75\n",
            "Mpca 180 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 180 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 180 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 180 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 180 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 180 Mlda 22 Accuracy 0.75\n",
            "Mpca 180 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 180 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 180 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 180 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 180 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 180 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 180 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 180 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 180 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 180 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 180 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 180 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 180 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 180 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 180 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 180 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 180 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 180 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 180 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 180 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 180 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 180 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 180 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 180 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 180 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 180 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 180 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 180 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 181 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 181 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 181 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 181 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 181 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 181 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 181 Mlda 7 Accuracy 0.5\n",
            "Mpca 181 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 181 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 181 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 181 Mlda 11 Accuracy 0.625\n",
            "Mpca 181 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 181 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 181 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 181 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 181 Mlda 16 Accuracy 0.75\n",
            "Mpca 181 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 181 Mlda 18 Accuracy 0.75\n",
            "Mpca 181 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 181 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 181 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 181 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 181 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 181 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 181 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 181 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 181 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 181 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 181 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 181 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 181 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 181 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 181 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 181 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 181 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 181 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 181 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 181 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 181 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 181 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 181 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 181 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 181 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 181 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 181 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 181 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 181 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 181 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 181 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 181 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 182 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 182 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 182 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 182 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 182 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 182 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 182 Mlda 7 Accuracy 0.5\n",
            "Mpca 182 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 182 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 182 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 182 Mlda 11 Accuracy 0.625\n",
            "Mpca 182 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 182 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 182 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 182 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 182 Mlda 16 Accuracy 0.75\n",
            "Mpca 182 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 182 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 182 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 182 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 182 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 182 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 182 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 182 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 182 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 182 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 182 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 182 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 182 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 182 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 182 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 182 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 182 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 182 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 182 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 182 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 182 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 182 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 182 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 182 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 182 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 182 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 182 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 182 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 182 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 182 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 182 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 182 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 182 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 182 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 183 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 183 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 183 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 183 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 183 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 183 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 183 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 183 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 183 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 183 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 183 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 183 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 183 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 183 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 183 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 183 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 183 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 183 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 183 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 183 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 183 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 183 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 183 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 183 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 183 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 183 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 183 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 183 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 183 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 183 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 183 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 183 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 183 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 183 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 183 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 183 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 183 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 183 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 183 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 183 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 183 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 183 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 183 Mlda 50 Accuracy 0.875\n",
            "Mpca 184 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 184 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 184 Mlda 3 Accuracy 0.25\n",
            "Mpca 184 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 184 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 184 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 184 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 184 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 184 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 184 Mlda 10 Accuracy 0.5673076923076923\n",
            "Mpca 184 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 184 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 184 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 184 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 184 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 184 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 184 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 184 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 184 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 184 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 184 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 184 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 184 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 184 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 184 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 184 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 184 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 184 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 184 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 184 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 184 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 184 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 184 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 184 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 184 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 184 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 184 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 184 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 184 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 184 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 184 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 184 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 184 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 184 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 184 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 184 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 184 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 184 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 184 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 184 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 185 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 185 Mlda 2 Accuracy 0.125\n",
            "Mpca 185 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 185 Mlda 4 Accuracy 0.375\n",
            "Mpca 185 Mlda 5 Accuracy 0.375\n",
            "Mpca 185 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 185 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 185 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 185 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 185 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 185 Mlda 11 Accuracy 0.5961538461538461\n",
            "Mpca 185 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 185 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 185 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 185 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 185 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 185 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 185 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 185 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 185 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 185 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 185 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 185 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 185 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 185 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 185 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 185 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 185 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 185 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 185 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 185 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 185 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 185 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 185 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 185 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 185 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 185 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 185 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 185 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 185 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 185 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 185 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 185 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 185 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 185 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 185 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 185 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 185 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 185 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 185 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 186 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 186 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 186 Mlda 3 Accuracy 0.25\n",
            "Mpca 186 Mlda 4 Accuracy 0.375\n",
            "Mpca 186 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 186 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 186 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 186 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 186 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 186 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 186 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 186 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 186 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 186 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 186 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 186 Mlda 16 Accuracy 0.75\n",
            "Mpca 186 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 186 Mlda 18 Accuracy 0.75\n",
            "Mpca 186 Mlda 19 Accuracy 0.75\n",
            "Mpca 186 Mlda 20 Accuracy 0.75\n",
            "Mpca 186 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 186 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 186 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 186 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 186 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 186 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 186 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 186 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 186 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 186 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 186 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 186 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 186 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 186 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 186 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 186 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 186 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 186 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 186 Mlda 50 Accuracy 0.875\n",
            "Mpca 187 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 187 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 187 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 187 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 187 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 187 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 187 Mlda 7 Accuracy 0.5\n",
            "Mpca 187 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 187 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 187 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 187 Mlda 11 Accuracy 0.625\n",
            "Mpca 187 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 187 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 187 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 187 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 187 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 187 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 187 Mlda 18 Accuracy 0.75\n",
            "Mpca 187 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 187 Mlda 20 Accuracy 0.75\n",
            "Mpca 187 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 187 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 187 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 187 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 187 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 187 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 187 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 187 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 187 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 187 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 187 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 187 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 187 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 187 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 187 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 187 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 187 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 187 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 187 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 187 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 187 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 187 Mlda 50 Accuracy 0.875\n",
            "Mpca 188 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 188 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 188 Mlda 3 Accuracy 0.25\n",
            "Mpca 188 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 188 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 188 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 188 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 188 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 188 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 188 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 188 Mlda 11 Accuracy 0.625\n",
            "Mpca 188 Mlda 12 Accuracy 0.625\n",
            "Mpca 188 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 188 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 188 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 188 Mlda 16 Accuracy 0.75\n",
            "Mpca 188 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 188 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 188 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 188 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 188 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 188 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 188 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 188 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 188 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 188 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 188 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 188 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 188 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 188 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 188 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 188 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 188 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 188 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 188 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 188 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 188 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 188 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 188 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 188 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 188 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 188 Mlda 50 Accuracy 0.875\n",
            "Mpca 189 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 189 Mlda 2 Accuracy 0.125\n",
            "Mpca 189 Mlda 3 Accuracy 0.25\n",
            "Mpca 189 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 189 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 189 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 189 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 189 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 189 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 189 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 189 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 189 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 189 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 189 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 189 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 189 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 189 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 189 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 189 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 189 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 189 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 189 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 189 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 189 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 189 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 189 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 189 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 189 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 189 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 189 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 189 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 189 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 189 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 189 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 189 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 189 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 189 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 189 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 189 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 189 Mlda 50 Accuracy 0.875\n",
            "Mpca 190 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 190 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 190 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 190 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 190 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 190 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 190 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 190 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 190 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 190 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 190 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 190 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 190 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 190 Mlda 14 Accuracy 0.75\n",
            "Mpca 190 Mlda 15 Accuracy 0.75\n",
            "Mpca 190 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 190 Mlda 17 Accuracy 0.75\n",
            "Mpca 190 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 190 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 190 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 190 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 190 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 190 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 190 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 190 Mlda 25 Accuracy 0.8173076923076923\n",
            "Mpca 190 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 190 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 190 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 190 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 190 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 190 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 190 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 190 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 190 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 190 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 190 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 190 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 190 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 190 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 190 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 190 Mlda 49 Accuracy 0.875\n",
            "Mpca 190 Mlda 50 Accuracy 0.875\n",
            "Mpca 191 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 191 Mlda 2 Accuracy 0.125\n",
            "Mpca 191 Mlda 3 Accuracy 0.25\n",
            "Mpca 191 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 191 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 191 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 191 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 191 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 191 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 191 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 191 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 191 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 191 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 191 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 191 Mlda 15 Accuracy 0.75\n",
            "Mpca 191 Mlda 16 Accuracy 0.75\n",
            "Mpca 191 Mlda 17 Accuracy 0.75\n",
            "Mpca 191 Mlda 18 Accuracy 0.75\n",
            "Mpca 191 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 191 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 191 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 191 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 191 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 191 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 191 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 191 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 191 Mlda 27 Accuracy 0.8173076923076923\n",
            "Mpca 191 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 191 Mlda 29 Accuracy 0.8365384615384616\n",
            "Mpca 191 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 191 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 191 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 191 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 191 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 191 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 191 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 191 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 191 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 191 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 191 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 191 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 191 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 191 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 191 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 191 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 191 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 191 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 191 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 191 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 191 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 192 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 192 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 192 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 192 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 192 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 192 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 192 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 192 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 192 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 192 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 192 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 192 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 192 Mlda 14 Accuracy 0.75\n",
            "Mpca 192 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 192 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 192 Mlda 17 Accuracy 0.75\n",
            "Mpca 192 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 192 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 192 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 192 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 192 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 192 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 192 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 192 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 192 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 192 Mlda 27 Accuracy 0.8269230769230769\n",
            "Mpca 192 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 192 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 192 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 192 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 192 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 192 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 192 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 192 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 192 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 192 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 192 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 192 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 192 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 192 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 192 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 192 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 193 Mlda 2 Accuracy 0.125\n",
            "Mpca 193 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 193 Mlda 4 Accuracy 0.38461538461538464\n",
            "Mpca 193 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 193 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 193 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 193 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 193 Mlda 9 Accuracy 0.625\n",
            "Mpca 193 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 193 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 193 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 193 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 193 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 193 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 193 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 193 Mlda 17 Accuracy 0.75\n",
            "Mpca 193 Mlda 18 Accuracy 0.75\n",
            "Mpca 193 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 193 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 193 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 193 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 193 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 193 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 193 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 193 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 193 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 193 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 193 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 193 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 193 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 193 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 193 Mlda 33 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 193 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 193 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 193 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 193 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 193 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 193 Mlda 44 Accuracy 0.875\n",
            "Mpca 193 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 193 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 193 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 194 Mlda 2 Accuracy 0.125\n",
            "Mpca 194 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 194 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 194 Mlda 5 Accuracy 0.375\n",
            "Mpca 194 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 194 Mlda 7 Accuracy 0.5769230769230769\n",
            "Mpca 194 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 194 Mlda 9 Accuracy 0.625\n",
            "Mpca 194 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 194 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 194 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 194 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 194 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 194 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 194 Mlda 16 Accuracy 0.75\n",
            "Mpca 194 Mlda 17 Accuracy 0.75\n",
            "Mpca 194 Mlda 18 Accuracy 0.75\n",
            "Mpca 194 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 194 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 194 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 194 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 194 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 194 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 194 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 194 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 194 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 194 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 194 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 194 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 194 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 194 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 194 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 194 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 194 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 194 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 194 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 194 Mlda 43 Accuracy 0.875\n",
            "Mpca 194 Mlda 44 Accuracy 0.875\n",
            "Mpca 194 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 194 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 194 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 194 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 195 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 195 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 195 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 195 Mlda 4 Accuracy 0.375\n",
            "Mpca 195 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 195 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 195 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 195 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 195 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 195 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 195 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 195 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 195 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 195 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 195 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 195 Mlda 16 Accuracy 0.75\n",
            "Mpca 195 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 195 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 195 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 195 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 195 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 195 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 195 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 195 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 195 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 195 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 195 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 195 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 195 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 195 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 195 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 195 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 195 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 195 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 195 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 195 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 195 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 195 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 195 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 195 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 195 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 195 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 195 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 195 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 195 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 195 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 195 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 195 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 195 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 195 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 196 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 196 Mlda 2 Accuracy 0.125\n",
            "Mpca 196 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 196 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 196 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 196 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 196 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 196 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 196 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 196 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 196 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 196 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 196 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 196 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 196 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 196 Mlda 16 Accuracy 0.75\n",
            "Mpca 196 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 196 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 196 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 196 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 196 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 196 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 196 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 196 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 196 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 196 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 196 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 196 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 196 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 196 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 196 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 196 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 196 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 196 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 196 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 196 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 196 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 196 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 196 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 196 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 196 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 197 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 197 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 197 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 197 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 197 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 197 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 197 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 197 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 197 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 197 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 197 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 197 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 197 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 197 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 197 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 197 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 197 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 197 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 197 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 197 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 197 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 197 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 197 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 197 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 197 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 197 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 197 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 197 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 197 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 197 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 197 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 197 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 197 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 197 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 197 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 197 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 197 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 197 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 197 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 197 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 197 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 197 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 197 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 197 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 197 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 197 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 197 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 197 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 197 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 197 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 198 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 198 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 198 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 198 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 198 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 198 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 198 Mlda 7 Accuracy 0.5\n",
            "Mpca 198 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 198 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 198 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 198 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 198 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 198 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 198 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 198 Mlda 15 Accuracy 0.75\n",
            "Mpca 198 Mlda 16 Accuracy 0.75\n",
            "Mpca 198 Mlda 17 Accuracy 0.75\n",
            "Mpca 198 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 198 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 198 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 198 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 198 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 198 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 198 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 198 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 198 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 198 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 198 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 198 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 198 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 198 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 198 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 198 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 198 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 198 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 198 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 198 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 198 Mlda 38 Accuracy 0.8653846153846154\n",
            "Mpca 198 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 198 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 198 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 198 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 198 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 198 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 198 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 198 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 198 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 198 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 198 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 198 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 199 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 199 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 199 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 199 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 199 Mlda 5 Accuracy 0.375\n",
            "Mpca 199 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 199 Mlda 7 Accuracy 0.5\n",
            "Mpca 199 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 199 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 199 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 199 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 199 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 199 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 199 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 199 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 199 Mlda 16 Accuracy 0.75\n",
            "Mpca 199 Mlda 17 Accuracy 0.75\n",
            "Mpca 199 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 199 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 199 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 199 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 199 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 199 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 199 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 199 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 199 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 199 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 199 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 199 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 199 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 199 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 199 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 199 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 199 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 199 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 199 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 199 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 199 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 199 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 199 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 199 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 199 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 199 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 199 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 199 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 199 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 199 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 199 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 199 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 199 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 200 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 200 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 200 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 200 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 200 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 200 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 200 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 200 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 200 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 200 Mlda 10 Accuracy 0.625\n",
            "Mpca 200 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 200 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 200 Mlda 13 Accuracy 0.6442307692307693\n",
            "Mpca 200 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 200 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 200 Mlda 16 Accuracy 0.75\n",
            "Mpca 200 Mlda 17 Accuracy 0.75\n",
            "Mpca 200 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 200 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 200 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 200 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 200 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 200 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 200 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 200 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 200 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 200 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 200 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 200 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 200 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 200 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 200 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 200 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 200 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 200 Mlda 35 Accuracy 0.8653846153846154\n",
            "Mpca 200 Mlda 36 Accuracy 0.8653846153846154\n",
            "Mpca 200 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 200 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 200 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 200 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 200 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 200 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 200 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 200 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 200 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 200 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 200 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 200 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 200 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 200 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 201 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 201 Mlda 3 Accuracy 0.28846153846153844\n",
            "Mpca 201 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 201 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 201 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 201 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 201 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 201 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 201 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 201 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 201 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 201 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 201 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 201 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 201 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 201 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 201 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 201 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 201 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 201 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 201 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 201 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 201 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 201 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 201 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 201 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 201 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 201 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 201 Mlda 30 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 201 Mlda 36 Accuracy 0.8557692307692307\n",
            "Mpca 201 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 201 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 201 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 201 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 202 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 202 Mlda 2 Accuracy 0.125\n",
            "Mpca 202 Mlda 3 Accuracy 0.3076923076923077\n",
            "Mpca 202 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 202 Mlda 5 Accuracy 0.375\n",
            "Mpca 202 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 202 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 202 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 202 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 202 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 202 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 202 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 202 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 202 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 202 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 202 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 202 Mlda 17 Accuracy 0.75\n",
            "Mpca 202 Mlda 18 Accuracy 0.75\n",
            "Mpca 202 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 202 Mlda 20 Accuracy 0.8076923076923077\n",
            "Mpca 202 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 202 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 202 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 202 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 202 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 202 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 202 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 202 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 202 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 202 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 202 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 202 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 202 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 202 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 202 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 202 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 202 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 202 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 202 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 202 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 202 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 203 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 203 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 203 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 203 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 203 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 203 Mlda 7 Accuracy 0.5\n",
            "Mpca 203 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 203 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 203 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 203 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 203 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 203 Mlda 13 Accuracy 0.6442307692307693\n",
            "Mpca 203 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 203 Mlda 15 Accuracy 0.75\n",
            "Mpca 203 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 203 Mlda 17 Accuracy 0.75\n",
            "Mpca 203 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 203 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 203 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 203 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 203 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 203 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 203 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 203 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 203 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 203 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 203 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 203 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 203 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 203 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 203 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 203 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 203 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 203 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 203 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 203 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 203 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 203 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 203 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 203 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 204 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 204 Mlda 2 Accuracy 0.125\n",
            "Mpca 204 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 204 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 204 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 204 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 204 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 204 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 204 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 204 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 204 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 204 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 204 Mlda 13 Accuracy 0.625\n",
            "Mpca 204 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 204 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 204 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 204 Mlda 17 Accuracy 0.75\n",
            "Mpca 204 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 204 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 204 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 204 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 204 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 204 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 204 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 204 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 204 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 204 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 204 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 204 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 204 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 204 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 204 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 204 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 204 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 204 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 204 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 204 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 204 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 204 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 204 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 204 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 204 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 204 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 204 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 204 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 204 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 204 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 204 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 204 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 204 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 205 Mlda 2 Accuracy 0.125\n",
            "Mpca 205 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 205 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 205 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 205 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 205 Mlda 7 Accuracy 0.5\n",
            "Mpca 205 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 205 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 205 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 205 Mlda 11 Accuracy 0.625\n",
            "Mpca 205 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 205 Mlda 13 Accuracy 0.625\n",
            "Mpca 205 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 205 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 205 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 205 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 205 Mlda 18 Accuracy 0.75\n",
            "Mpca 205 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 205 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 205 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 205 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 205 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 205 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 205 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 205 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 205 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 205 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 205 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 205 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 205 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 205 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 205 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 205 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 205 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 205 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 205 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 205 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 205 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 205 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 205 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 206 Mlda 2 Accuracy 0.125\n",
            "Mpca 206 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 206 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 206 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 206 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 206 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 206 Mlda 8 Accuracy 0.5\n",
            "Mpca 206 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 206 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 206 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 206 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 206 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 206 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 206 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 206 Mlda 16 Accuracy 0.75\n",
            "Mpca 206 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 206 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 206 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 206 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 206 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 206 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 206 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 206 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 206 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 206 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 206 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 206 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 206 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 206 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 206 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 206 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 206 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 206 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 206 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 206 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 206 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 206 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 206 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 206 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 206 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 206 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 206 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 207 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 207 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 207 Mlda 3 Accuracy 0.25\n",
            "Mpca 207 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 207 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 207 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 207 Mlda 7 Accuracy 0.5\n",
            "Mpca 207 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 207 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 207 Mlda 10 Accuracy 0.625\n",
            "Mpca 207 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 207 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 207 Mlda 13 Accuracy 0.625\n",
            "Mpca 207 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 207 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 207 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 207 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 207 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 207 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 207 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 207 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 207 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 207 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 207 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 207 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 207 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 207 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 207 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 207 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 207 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 207 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 207 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 207 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 207 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 207 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 207 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 207 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 207 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 207 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 207 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 207 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 207 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 207 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 207 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 207 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 207 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 207 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 207 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 207 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 207 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 208 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 208 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 208 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 208 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 208 Mlda 5 Accuracy 0.375\n",
            "Mpca 208 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 208 Mlda 7 Accuracy 0.5\n",
            "Mpca 208 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 208 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 208 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 208 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 208 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 208 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 208 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 208 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 208 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 208 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 208 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 208 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 208 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 208 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 208 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 208 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 208 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 208 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 208 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 208 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 208 Mlda 28 Accuracy 0.75\n",
            "Mpca 208 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 208 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 208 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 208 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 208 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 208 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 208 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 208 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 208 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 208 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 208 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 208 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 208 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 209 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 209 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 209 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 209 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 209 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 209 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 209 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 209 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 209 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 209 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 209 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 209 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 209 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 209 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 209 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 209 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 209 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 209 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 209 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 209 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 209 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 209 Mlda 23 Accuracy 0.8076923076923077\n",
            "Mpca 209 Mlda 24 Accuracy 0.8076923076923077\n",
            "Mpca 209 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 209 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 209 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 209 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 209 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 209 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 209 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 209 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 209 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 209 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 209 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 209 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 209 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 209 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 209 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 209 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 209 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 210 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 210 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 210 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 210 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 210 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 210 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 210 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 210 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 210 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 210 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 210 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 210 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 210 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 210 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 210 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 210 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 210 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 210 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 210 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 210 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 210 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 210 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 210 Mlda 24 Accuracy 0.7980769230769231\n",
            "Mpca 210 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 210 Mlda 26 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 210 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 210 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 210 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 210 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 210 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 210 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 210 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 210 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 210 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 210 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 210 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 210 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 210 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 210 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 210 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 47 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 210 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 211 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 211 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 211 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 211 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 211 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 211 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 211 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 211 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 211 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 211 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 211 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 211 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 211 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 211 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 211 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 211 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 211 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 211 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 211 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 211 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 211 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 211 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 211 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 211 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 211 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 211 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 211 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 211 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 211 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 211 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 211 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 211 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 211 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 211 Mlda 34 Accuracy 0.8557692307692307\n",
            "Mpca 211 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 211 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 211 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 211 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 211 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 211 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 211 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 211 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 211 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 212 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 212 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 212 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 212 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 212 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 212 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 212 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 212 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 212 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 212 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 212 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 212 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 212 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 212 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 212 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 212 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 212 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 212 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 212 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 212 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 212 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 212 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 212 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 212 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 212 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 212 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 212 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 212 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 212 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 212 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 212 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 212 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 212 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 212 Mlda 34 Accuracy 0.8653846153846154\n",
            "Mpca 212 Mlda 35 Accuracy 0.8461538461538461\n",
            "Mpca 212 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 212 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 212 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 212 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 212 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 212 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 212 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 212 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 212 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 212 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 212 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 212 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 212 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 212 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 212 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 213 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 213 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 213 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 213 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 213 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 213 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 213 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 213 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 213 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 213 Mlda 11 Accuracy 0.625\n",
            "Mpca 213 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 213 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 213 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 213 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 213 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 213 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 213 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 213 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 213 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 213 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 213 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 213 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 213 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 213 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 213 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 213 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 213 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 213 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 213 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 213 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 213 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 213 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 213 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 213 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 213 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 213 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 213 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 213 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 213 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 214 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 214 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 214 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 214 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 214 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 214 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 214 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 214 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 214 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 214 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 214 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 214 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 214 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 214 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 214 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 214 Mlda 17 Accuracy 0.75\n",
            "Mpca 214 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 214 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 214 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 214 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 214 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 214 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 214 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 214 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 214 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 214 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 214 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 214 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 214 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 214 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 214 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 214 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 214 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 214 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 214 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 214 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 214 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 214 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 214 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 214 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 215 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 215 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 215 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 215 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 215 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 215 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 215 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 215 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 215 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 215 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 215 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 215 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 215 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 215 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 215 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 215 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 215 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 215 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 215 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 215 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 215 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 215 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 215 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 215 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 215 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 215 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 215 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 215 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 215 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 215 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 215 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 215 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 215 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 215 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 215 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 215 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 215 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 215 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 215 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 215 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 215 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 215 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 215 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 215 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 215 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 215 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 215 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 215 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 215 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 215 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 216 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 216 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 216 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 216 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 216 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 216 Mlda 6 Accuracy 0.5288461538461539\n",
            "Mpca 216 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 216 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 216 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 216 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 216 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 216 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 216 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 216 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 216 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 216 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 216 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 216 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 216 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 216 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 216 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 216 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 216 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 216 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 216 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 216 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 216 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 216 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 216 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 216 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 216 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 216 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 216 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 216 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 216 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 216 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 216 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 216 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 217 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 217 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 217 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 217 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 217 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 217 Mlda 6 Accuracy 0.5192307692307693\n",
            "Mpca 217 Mlda 7 Accuracy 0.5769230769230769\n",
            "Mpca 217 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 217 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 217 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 217 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 217 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 217 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 217 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 217 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 217 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 217 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 217 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 217 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 217 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 217 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 217 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 217 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 217 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 217 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 217 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 217 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 217 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 217 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 217 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 217 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 217 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 217 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 217 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 217 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 217 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 217 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 217 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 217 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 217 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 217 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 217 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 217 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 217 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 217 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 217 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 217 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 217 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 217 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 217 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 218 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 218 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 218 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 218 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 218 Mlda 5 Accuracy 0.375\n",
            "Mpca 218 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 218 Mlda 7 Accuracy 0.5769230769230769\n",
            "Mpca 218 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 218 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 218 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 218 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 218 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 218 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 218 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 218 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 218 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 218 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 218 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 218 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 218 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 218 Mlda 21 Accuracy 0.7788461538461539\n",
            "Mpca 218 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 218 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 218 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 218 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 218 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 218 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 218 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 218 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 218 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 218 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 218 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 218 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 218 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 218 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 218 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 218 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 218 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 218 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 218 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 218 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 218 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 218 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 218 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 218 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 218 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 218 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 218 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 218 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 218 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 219 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 219 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 219 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 219 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 219 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 219 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 219 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 219 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 219 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 219 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 219 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 219 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 219 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 219 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 219 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 219 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 219 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 219 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 219 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 219 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 219 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 219 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 219 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 219 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 219 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 219 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 219 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 219 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 219 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 219 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 219 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 219 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 219 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 219 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 219 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 219 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 219 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 219 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 219 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 219 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 219 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 219 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 219 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 219 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 219 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 219 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 219 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 219 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 219 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 219 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 220 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 220 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 220 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 220 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 220 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 220 Mlda 6 Accuracy 0.5\n",
            "Mpca 220 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 220 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 220 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 220 Mlda 10 Accuracy 0.625\n",
            "Mpca 220 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 220 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 220 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 220 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 220 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 220 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 220 Mlda 17 Accuracy 0.75\n",
            "Mpca 220 Mlda 18 Accuracy 0.75\n",
            "Mpca 220 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 220 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 220 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 220 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 220 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 220 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 220 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 220 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 220 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 220 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 220 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 220 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 220 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 220 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 220 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 220 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 220 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 220 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 220 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 220 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 220 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 220 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 220 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 220 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 221 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 221 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 221 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 221 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 221 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 221 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 221 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 221 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 221 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 221 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 221 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 221 Mlda 12 Accuracy 0.7596153846153846\n",
            "Mpca 221 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 221 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 221 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 221 Mlda 16 Accuracy 0.75\n",
            "Mpca 221 Mlda 17 Accuracy 0.75\n",
            "Mpca 221 Mlda 18 Accuracy 0.75\n",
            "Mpca 221 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 221 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 221 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 221 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 221 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 221 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 221 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 221 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 221 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 221 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 221 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 221 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 221 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 221 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 221 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 221 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 221 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 221 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 221 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 221 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 221 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 221 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 221 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 221 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 221 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 221 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 221 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 221 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 221 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 221 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 221 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 221 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 222 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 222 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 222 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 222 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 222 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 222 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 222 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 222 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 222 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 222 Mlda 10 Accuracy 0.625\n",
            "Mpca 222 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 222 Mlda 12 Accuracy 0.7403846153846154\n",
            "Mpca 222 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 222 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 222 Mlda 15 Accuracy 0.75\n",
            "Mpca 222 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 222 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 222 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 222 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 222 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 222 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 222 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 222 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 222 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 222 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 222 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 222 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 222 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 222 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 222 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 222 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 222 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 222 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 222 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 222 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 222 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 222 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 222 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 222 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 222 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 222 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 222 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 222 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 222 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 222 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 222 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 222 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 222 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 222 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 222 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 223 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 223 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 223 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 223 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 223 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 223 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 223 Mlda 7 Accuracy 0.5865384615384616\n",
            "Mpca 223 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 223 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 223 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 223 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 223 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 223 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 223 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 223 Mlda 15 Accuracy 0.75\n",
            "Mpca 223 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 223 Mlda 17 Accuracy 0.75\n",
            "Mpca 223 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 223 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 223 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 223 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 223 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 223 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 223 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 223 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 223 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 223 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 223 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 223 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 223 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 223 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 223 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 223 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 223 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 223 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 223 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 223 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 223 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 223 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 223 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 223 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 223 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 223 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 223 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 223 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 223 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 223 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 223 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 223 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 223 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 224 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 224 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 224 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 224 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 224 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 224 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 224 Mlda 7 Accuracy 0.5673076923076923\n",
            "Mpca 224 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 224 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 224 Mlda 10 Accuracy 0.625\n",
            "Mpca 224 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 224 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 224 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 224 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 224 Mlda 15 Accuracy 0.75\n",
            "Mpca 224 Mlda 16 Accuracy 0.75\n",
            "Mpca 224 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 224 Mlda 18 Accuracy 0.75\n",
            "Mpca 224 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 224 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 224 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 224 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 224 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 224 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 224 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 224 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 224 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 224 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 224 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 224 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 224 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 224 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 224 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 224 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 224 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 224 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 224 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 224 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 224 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 224 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 224 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 224 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 225 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 225 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 225 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 225 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 225 Mlda 5 Accuracy 0.4326923076923077\n",
            "Mpca 225 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 225 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 225 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 225 Mlda 9 Accuracy 0.625\n",
            "Mpca 225 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 225 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 225 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 225 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 225 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 225 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 225 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 225 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 225 Mlda 18 Accuracy 0.75\n",
            "Mpca 225 Mlda 19 Accuracy 0.75\n",
            "Mpca 225 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 225 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 23 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 225 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 225 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 225 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 225 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 225 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 225 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 225 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 225 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 225 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 225 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 225 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 225 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 225 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 225 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 225 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 225 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 225 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 225 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 225 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 225 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 225 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 226 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 226 Mlda 2 Accuracy 0.125\n",
            "Mpca 226 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 226 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 226 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 226 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 226 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 226 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 226 Mlda 9 Accuracy 0.625\n",
            "Mpca 226 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 226 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 226 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 226 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 226 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 226 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 226 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 226 Mlda 17 Accuracy 0.75\n",
            "Mpca 226 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 226 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 226 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 226 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 226 Mlda 22 Accuracy 0.7980769230769231\n",
            "Mpca 226 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 226 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 226 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 226 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 226 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 226 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 226 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 226 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 226 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 226 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 226 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 226 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 226 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 226 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 226 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 226 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 226 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 226 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 226 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 226 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 226 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 226 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 226 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 226 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 226 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 226 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 226 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 226 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 227 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 227 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 227 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 227 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 227 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 227 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 227 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 227 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 227 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 227 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 227 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 227 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 227 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 227 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 227 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 227 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 227 Mlda 17 Accuracy 0.75\n",
            "Mpca 227 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 227 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 227 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 227 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 227 Mlda 22 Accuracy 0.7884615384615384\n",
            "Mpca 227 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 227 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 227 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 227 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 227 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 227 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 227 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 227 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 227 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 227 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 227 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 227 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 227 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 227 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 227 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 227 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 227 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 227 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 227 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 227 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 227 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 228 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 228 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 228 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 228 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 228 Mlda 5 Accuracy 0.375\n",
            "Mpca 228 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 228 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 228 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 228 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 228 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 228 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 228 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 228 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 228 Mlda 14 Accuracy 0.7692307692307693\n",
            "Mpca 228 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 228 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 228 Mlda 17 Accuracy 0.75\n",
            "Mpca 228 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 228 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 228 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 228 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 228 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 228 Mlda 23 Accuracy 0.75\n",
            "Mpca 228 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 228 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 228 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 228 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 228 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 228 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 228 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 228 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 228 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 228 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 228 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 228 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 228 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 228 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 228 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 228 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 228 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 228 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 228 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 228 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 229 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 229 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 229 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 229 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 229 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 229 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 229 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 229 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 229 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 229 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 229 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 229 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 229 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 229 Mlda 14 Accuracy 0.75\n",
            "Mpca 229 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 229 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 229 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 229 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 229 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 229 Mlda 20 Accuracy 0.75\n",
            "Mpca 229 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 229 Mlda 22 Accuracy 0.75\n",
            "Mpca 229 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 229 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 229 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 229 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 229 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 229 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 229 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 229 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 229 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 229 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 229 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 229 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 229 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 229 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 229 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 229 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 229 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 229 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 229 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 229 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 229 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 230 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 230 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 230 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 230 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 230 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 230 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 230 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 230 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 230 Mlda 9 Accuracy 0.625\n",
            "Mpca 230 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 230 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 230 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 230 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 230 Mlda 14 Accuracy 0.75\n",
            "Mpca 230 Mlda 15 Accuracy 0.75\n",
            "Mpca 230 Mlda 16 Accuracy 0.75\n",
            "Mpca 230 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 230 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 230 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 230 Mlda 20 Accuracy 0.75\n",
            "Mpca 230 Mlda 21 Accuracy 0.75\n",
            "Mpca 230 Mlda 22 Accuracy 0.75\n",
            "Mpca 230 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 230 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 230 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 230 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 230 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 230 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 230 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 230 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 230 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 230 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 230 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 230 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 230 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 230 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 230 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 230 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 230 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 230 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 230 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 230 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 231 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 231 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 231 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 231 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 231 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 231 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 231 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 231 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 231 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 231 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 231 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 231 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 231 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 231 Mlda 14 Accuracy 0.75\n",
            "Mpca 231 Mlda 15 Accuracy 0.75\n",
            "Mpca 231 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 231 Mlda 17 Accuracy 0.75\n",
            "Mpca 231 Mlda 18 Accuracy 0.75\n",
            "Mpca 231 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 231 Mlda 20 Accuracy 0.75\n",
            "Mpca 231 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 231 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 231 Mlda 23 Accuracy 0.75\n",
            "Mpca 231 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 231 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 231 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 231 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 231 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 231 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 231 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 231 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 231 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 231 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 231 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 231 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 231 Mlda 36 Accuracy 0.7788461538461539\n",
            "Mpca 231 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 231 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 231 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 231 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 231 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 231 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 231 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 231 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 231 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 231 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 231 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 231 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 231 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 231 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 232 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 232 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 232 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 232 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 232 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 232 Mlda 6 Accuracy 0.5\n",
            "Mpca 232 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 232 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 232 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 232 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 232 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 232 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 232 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 232 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 232 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 232 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 232 Mlda 17 Accuracy 0.75\n",
            "Mpca 232 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 232 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 232 Mlda 20 Accuracy 0.75\n",
            "Mpca 232 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 232 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 232 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 232 Mlda 24 Accuracy 0.7884615384615384\n",
            "Mpca 232 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 232 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 232 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 232 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 232 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 232 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 232 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 232 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 232 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 232 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 232 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 232 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 232 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 232 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 232 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 232 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 232 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 232 Mlda 42 Accuracy 0.8076923076923077\n",
            "Mpca 232 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 232 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 232 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 232 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 232 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 232 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 232 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 232 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 233 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 233 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 233 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 233 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 233 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 233 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 233 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 233 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 233 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 233 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 233 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 233 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 233 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 233 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 233 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 233 Mlda 16 Accuracy 0.75\n",
            "Mpca 233 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 233 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 233 Mlda 19 Accuracy 0.75\n",
            "Mpca 233 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 233 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 233 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 233 Mlda 23 Accuracy 0.75\n",
            "Mpca 233 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 233 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 233 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 233 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 233 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 233 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 233 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 233 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 233 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 233 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 233 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 233 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 233 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 233 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 233 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 233 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 233 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 233 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 233 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 233 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 233 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 233 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 233 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 233 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 233 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 233 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 233 Mlda 50 Accuracy 0.875\n",
            "Mpca 234 Mlda 1 Accuracy 0.125\n",
            "Mpca 234 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 234 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 234 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 234 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 234 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 234 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 234 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 234 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 234 Mlda 10 Accuracy 0.625\n",
            "Mpca 234 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 234 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 234 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 234 Mlda 14 Accuracy 0.75\n",
            "Mpca 234 Mlda 15 Accuracy 0.75\n",
            "Mpca 234 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 234 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 234 Mlda 18 Accuracy 0.75\n",
            "Mpca 234 Mlda 19 Accuracy 0.75\n",
            "Mpca 234 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 234 Mlda 21 Accuracy 0.75\n",
            "Mpca 234 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 234 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 234 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 234 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 234 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 234 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 234 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 234 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 234 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 234 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 234 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 234 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 234 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 234 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 234 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 234 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 234 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 234 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 234 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 234 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 234 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 234 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 234 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 234 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 234 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 234 Mlda 47 Accuracy 0.875\n",
            "Mpca 234 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 234 Mlda 49 Accuracy 0.875\n",
            "Mpca 234 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 235 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 235 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 235 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 235 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 235 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 235 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 235 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 235 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 235 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 235 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 235 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 235 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 235 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 235 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 235 Mlda 15 Accuracy 0.75\n",
            "Mpca 235 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 235 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 235 Mlda 18 Accuracy 0.75\n",
            "Mpca 235 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 235 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 235 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 235 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 235 Mlda 23 Accuracy 0.75\n",
            "Mpca 235 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 235 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 235 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 235 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 235 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 235 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 235 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 235 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 235 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 235 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 235 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 235 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 235 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 235 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 235 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 235 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 235 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 235 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 235 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 235 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 235 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 235 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 235 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 235 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 235 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 235 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 235 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 236 Mlda 1 Accuracy 0.1346153846153846\n",
            "Mpca 236 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 236 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 236 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 236 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 236 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 236 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 236 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 236 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 236 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 236 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 236 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 236 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 236 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 236 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 236 Mlda 16 Accuracy 0.75\n",
            "Mpca 236 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 236 Mlda 18 Accuracy 0.7307692307692307\n",
            "Mpca 236 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 236 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 236 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 236 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 236 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 236 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 236 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 236 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 236 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 236 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 236 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 236 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 236 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 236 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 236 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 236 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 236 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 236 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 236 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 236 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 236 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 236 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 236 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 236 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 236 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 236 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 236 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 236 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 236 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 236 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 236 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 236 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 237 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 237 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 237 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 237 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 237 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 237 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 237 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 237 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 237 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 237 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 237 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 237 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 237 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 237 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 237 Mlda 15 Accuracy 0.75\n",
            "Mpca 237 Mlda 16 Accuracy 0.75\n",
            "Mpca 237 Mlda 17 Accuracy 0.75\n",
            "Mpca 237 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 237 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 237 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 237 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 237 Mlda 22 Accuracy 0.75\n",
            "Mpca 237 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 237 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 237 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 237 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 237 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 237 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 237 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 237 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 237 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 237 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 237 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 237 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 237 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 237 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 237 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 237 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 237 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 237 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 237 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 237 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 237 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 237 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 237 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 237 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 237 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 237 Mlda 48 Accuracy 0.875\n",
            "Mpca 237 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 237 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 238 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 238 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 238 Mlda 3 Accuracy 0.25\n",
            "Mpca 238 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 238 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 238 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 238 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 238 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 238 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 238 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 238 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 238 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 238 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 238 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 238 Mlda 15 Accuracy 0.75\n",
            "Mpca 238 Mlda 16 Accuracy 0.75\n",
            "Mpca 238 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 238 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 238 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 238 Mlda 20 Accuracy 0.75\n",
            "Mpca 238 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 238 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 238 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 238 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 238 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 238 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 238 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 238 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 238 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 238 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 238 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 238 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 238 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 238 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 238 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 238 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 238 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 238 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 238 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 238 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 238 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 238 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 238 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 238 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 238 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 238 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 238 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 238 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 238 Mlda 49 Accuracy 0.875\n",
            "Mpca 238 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 239 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 239 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 239 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 239 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 239 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 239 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 239 Mlda 7 Accuracy 0.5769230769230769\n",
            "Mpca 239 Mlda 8 Accuracy 0.6442307692307693\n",
            "Mpca 239 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 239 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 239 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 239 Mlda 12 Accuracy 0.7211538461538461\n",
            "Mpca 239 Mlda 13 Accuracy 0.7596153846153846\n",
            "Mpca 239 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 239 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 239 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 239 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 239 Mlda 18 Accuracy 0.75\n",
            "Mpca 239 Mlda 19 Accuracy 0.75\n",
            "Mpca 239 Mlda 20 Accuracy 0.75\n",
            "Mpca 239 Mlda 21 Accuracy 0.75\n",
            "Mpca 239 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 239 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 239 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 239 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 239 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 239 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 239 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 239 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 239 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 239 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 239 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 239 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 239 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 239 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 239 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 239 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 239 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 239 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 239 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 239 Mlda 41 Accuracy 0.8653846153846154\n",
            "Mpca 239 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 239 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 239 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 239 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 239 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 239 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 239 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 239 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 239 Mlda 50 Accuracy 0.875\n",
            "Mpca 240 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 240 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 240 Mlda 3 Accuracy 0.25\n",
            "Mpca 240 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 240 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 240 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 240 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 240 Mlda 8 Accuracy 0.6153846153846154\n",
            "Mpca 240 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 240 Mlda 10 Accuracy 0.6634615384615384\n",
            "Mpca 240 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 240 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 240 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 240 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 240 Mlda 15 Accuracy 0.75\n",
            "Mpca 240 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 240 Mlda 17 Accuracy 0.75\n",
            "Mpca 240 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 240 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 240 Mlda 20 Accuracy 0.75\n",
            "Mpca 240 Mlda 21 Accuracy 0.75\n",
            "Mpca 240 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 240 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 240 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 240 Mlda 25 Accuracy 0.75\n",
            "Mpca 240 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 240 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 240 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 240 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 240 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 240 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 240 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 240 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 240 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 240 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 240 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 240 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 240 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 240 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 240 Mlda 40 Accuracy 0.8653846153846154\n",
            "Mpca 240 Mlda 41 Accuracy 0.875\n",
            "Mpca 240 Mlda 42 Accuracy 0.875\n",
            "Mpca 240 Mlda 43 Accuracy 0.875\n",
            "Mpca 240 Mlda 44 Accuracy 0.875\n",
            "Mpca 240 Mlda 45 Accuracy 0.875\n",
            "Mpca 240 Mlda 46 Accuracy 0.875\n",
            "Mpca 240 Mlda 47 Accuracy 0.875\n",
            "Mpca 240 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 240 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 240 Mlda 50 Accuracy 0.875\n",
            "Mpca 241 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 241 Mlda 2 Accuracy 0.18269230769230768\n",
            "Mpca 241 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 241 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 241 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 241 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 241 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 241 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 241 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 241 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 241 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 241 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 241 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 241 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 241 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 241 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 241 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 241 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 241 Mlda 19 Accuracy 0.75\n",
            "Mpca 241 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 241 Mlda 21 Accuracy 0.75\n",
            "Mpca 241 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 241 Mlda 23 Accuracy 0.7884615384615384\n",
            "Mpca 241 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 241 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 241 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 241 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 241 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 241 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 241 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 241 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 241 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 241 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 241 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 241 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 241 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 241 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 241 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 241 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 241 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 241 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 241 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 241 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 241 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 241 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 241 Mlda 46 Accuracy 0.875\n",
            "Mpca 241 Mlda 47 Accuracy 0.875\n",
            "Mpca 241 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 241 Mlda 49 Accuracy 0.875\n",
            "Mpca 241 Mlda 50 Accuracy 0.875\n",
            "Mpca 242 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 242 Mlda 2 Accuracy 0.21153846153846154\n",
            "Mpca 242 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 242 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 242 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 242 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 242 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 242 Mlda 8 Accuracy 0.6057692307692307\n",
            "Mpca 242 Mlda 9 Accuracy 0.6634615384615384\n",
            "Mpca 242 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 242 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 242 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 242 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 242 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 242 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 242 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 242 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 242 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 242 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 242 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 242 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 242 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 242 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 242 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 242 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 242 Mlda 26 Accuracy 0.75\n",
            "Mpca 242 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 242 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 242 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 242 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 242 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 242 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 242 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 242 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 242 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 242 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 242 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 242 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 242 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 242 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 242 Mlda 41 Accuracy 0.8653846153846154\n",
            "Mpca 242 Mlda 42 Accuracy 0.8846153846153846\n",
            "Mpca 242 Mlda 43 Accuracy 0.8846153846153846\n",
            "Mpca 242 Mlda 44 Accuracy 0.875\n",
            "Mpca 242 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 242 Mlda 46 Accuracy 0.875\n",
            "Mpca 242 Mlda 47 Accuracy 0.875\n",
            "Mpca 242 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 242 Mlda 49 Accuracy 0.875\n",
            "Mpca 242 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 243 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 243 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 243 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 243 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 243 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 243 Mlda 6 Accuracy 0.5096153846153846\n",
            "Mpca 243 Mlda 7 Accuracy 0.5576923076923077\n",
            "Mpca 243 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 243 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 243 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 243 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 243 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 243 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 243 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 243 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 243 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 243 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 243 Mlda 18 Accuracy 0.75\n",
            "Mpca 243 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 243 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 243 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 243 Mlda 22 Accuracy 0.75\n",
            "Mpca 243 Mlda 23 Accuracy 0.75\n",
            "Mpca 243 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 243 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 243 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 243 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 243 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 243 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 243 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 243 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 243 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 243 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 243 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 243 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 243 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 243 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 243 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 243 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 243 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 243 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 243 Mlda 42 Accuracy 0.875\n",
            "Mpca 243 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 243 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 243 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 243 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 243 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 243 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 243 Mlda 49 Accuracy 0.875\n",
            "Mpca 243 Mlda 50 Accuracy 0.875\n",
            "Mpca 244 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 244 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 244 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 244 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 244 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 244 Mlda 6 Accuracy 0.5192307692307693\n",
            "Mpca 244 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 244 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 244 Mlda 9 Accuracy 0.625\n",
            "Mpca 244 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 244 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 244 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 244 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 244 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 244 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 244 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 244 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 244 Mlda 18 Accuracy 0.75\n",
            "Mpca 244 Mlda 19 Accuracy 0.75\n",
            "Mpca 244 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 244 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 244 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 244 Mlda 23 Accuracy 0.7307692307692307\n",
            "Mpca 244 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 244 Mlda 25 Accuracy 0.75\n",
            "Mpca 244 Mlda 26 Accuracy 0.75\n",
            "Mpca 244 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 244 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 244 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 244 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 244 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 244 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 244 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 244 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 244 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 244 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 244 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 244 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 244 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 244 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 244 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 244 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 244 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 244 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 244 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 244 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 244 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 244 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 244 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 244 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 245 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 245 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 245 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 245 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 245 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 245 Mlda 6 Accuracy 0.5\n",
            "Mpca 245 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 245 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 245 Mlda 9 Accuracy 0.6442307692307693\n",
            "Mpca 245 Mlda 10 Accuracy 0.6730769230769231\n",
            "Mpca 245 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 245 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 245 Mlda 13 Accuracy 0.75\n",
            "Mpca 245 Mlda 14 Accuracy 0.7596153846153846\n",
            "Mpca 245 Mlda 15 Accuracy 0.7692307692307693\n",
            "Mpca 245 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 245 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 245 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 245 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 245 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 245 Mlda 21 Accuracy 0.75\n",
            "Mpca 245 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 245 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 245 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 245 Mlda 25 Accuracy 0.75\n",
            "Mpca 245 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 245 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 245 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 245 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 245 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 245 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 245 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 245 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 245 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 245 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 245 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 245 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 245 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 245 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 245 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 245 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 245 Mlda 42 Accuracy 0.875\n",
            "Mpca 245 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 245 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 245 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 245 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 245 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 245 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 245 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 245 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 246 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 246 Mlda 2 Accuracy 0.22115384615384615\n",
            "Mpca 246 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 246 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 246 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 246 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 246 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 246 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 246 Mlda 9 Accuracy 0.625\n",
            "Mpca 246 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 246 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 246 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 246 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 246 Mlda 14 Accuracy 0.7403846153846154\n",
            "Mpca 246 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 246 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 246 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 246 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 246 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 246 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 246 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 246 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 246 Mlda 23 Accuracy 0.7307692307692307\n",
            "Mpca 246 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 246 Mlda 25 Accuracy 0.75\n",
            "Mpca 246 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 246 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 246 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 246 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 246 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 246 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 246 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 246 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 246 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 246 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 246 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 246 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 246 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 246 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 246 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 246 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 246 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 246 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 246 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 246 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 246 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 246 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 246 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 246 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 246 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 247 Mlda 2 Accuracy 0.25\n",
            "Mpca 247 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 247 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 247 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 247 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 247 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 247 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 247 Mlda 9 Accuracy 0.6538461538461539\n",
            "Mpca 247 Mlda 10 Accuracy 0.6923076923076923\n",
            "Mpca 247 Mlda 11 Accuracy 0.6923076923076923\n",
            "Mpca 247 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 247 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 247 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 247 Mlda 15 Accuracy 0.75\n",
            "Mpca 247 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 17 Accuracy 0.75\n",
            "Mpca 247 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 247 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 247 Mlda 26 Accuracy 0.75\n",
            "Mpca 247 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 247 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 247 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 247 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 247 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 247 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 247 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 247 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 247 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 247 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 247 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 247 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 247 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 247 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 247 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 48 Accuracy 0.875\n",
            "Mpca 247 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 247 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 248 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 248 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 248 Mlda 3 Accuracy 0.27884615384615385\n",
            "Mpca 248 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 248 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 248 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 248 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 248 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 248 Mlda 9 Accuracy 0.6538461538461539\n",
            "Mpca 248 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 248 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 248 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 248 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 248 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 248 Mlda 15 Accuracy 0.7211538461538461\n",
            "Mpca 248 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 248 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 248 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 248 Mlda 19 Accuracy 0.75\n",
            "Mpca 248 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 248 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 248 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 248 Mlda 23 Accuracy 0.75\n",
            "Mpca 248 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 248 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 248 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 248 Mlda 27 Accuracy 0.7403846153846154\n",
            "Mpca 248 Mlda 28 Accuracy 0.75\n",
            "Mpca 248 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 248 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 248 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 248 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 248 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 248 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 248 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 248 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 248 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 248 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 248 Mlda 48 Accuracy 0.875\n",
            "Mpca 248 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 248 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 249 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 249 Mlda 2 Accuracy 0.23076923076923078\n",
            "Mpca 249 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 249 Mlda 4 Accuracy 0.375\n",
            "Mpca 249 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 249 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 249 Mlda 7 Accuracy 0.5384615384615384\n",
            "Mpca 249 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 249 Mlda 9 Accuracy 0.625\n",
            "Mpca 249 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 249 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 249 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 249 Mlda 13 Accuracy 0.7307692307692307\n",
            "Mpca 249 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 249 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 249 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 249 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 249 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 249 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 249 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 249 Mlda 21 Accuracy 0.75\n",
            "Mpca 249 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 249 Mlda 23 Accuracy 0.75\n",
            "Mpca 249 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 249 Mlda 25 Accuracy 0.75\n",
            "Mpca 249 Mlda 26 Accuracy 0.75\n",
            "Mpca 249 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 249 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 249 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 249 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 249 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 249 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 249 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 249 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 249 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 249 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 249 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 249 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 249 Mlda 39 Accuracy 0.8653846153846154\n",
            "Mpca 249 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 249 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 249 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 249 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 249 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 249 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 249 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 249 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 249 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 249 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 249 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 250 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 250 Mlda 2 Accuracy 0.2403846153846154\n",
            "Mpca 250 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 250 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 250 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 250 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 250 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 250 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 250 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 250 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 250 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 250 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 250 Mlda 13 Accuracy 0.7403846153846154\n",
            "Mpca 250 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 250 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 250 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 250 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 250 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 250 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 250 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 250 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 250 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 250 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 250 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 250 Mlda 25 Accuracy 0.75\n",
            "Mpca 250 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 250 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 250 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 250 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 250 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 250 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 250 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 250 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 250 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 250 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 250 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 250 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 250 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 250 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 250 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 250 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 250 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 250 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 250 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 250 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 250 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 250 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 250 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 250 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 250 Mlda 50 Accuracy 0.875\n",
            "Mpca 251 Mlda 1 Accuracy 0.1346153846153846\n",
            "Mpca 251 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 251 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 251 Mlda 4 Accuracy 0.33653846153846156\n",
            "Mpca 251 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 251 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 251 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 251 Mlda 8 Accuracy 0.5576923076923077\n",
            "Mpca 251 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 251 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 251 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 251 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 251 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 251 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 251 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 251 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 251 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 251 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 251 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 251 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 251 Mlda 21 Accuracy 0.75\n",
            "Mpca 251 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 251 Mlda 23 Accuracy 0.75\n",
            "Mpca 251 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 251 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 251 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 251 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 251 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 251 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 251 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 251 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 251 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 251 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 251 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 251 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 251 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 251 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 251 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 251 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 251 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 251 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 251 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 251 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 251 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 251 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 251 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 251 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 251 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 251 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 251 Mlda 50 Accuracy 0.875\n",
            "Mpca 252 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 252 Mlda 2 Accuracy 0.20192307692307693\n",
            "Mpca 252 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 252 Mlda 4 Accuracy 0.375\n",
            "Mpca 252 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 252 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 252 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 252 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 252 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 252 Mlda 10 Accuracy 0.6538461538461539\n",
            "Mpca 252 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 252 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 252 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 252 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 252 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 252 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 252 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 252 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 252 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 252 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 252 Mlda 21 Accuracy 0.75\n",
            "Mpca 252 Mlda 22 Accuracy 0.75\n",
            "Mpca 252 Mlda 23 Accuracy 0.75\n",
            "Mpca 252 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 252 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 252 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 252 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 252 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 252 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 252 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 252 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 252 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 252 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 252 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 252 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 252 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 252 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 252 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 252 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 252 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 252 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 252 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 252 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 253 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 253 Mlda 2 Accuracy 0.21153846153846154\n",
            "Mpca 253 Mlda 3 Accuracy 0.2980769230769231\n",
            "Mpca 253 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 253 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 253 Mlda 6 Accuracy 0.4807692307692308\n",
            "Mpca 253 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 253 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 253 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 253 Mlda 10 Accuracy 0.6826923076923077\n",
            "Mpca 253 Mlda 11 Accuracy 0.7019230769230769\n",
            "Mpca 253 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 253 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 253 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 253 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 253 Mlda 16 Accuracy 0.7596153846153846\n",
            "Mpca 253 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 253 Mlda 18 Accuracy 0.75\n",
            "Mpca 253 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 253 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 253 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 253 Mlda 22 Accuracy 0.75\n",
            "Mpca 253 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 253 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 253 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 253 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 253 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 253 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 253 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 253 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 253 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 253 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 253 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 253 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 253 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 253 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 253 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 253 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 253 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 253 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 253 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 253 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 253 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 254 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 254 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 254 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 254 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 254 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 254 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 254 Mlda 7 Accuracy 0.5480769230769231\n",
            "Mpca 254 Mlda 8 Accuracy 0.5769230769230769\n",
            "Mpca 254 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 254 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 254 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 254 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 254 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 254 Mlda 14 Accuracy 0.7307692307692307\n",
            "Mpca 254 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 254 Mlda 16 Accuracy 0.7692307692307693\n",
            "Mpca 254 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 254 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 254 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 254 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 254 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 254 Mlda 22 Accuracy 0.75\n",
            "Mpca 254 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 254 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 254 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 254 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 254 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 254 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 254 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 254 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 254 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 254 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 254 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 254 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 254 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 254 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 254 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 254 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 254 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 254 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 254 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 254 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 254 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 254 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 254 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 254 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 254 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 254 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 254 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 254 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 255 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 255 Mlda 2 Accuracy 0.22115384615384615\n",
            "Mpca 255 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 255 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 255 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 255 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 255 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 255 Mlda 8 Accuracy 0.5961538461538461\n",
            "Mpca 255 Mlda 9 Accuracy 0.6153846153846154\n",
            "Mpca 255 Mlda 10 Accuracy 0.625\n",
            "Mpca 255 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 255 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 255 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 255 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 255 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 255 Mlda 16 Accuracy 0.75\n",
            "Mpca 255 Mlda 17 Accuracy 0.7692307692307693\n",
            "Mpca 255 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 255 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 255 Mlda 20 Accuracy 0.75\n",
            "Mpca 255 Mlda 21 Accuracy 0.75\n",
            "Mpca 255 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 255 Mlda 23 Accuracy 0.75\n",
            "Mpca 255 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 255 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 255 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 255 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 255 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 255 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 255 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 255 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 255 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 255 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 255 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 255 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 255 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 255 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 255 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 255 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 255 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 255 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 255 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 255 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 255 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 255 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 255 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 255 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 255 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 255 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 255 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 256 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 256 Mlda 2 Accuracy 0.2403846153846154\n",
            "Mpca 256 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 256 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 256 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 256 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 256 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 256 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 256 Mlda 9 Accuracy 0.6346153846153846\n",
            "Mpca 256 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 256 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 256 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 256 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 256 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 256 Mlda 15 Accuracy 0.7307692307692307\n",
            "Mpca 256 Mlda 16 Accuracy 0.7403846153846154\n",
            "Mpca 256 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 256 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 256 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 256 Mlda 20 Accuracy 0.75\n",
            "Mpca 256 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 256 Mlda 22 Accuracy 0.75\n",
            "Mpca 256 Mlda 23 Accuracy 0.75\n",
            "Mpca 256 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 256 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 256 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 256 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 256 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 256 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 256 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 256 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 256 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 256 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 256 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 256 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 256 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 256 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 256 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 256 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 256 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 256 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 256 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 256 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 256 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 256 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 256 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 256 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 256 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 256 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 256 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 257 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 257 Mlda 2 Accuracy 0.21153846153846154\n",
            "Mpca 257 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 257 Mlda 4 Accuracy 0.36538461538461536\n",
            "Mpca 257 Mlda 5 Accuracy 0.4423076923076923\n",
            "Mpca 257 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 257 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 257 Mlda 8 Accuracy 0.5865384615384616\n",
            "Mpca 257 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 257 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 257 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 257 Mlda 12 Accuracy 0.7115384615384616\n",
            "Mpca 257 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 257 Mlda 14 Accuracy 0.7115384615384616\n",
            "Mpca 257 Mlda 15 Accuracy 0.7403846153846154\n",
            "Mpca 257 Mlda 16 Accuracy 0.75\n",
            "Mpca 257 Mlda 17 Accuracy 0.7788461538461539\n",
            "Mpca 257 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 257 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 257 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 257 Mlda 21 Accuracy 0.75\n",
            "Mpca 257 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 257 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 257 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 257 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 257 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 257 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 257 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 257 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 257 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 257 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 257 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 257 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 257 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 257 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 257 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 257 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 257 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 257 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 257 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 257 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 257 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 257 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 257 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 257 Mlda 45 Accuracy 0.8173076923076923\n",
            "Mpca 257 Mlda 46 Accuracy 0.8269230769230769\n",
            "Mpca 257 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 257 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 257 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 257 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 258 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 258 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 258 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 258 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 258 Mlda 5 Accuracy 0.41346153846153844\n",
            "Mpca 258 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 258 Mlda 7 Accuracy 0.4807692307692308\n",
            "Mpca 258 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 258 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 258 Mlda 10 Accuracy 0.625\n",
            "Mpca 258 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 258 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 258 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 258 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 258 Mlda 15 Accuracy 0.7596153846153846\n",
            "Mpca 258 Mlda 16 Accuracy 0.7788461538461539\n",
            "Mpca 258 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 258 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 258 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 258 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 258 Mlda 21 Accuracy 0.75\n",
            "Mpca 258 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 258 Mlda 23 Accuracy 0.75\n",
            "Mpca 258 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 258 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 258 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 258 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 258 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 258 Mlda 29 Accuracy 0.8269230769230769\n",
            "Mpca 258 Mlda 30 Accuracy 0.8269230769230769\n",
            "Mpca 258 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 258 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 258 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 258 Mlda 34 Accuracy 0.8461538461538461\n",
            "Mpca 258 Mlda 35 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 36 Accuracy 0.8461538461538461\n",
            "Mpca 258 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 258 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 258 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 258 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 258 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 44 Accuracy 0.875\n",
            "Mpca 258 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 258 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 258 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 259 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 259 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 259 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 259 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 259 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 259 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 259 Mlda 7 Accuracy 0.5\n",
            "Mpca 259 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 259 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 259 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 259 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 259 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 259 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 259 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 259 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 259 Mlda 16 Accuracy 0.7307692307692307\n",
            "Mpca 259 Mlda 17 Accuracy 0.7211538461538461\n",
            "Mpca 259 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 259 Mlda 19 Accuracy 0.7403846153846154\n",
            "Mpca 259 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 259 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 259 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 259 Mlda 23 Accuracy 0.75\n",
            "Mpca 259 Mlda 24 Accuracy 0.75\n",
            "Mpca 259 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 259 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 259 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 259 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 259 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 259 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 259 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 259 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 259 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 259 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 259 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 259 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 259 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 259 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 259 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 259 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 259 Mlda 41 Accuracy 0.8653846153846154\n",
            "Mpca 259 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 259 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 259 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 259 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 259 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 259 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 259 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 259 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 259 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 260 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 260 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 260 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 260 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 260 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 260 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 260 Mlda 7 Accuracy 0.5\n",
            "Mpca 260 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 260 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 260 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 260 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 260 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 260 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 260 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 260 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 260 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 260 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 260 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 260 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 260 Mlda 20 Accuracy 0.75\n",
            "Mpca 260 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 260 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 260 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 260 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 260 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 260 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 260 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 260 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 260 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 260 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 260 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 260 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 260 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 260 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 260 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 260 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 260 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 260 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 260 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 260 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 260 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 260 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 260 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 260 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 260 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 260 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 260 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 260 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 260 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 260 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 261 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 261 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 261 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 261 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 261 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 261 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 261 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 261 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 261 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 261 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 261 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 261 Mlda 12 Accuracy 0.6923076923076923\n",
            "Mpca 261 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 261 Mlda 14 Accuracy 0.6730769230769231\n",
            "Mpca 261 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 261 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 261 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 261 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 261 Mlda 19 Accuracy 0.75\n",
            "Mpca 261 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 261 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 261 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 261 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 261 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 261 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 261 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 261 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 261 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 261 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 261 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 261 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 261 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 261 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 261 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 261 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 261 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 261 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 261 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 261 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 261 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 261 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 261 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 261 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 261 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 261 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 261 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 261 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 261 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 261 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 261 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 262 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 262 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 262 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 262 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 262 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 262 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 262 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 262 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 262 Mlda 9 Accuracy 0.6057692307692307\n",
            "Mpca 262 Mlda 10 Accuracy 0.625\n",
            "Mpca 262 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 262 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 262 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 262 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 262 Mlda 15 Accuracy 0.7115384615384616\n",
            "Mpca 262 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 262 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 262 Mlda 18 Accuracy 0.7403846153846154\n",
            "Mpca 262 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 262 Mlda 20 Accuracy 0.7596153846153846\n",
            "Mpca 262 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 262 Mlda 22 Accuracy 0.75\n",
            "Mpca 262 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 262 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 262 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 262 Mlda 26 Accuracy 0.75\n",
            "Mpca 262 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 262 Mlda 28 Accuracy 0.7692307692307693\n",
            "Mpca 262 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 262 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 262 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 262 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 262 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 262 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 262 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 262 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 262 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 262 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 262 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 262 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 262 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 262 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 262 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 262 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 262 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 262 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 262 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 262 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 262 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 262 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 263 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 263 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 263 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 263 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 263 Mlda 5 Accuracy 0.375\n",
            "Mpca 263 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 263 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 263 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 263 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 263 Mlda 10 Accuracy 0.625\n",
            "Mpca 263 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 263 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 263 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 263 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 263 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 263 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 263 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 263 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 263 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 263 Mlda 20 Accuracy 0.7692307692307693\n",
            "Mpca 263 Mlda 21 Accuracy 0.7596153846153846\n",
            "Mpca 263 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 263 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 263 Mlda 24 Accuracy 0.75\n",
            "Mpca 263 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 263 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 263 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 263 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 263 Mlda 29 Accuracy 0.7596153846153846\n",
            "Mpca 263 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 263 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 263 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 263 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 263 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 263 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 263 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 263 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 263 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 263 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 263 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 263 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 263 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 263 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 263 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 263 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 263 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 263 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 263 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 263 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 263 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 264 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 264 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 264 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 264 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 264 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 264 Mlda 7 Accuracy 0.4519230769230769\n",
            "Mpca 264 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 264 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 264 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 264 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 264 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 264 Mlda 13 Accuracy 0.7115384615384616\n",
            "Mpca 264 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 264 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 264 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 264 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 264 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 264 Mlda 19 Accuracy 0.7596153846153846\n",
            "Mpca 264 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 264 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 264 Mlda 22 Accuracy 0.75\n",
            "Mpca 264 Mlda 23 Accuracy 0.75\n",
            "Mpca 264 Mlda 24 Accuracy 0.75\n",
            "Mpca 264 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 264 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 264 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 264 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 264 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 264 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 264 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 264 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 264 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 264 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 264 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 264 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 264 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 264 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 264 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 264 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 264 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 264 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 264 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 264 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 265 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 265 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 265 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 265 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 265 Mlda 5 Accuracy 0.375\n",
            "Mpca 265 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 265 Mlda 7 Accuracy 0.4519230769230769\n",
            "Mpca 265 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 265 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 265 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 265 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 265 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 265 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 265 Mlda 14 Accuracy 0.6730769230769231\n",
            "Mpca 265 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 265 Mlda 16 Accuracy 0.7115384615384616\n",
            "Mpca 265 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 265 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 265 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 265 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 265 Mlda 21 Accuracy 0.7692307692307693\n",
            "Mpca 265 Mlda 22 Accuracy 0.75\n",
            "Mpca 265 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 265 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 265 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 265 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 265 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 265 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 265 Mlda 29 Accuracy 0.7692307692307693\n",
            "Mpca 265 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 265 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 265 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 265 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 265 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 265 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 265 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 265 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 265 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 265 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 265 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 265 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 265 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 265 Mlda 43 Accuracy 0.875\n",
            "Mpca 265 Mlda 44 Accuracy 0.875\n",
            "Mpca 265 Mlda 45 Accuracy 0.875\n",
            "Mpca 265 Mlda 46 Accuracy 0.875\n",
            "Mpca 265 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 265 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 265 Mlda 49 Accuracy 0.875\n",
            "Mpca 265 Mlda 50 Accuracy 0.875\n",
            "Mpca 266 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 266 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 266 Mlda 3 Accuracy 0.25\n",
            "Mpca 266 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 266 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 266 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 266 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 266 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 266 Mlda 9 Accuracy 0.5576923076923077\n",
            "Mpca 266 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 266 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 266 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 266 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 266 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 266 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 266 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 266 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 266 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 266 Mlda 19 Accuracy 0.7692307692307693\n",
            "Mpca 266 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 266 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 266 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 266 Mlda 23 Accuracy 0.75\n",
            "Mpca 266 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 266 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 266 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 266 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 266 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 266 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 266 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 266 Mlda 31 Accuracy 0.8365384615384616\n",
            "Mpca 266 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 266 Mlda 33 Accuracy 0.8461538461538461\n",
            "Mpca 266 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 266 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 266 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 266 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 266 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 266 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 266 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 266 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 266 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 266 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 266 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 266 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 266 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 266 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 266 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 266 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 266 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 267 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 267 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 267 Mlda 3 Accuracy 0.25\n",
            "Mpca 267 Mlda 4 Accuracy 0.3076923076923077\n",
            "Mpca 267 Mlda 5 Accuracy 0.375\n",
            "Mpca 267 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 267 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 267 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 267 Mlda 9 Accuracy 0.5673076923076923\n",
            "Mpca 267 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 267 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 267 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 267 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 267 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 267 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 267 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 267 Mlda 17 Accuracy 0.7403846153846154\n",
            "Mpca 267 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 267 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 267 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 267 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 267 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 267 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 267 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 267 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 267 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 267 Mlda 27 Accuracy 0.75\n",
            "Mpca 267 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 267 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 267 Mlda 30 Accuracy 0.8461538461538461\n",
            "Mpca 267 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 267 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 267 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 267 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 267 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 267 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 267 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 267 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 267 Mlda 39 Accuracy 0.8461538461538461\n",
            "Mpca 267 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 267 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 267 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 267 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 268 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 268 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 268 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 268 Mlda 5 Accuracy 0.375\n",
            "Mpca 268 Mlda 6 Accuracy 0.4519230769230769\n",
            "Mpca 268 Mlda 7 Accuracy 0.5288461538461539\n",
            "Mpca 268 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 268 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 268 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 268 Mlda 11 Accuracy 0.6634615384615384\n",
            "Mpca 268 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 268 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 268 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 268 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 268 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 268 Mlda 17 Accuracy 0.75\n",
            "Mpca 268 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 268 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 268 Mlda 20 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 268 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 268 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 268 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 268 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 268 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 268 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 268 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 268 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 268 Mlda 36 Accuracy 0.8076923076923077\n",
            "Mpca 268 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 268 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 268 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 268 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 268 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 268 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 268 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 268 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 269 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 269 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 269 Mlda 3 Accuracy 0.25961538461538464\n",
            "Mpca 269 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 269 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 269 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 269 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 269 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 269 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 269 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 269 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 269 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 269 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 269 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 269 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 269 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 269 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 269 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 269 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 269 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 269 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 269 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 269 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 269 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 269 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 269 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 269 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 269 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 269 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 269 Mlda 30 Accuracy 0.8173076923076923\n",
            "Mpca 269 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 269 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 269 Mlda 33 Accuracy 0.8365384615384616\n",
            "Mpca 269 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 269 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 269 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 269 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 269 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 269 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 269 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 269 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 269 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 269 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 269 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 269 Mlda 45 Accuracy 0.875\n",
            "Mpca 269 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 269 Mlda 47 Accuracy 0.875\n",
            "Mpca 269 Mlda 48 Accuracy 0.875\n",
            "Mpca 269 Mlda 49 Accuracy 0.875\n",
            "Mpca 269 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 270 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 270 Mlda 2 Accuracy 0.125\n",
            "Mpca 270 Mlda 3 Accuracy 0.25\n",
            "Mpca 270 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 270 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 270 Mlda 6 Accuracy 0.46153846153846156\n",
            "Mpca 270 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 270 Mlda 8 Accuracy 0.5673076923076923\n",
            "Mpca 270 Mlda 9 Accuracy 0.5961538461538461\n",
            "Mpca 270 Mlda 10 Accuracy 0.6442307692307693\n",
            "Mpca 270 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 270 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 270 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 270 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 270 Mlda 15 Accuracy 0.6730769230769231\n",
            "Mpca 270 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 270 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 270 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 270 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 270 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 270 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 270 Mlda 22 Accuracy 0.7692307692307693\n",
            "Mpca 270 Mlda 23 Accuracy 0.7788461538461539\n",
            "Mpca 270 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 270 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 270 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 270 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 270 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 270 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 270 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 270 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 270 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 270 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 270 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 270 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 270 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 270 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 270 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 270 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 270 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 270 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 270 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 270 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 270 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 270 Mlda 45 Accuracy 0.875\n",
            "Mpca 270 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 270 Mlda 47 Accuracy 0.875\n",
            "Mpca 270 Mlda 48 Accuracy 0.8846153846153846\n",
            "Mpca 270 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 270 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 271 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 271 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 271 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 271 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 271 Mlda 5 Accuracy 0.375\n",
            "Mpca 271 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 271 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 271 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 271 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 271 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 271 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 271 Mlda 12 Accuracy 0.7019230769230769\n",
            "Mpca 271 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 271 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 271 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 271 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 271 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 271 Mlda 18 Accuracy 0.7788461538461539\n",
            "Mpca 271 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 271 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 271 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 271 Mlda 22 Accuracy 0.7788461538461539\n",
            "Mpca 271 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 271 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 271 Mlda 25 Accuracy 0.8076923076923077\n",
            "Mpca 271 Mlda 26 Accuracy 0.8076923076923077\n",
            "Mpca 271 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 271 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 271 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 271 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 271 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 271 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 271 Mlda 33 Accuracy 0.8269230769230769\n",
            "Mpca 271 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 271 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 271 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 271 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 271 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 271 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 271 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 271 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 271 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 271 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 271 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 271 Mlda 45 Accuracy 0.875\n",
            "Mpca 271 Mlda 46 Accuracy 0.875\n",
            "Mpca 271 Mlda 47 Accuracy 0.8846153846153846\n",
            "Mpca 271 Mlda 48 Accuracy 0.8846153846153846\n",
            "Mpca 271 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 271 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 272 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 272 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 272 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 272 Mlda 4 Accuracy 0.3557692307692308\n",
            "Mpca 272 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 272 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 272 Mlda 7 Accuracy 0.5\n",
            "Mpca 272 Mlda 8 Accuracy 0.5480769230769231\n",
            "Mpca 272 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 272 Mlda 10 Accuracy 0.6346153846153846\n",
            "Mpca 272 Mlda 11 Accuracy 0.6826923076923077\n",
            "Mpca 272 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 272 Mlda 13 Accuracy 0.6826923076923077\n",
            "Mpca 272 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 272 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 272 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 272 Mlda 17 Accuracy 0.7596153846153846\n",
            "Mpca 272 Mlda 18 Accuracy 0.7884615384615384\n",
            "Mpca 272 Mlda 19 Accuracy 0.7788461538461539\n",
            "Mpca 272 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 272 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 272 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 272 Mlda 23 Accuracy 0.75\n",
            "Mpca 272 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 272 Mlda 25 Accuracy 0.7980769230769231\n",
            "Mpca 272 Mlda 26 Accuracy 0.7980769230769231\n",
            "Mpca 272 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 272 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 272 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 272 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 272 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 272 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 272 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 272 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 272 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 272 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 272 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 272 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 272 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 272 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 272 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 272 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 272 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 272 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 272 Mlda 45 Accuracy 0.8846153846153846\n",
            "Mpca 272 Mlda 46 Accuracy 0.875\n",
            "Mpca 272 Mlda 47 Accuracy 0.8846153846153846\n",
            "Mpca 272 Mlda 48 Accuracy 0.875\n",
            "Mpca 272 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 272 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 273 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 273 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 273 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 273 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 273 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 273 Mlda 6 Accuracy 0.4326923076923077\n",
            "Mpca 273 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 273 Mlda 8 Accuracy 0.5384615384615384\n",
            "Mpca 273 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 273 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 273 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 273 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 273 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 273 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 273 Mlda 15 Accuracy 0.6538461538461539\n",
            "Mpca 273 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 273 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 273 Mlda 18 Accuracy 0.7692307692307693\n",
            "Mpca 273 Mlda 19 Accuracy 0.8076923076923077\n",
            "Mpca 273 Mlda 20 Accuracy 0.7884615384615384\n",
            "Mpca 273 Mlda 21 Accuracy 0.7980769230769231\n",
            "Mpca 273 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 273 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 273 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 273 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 273 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 273 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 273 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 273 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 273 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 273 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 273 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 273 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 273 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 273 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 273 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 273 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 273 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 273 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 273 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 273 Mlda 41 Accuracy 0.8557692307692307\n",
            "Mpca 273 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 273 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 273 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 273 Mlda 45 Accuracy 0.875\n",
            "Mpca 273 Mlda 46 Accuracy 0.875\n",
            "Mpca 273 Mlda 47 Accuracy 0.875\n",
            "Mpca 273 Mlda 48 Accuracy 0.875\n",
            "Mpca 273 Mlda 49 Accuracy 0.875\n",
            "Mpca 273 Mlda 50 Accuracy 0.875\n",
            "Mpca 274 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 274 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 274 Mlda 3 Accuracy 0.2692307692307692\n",
            "Mpca 274 Mlda 4 Accuracy 0.34615384615384615\n",
            "Mpca 274 Mlda 5 Accuracy 0.3942307692307692\n",
            "Mpca 274 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 274 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 274 Mlda 8 Accuracy 0.5288461538461539\n",
            "Mpca 274 Mlda 9 Accuracy 0.5865384615384616\n",
            "Mpca 274 Mlda 10 Accuracy 0.6057692307692307\n",
            "Mpca 274 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 274 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 274 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 274 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 274 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 274 Mlda 16 Accuracy 0.6826923076923077\n",
            "Mpca 274 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 274 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 274 Mlda 19 Accuracy 0.7980769230769231\n",
            "Mpca 274 Mlda 20 Accuracy 0.7980769230769231\n",
            "Mpca 274 Mlda 21 Accuracy 0.7884615384615384\n",
            "Mpca 274 Mlda 22 Accuracy 0.75\n",
            "Mpca 274 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 274 Mlda 24 Accuracy 0.7788461538461539\n",
            "Mpca 274 Mlda 25 Accuracy 0.7884615384615384\n",
            "Mpca 274 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 274 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 274 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 274 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 274 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 274 Mlda 31 Accuracy 0.8269230769230769\n",
            "Mpca 274 Mlda 32 Accuracy 0.8461538461538461\n",
            "Mpca 274 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 274 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 274 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 274 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 274 Mlda 37 Accuracy 0.8557692307692307\n",
            "Mpca 274 Mlda 38 Accuracy 0.8557692307692307\n",
            "Mpca 274 Mlda 39 Accuracy 0.8557692307692307\n",
            "Mpca 274 Mlda 40 Accuracy 0.8557692307692307\n",
            "Mpca 274 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 274 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 274 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 274 Mlda 44 Accuracy 0.8653846153846154\n",
            "Mpca 274 Mlda 45 Accuracy 0.875\n",
            "Mpca 274 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 274 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 274 Mlda 48 Accuracy 0.875\n",
            "Mpca 274 Mlda 49 Accuracy 0.8846153846153846\n",
            "Mpca 274 Mlda 50 Accuracy 0.8846153846153846\n",
            "Mpca 275 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 275 Mlda 2 Accuracy 0.125\n",
            "Mpca 275 Mlda 3 Accuracy 0.25\n",
            "Mpca 275 Mlda 4 Accuracy 0.3173076923076923\n",
            "Mpca 275 Mlda 5 Accuracy 0.40384615384615385\n",
            "Mpca 275 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 275 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 275 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 275 Mlda 9 Accuracy 0.5769230769230769\n",
            "Mpca 275 Mlda 10 Accuracy 0.625\n",
            "Mpca 275 Mlda 11 Accuracy 0.6730769230769231\n",
            "Mpca 275 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 275 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 275 Mlda 14 Accuracy 0.6730769230769231\n",
            "Mpca 275 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 275 Mlda 16 Accuracy 0.7211538461538461\n",
            "Mpca 275 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 275 Mlda 18 Accuracy 0.7596153846153846\n",
            "Mpca 275 Mlda 19 Accuracy 0.7884615384615384\n",
            "Mpca 275 Mlda 20 Accuracy 0.7788461538461539\n",
            "Mpca 275 Mlda 21 Accuracy 0.8076923076923077\n",
            "Mpca 275 Mlda 22 Accuracy 0.8076923076923077\n",
            "Mpca 275 Mlda 23 Accuracy 0.75\n",
            "Mpca 275 Mlda 24 Accuracy 0.7692307692307693\n",
            "Mpca 275 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 275 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 275 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 275 Mlda 28 Accuracy 0.8076923076923077\n",
            "Mpca 275 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 275 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 275 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 275 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 275 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 275 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 275 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 275 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 275 Mlda 37 Accuracy 0.8461538461538461\n",
            "Mpca 275 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 275 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 275 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 275 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 275 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 275 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 275 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 275 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 275 Mlda 46 Accuracy 0.8653846153846154\n",
            "Mpca 275 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 275 Mlda 48 Accuracy 0.8653846153846154\n",
            "Mpca 275 Mlda 49 Accuracy 0.8653846153846154\n",
            "Mpca 275 Mlda 50 Accuracy 0.8653846153846154\n",
            "Mpca 276 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 276 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 276 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 276 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 276 Mlda 5 Accuracy 0.4519230769230769\n",
            "Mpca 276 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 276 Mlda 7 Accuracy 0.5192307692307693\n",
            "Mpca 276 Mlda 8 Accuracy 0.4807692307692308\n",
            "Mpca 276 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 276 Mlda 10 Accuracy 0.6153846153846154\n",
            "Mpca 276 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 276 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 276 Mlda 13 Accuracy 0.6923076923076923\n",
            "Mpca 276 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 276 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 276 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 276 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 276 Mlda 18 Accuracy 0.7019230769230769\n",
            "Mpca 276 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 276 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 276 Mlda 21 Accuracy 0.75\n",
            "Mpca 276 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 276 Mlda 23 Accuracy 0.75\n",
            "Mpca 276 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 276 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 276 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 276 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 276 Mlda 28 Accuracy 0.8173076923076923\n",
            "Mpca 276 Mlda 29 Accuracy 0.8173076923076923\n",
            "Mpca 276 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 276 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 276 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 276 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 276 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 276 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 276 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 276 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 276 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 276 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 276 Mlda 40 Accuracy 0.8461538461538461\n",
            "Mpca 276 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 276 Mlda 42 Accuracy 0.8653846153846154\n",
            "Mpca 276 Mlda 43 Accuracy 0.8653846153846154\n",
            "Mpca 276 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 276 Mlda 45 Accuracy 0.8653846153846154\n",
            "Mpca 276 Mlda 46 Accuracy 0.875\n",
            "Mpca 276 Mlda 47 Accuracy 0.875\n",
            "Mpca 276 Mlda 48 Accuracy 0.875\n",
            "Mpca 276 Mlda 49 Accuracy 0.875\n",
            "Mpca 276 Mlda 50 Accuracy 0.875\n",
            "Mpca 277 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 277 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 277 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 277 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 277 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 277 Mlda 6 Accuracy 0.49038461538461536\n",
            "Mpca 277 Mlda 7 Accuracy 0.5096153846153846\n",
            "Mpca 277 Mlda 8 Accuracy 0.4807692307692308\n",
            "Mpca 277 Mlda 9 Accuracy 0.5288461538461539\n",
            "Mpca 277 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 277 Mlda 11 Accuracy 0.6442307692307693\n",
            "Mpca 277 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 277 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 277 Mlda 14 Accuracy 0.6730769230769231\n",
            "Mpca 277 Mlda 15 Accuracy 0.6730769230769231\n",
            "Mpca 277 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 277 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 277 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 277 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 277 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 277 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 277 Mlda 22 Accuracy 0.75\n",
            "Mpca 277 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 277 Mlda 24 Accuracy 0.75\n",
            "Mpca 277 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 277 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 277 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 277 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 277 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 277 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 277 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 277 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 277 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 277 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 277 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 277 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 277 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 277 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 277 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 277 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 277 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 277 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 277 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 277 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 277 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 277 Mlda 46 Accuracy 0.875\n",
            "Mpca 277 Mlda 47 Accuracy 0.8653846153846154\n",
            "Mpca 277 Mlda 48 Accuracy 0.875\n",
            "Mpca 277 Mlda 49 Accuracy 0.875\n",
            "Mpca 277 Mlda 50 Accuracy 0.875\n",
            "Mpca 278 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 278 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 278 Mlda 3 Accuracy 0.25\n",
            "Mpca 278 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 278 Mlda 5 Accuracy 0.4230769230769231\n",
            "Mpca 278 Mlda 6 Accuracy 0.47115384615384615\n",
            "Mpca 278 Mlda 7 Accuracy 0.47115384615384615\n",
            "Mpca 278 Mlda 8 Accuracy 0.4807692307692308\n",
            "Mpca 278 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 278 Mlda 10 Accuracy 0.5865384615384616\n",
            "Mpca 278 Mlda 11 Accuracy 0.6538461538461539\n",
            "Mpca 278 Mlda 12 Accuracy 0.6730769230769231\n",
            "Mpca 278 Mlda 13 Accuracy 0.7019230769230769\n",
            "Mpca 278 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 278 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 278 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 278 Mlda 17 Accuracy 0.7307692307692307\n",
            "Mpca 278 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 278 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 278 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 278 Mlda 21 Accuracy 0.75\n",
            "Mpca 278 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 278 Mlda 23 Accuracy 0.7596153846153846\n",
            "Mpca 278 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 278 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 278 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 278 Mlda 27 Accuracy 0.7692307692307693\n",
            "Mpca 278 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 278 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 278 Mlda 30 Accuracy 0.7980769230769231\n",
            "Mpca 278 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 278 Mlda 32 Accuracy 0.8269230769230769\n",
            "Mpca 278 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 278 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 278 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 278 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 278 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 278 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 278 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 278 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 278 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 278 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 278 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 278 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 278 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 278 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 278 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 278 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 278 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 278 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 279 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 279 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 279 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 279 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 279 Mlda 5 Accuracy 0.38461538461538464\n",
            "Mpca 279 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 279 Mlda 7 Accuracy 0.49038461538461536\n",
            "Mpca 279 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 279 Mlda 9 Accuracy 0.5288461538461539\n",
            "Mpca 279 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 279 Mlda 11 Accuracy 0.6346153846153846\n",
            "Mpca 279 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 279 Mlda 13 Accuracy 0.7211538461538461\n",
            "Mpca 279 Mlda 14 Accuracy 0.6826923076923077\n",
            "Mpca 279 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 279 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 279 Mlda 17 Accuracy 0.6923076923076923\n",
            "Mpca 279 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 279 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 279 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 279 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 279 Mlda 22 Accuracy 0.75\n",
            "Mpca 279 Mlda 23 Accuracy 0.75\n",
            "Mpca 279 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 279 Mlda 25 Accuracy 0.75\n",
            "Mpca 279 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 279 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 279 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 279 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 279 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 279 Mlda 31 Accuracy 0.8173076923076923\n",
            "Mpca 279 Mlda 32 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 33 Accuracy 0.8173076923076923\n",
            "Mpca 279 Mlda 34 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 36 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 37 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 279 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 279 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 42 Accuracy 0.8557692307692307\n",
            "Mpca 279 Mlda 43 Accuracy 0.8557692307692307\n",
            "Mpca 279 Mlda 44 Accuracy 0.8557692307692307\n",
            "Mpca 279 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 279 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 279 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 279 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 279 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 280 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 280 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 280 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 280 Mlda 5 Accuracy 0.36538461538461536\n",
            "Mpca 280 Mlda 6 Accuracy 0.4423076923076923\n",
            "Mpca 280 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 280 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 280 Mlda 9 Accuracy 0.49038461538461536\n",
            "Mpca 280 Mlda 10 Accuracy 0.5576923076923077\n",
            "Mpca 280 Mlda 11 Accuracy 0.6057692307692307\n",
            "Mpca 280 Mlda 12 Accuracy 0.6634615384615384\n",
            "Mpca 280 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 280 Mlda 14 Accuracy 0.7211538461538461\n",
            "Mpca 280 Mlda 15 Accuracy 0.7019230769230769\n",
            "Mpca 280 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 280 Mlda 17 Accuracy 0.7019230769230769\n",
            "Mpca 280 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 280 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 280 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 280 Mlda 21 Accuracy 0.75\n",
            "Mpca 280 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 280 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 280 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 280 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 280 Mlda 26 Accuracy 0.7692307692307693\n",
            "Mpca 280 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 280 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 280 Mlda 29 Accuracy 0.8076923076923077\n",
            "Mpca 280 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 280 Mlda 31 Accuracy 0.8076923076923077\n",
            "Mpca 280 Mlda 32 Accuracy 0.8173076923076923\n",
            "Mpca 280 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 280 Mlda 34 Accuracy 0.8269230769230769\n",
            "Mpca 280 Mlda 35 Accuracy 0.8076923076923077\n",
            "Mpca 280 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 280 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 280 Mlda 38 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 280 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 280 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 280 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 280 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 281 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 281 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 281 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 281 Mlda 4 Accuracy 0.22115384615384615\n",
            "Mpca 281 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 281 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 281 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 281 Mlda 8 Accuracy 0.4423076923076923\n",
            "Mpca 281 Mlda 9 Accuracy 0.49038461538461536\n",
            "Mpca 281 Mlda 10 Accuracy 0.5384615384615384\n",
            "Mpca 281 Mlda 11 Accuracy 0.5961538461538461\n",
            "Mpca 281 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 281 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 281 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 281 Mlda 15 Accuracy 0.6923076923076923\n",
            "Mpca 281 Mlda 16 Accuracy 0.6923076923076923\n",
            "Mpca 281 Mlda 17 Accuracy 0.6923076923076923\n",
            "Mpca 281 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 281 Mlda 19 Accuracy 0.7307692307692307\n",
            "Mpca 281 Mlda 20 Accuracy 0.75\n",
            "Mpca 281 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 281 Mlda 22 Accuracy 0.7403846153846154\n",
            "Mpca 281 Mlda 23 Accuracy 0.7307692307692307\n",
            "Mpca 281 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 281 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 281 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 281 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 281 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 281 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 281 Mlda 30 Accuracy 0.8076923076923077\n",
            "Mpca 281 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 281 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 281 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 281 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 281 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 281 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 281 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 281 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 281 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 281 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 281 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 281 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 281 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 281 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 281 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 281 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 281 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 281 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 281 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 281 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 282 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 282 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 282 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 282 Mlda 4 Accuracy 0.2403846153846154\n",
            "Mpca 282 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 282 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 282 Mlda 7 Accuracy 0.38461538461538464\n",
            "Mpca 282 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 282 Mlda 9 Accuracy 0.5\n",
            "Mpca 282 Mlda 10 Accuracy 0.5576923076923077\n",
            "Mpca 282 Mlda 11 Accuracy 0.5961538461538461\n",
            "Mpca 282 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 282 Mlda 13 Accuracy 0.6730769230769231\n",
            "Mpca 282 Mlda 14 Accuracy 0.7019230769230769\n",
            "Mpca 282 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 282 Mlda 16 Accuracy 0.7019230769230769\n",
            "Mpca 282 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 282 Mlda 18 Accuracy 0.6923076923076923\n",
            "Mpca 282 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 282 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 282 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 282 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 282 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 282 Mlda 24 Accuracy 0.7307692307692307\n",
            "Mpca 282 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 282 Mlda 26 Accuracy 0.75\n",
            "Mpca 282 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 282 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 282 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 282 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 282 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 282 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 282 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 282 Mlda 34 Accuracy 0.8076923076923077\n",
            "Mpca 282 Mlda 35 Accuracy 0.8173076923076923\n",
            "Mpca 282 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 282 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 282 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 282 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 282 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 282 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 282 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 282 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 282 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 282 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 282 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 282 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 282 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 282 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 282 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 283 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 283 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 283 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 283 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 283 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 283 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 283 Mlda 7 Accuracy 0.41346153846153844\n",
            "Mpca 283 Mlda 8 Accuracy 0.5\n",
            "Mpca 283 Mlda 9 Accuracy 0.5096153846153846\n",
            "Mpca 283 Mlda 10 Accuracy 0.5673076923076923\n",
            "Mpca 283 Mlda 11 Accuracy 0.5769230769230769\n",
            "Mpca 283 Mlda 12 Accuracy 0.625\n",
            "Mpca 283 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 283 Mlda 14 Accuracy 0.6923076923076923\n",
            "Mpca 283 Mlda 15 Accuracy 0.6826923076923077\n",
            "Mpca 283 Mlda 16 Accuracy 0.6826923076923077\n",
            "Mpca 283 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 283 Mlda 18 Accuracy 0.7211538461538461\n",
            "Mpca 283 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 283 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 283 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 283 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 283 Mlda 23 Accuracy 0.75\n",
            "Mpca 283 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 283 Mlda 25 Accuracy 0.7596153846153846\n",
            "Mpca 283 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 283 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 283 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 283 Mlda 29 Accuracy 0.7980769230769231\n",
            "Mpca 283 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 283 Mlda 31 Accuracy 0.7980769230769231\n",
            "Mpca 283 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 283 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 283 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 283 Mlda 35 Accuracy 0.8365384615384616\n",
            "Mpca 283 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 283 Mlda 37 Accuracy 0.8269230769230769\n",
            "Mpca 283 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 283 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 283 Mlda 40 Accuracy 0.8365384615384616\n",
            "Mpca 283 Mlda 41 Accuracy 0.8461538461538461\n",
            "Mpca 283 Mlda 42 Accuracy 0.8461538461538461\n",
            "Mpca 283 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 283 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 283 Mlda 45 Accuracy 0.8557692307692307\n",
            "Mpca 283 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 283 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 283 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 283 Mlda 49 Accuracy 0.8557692307692307\n",
            "Mpca 283 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 284 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 284 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 284 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 284 Mlda 4 Accuracy 0.2403846153846154\n",
            "Mpca 284 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 284 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 284 Mlda 7 Accuracy 0.4230769230769231\n",
            "Mpca 284 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 284 Mlda 9 Accuracy 0.5288461538461539\n",
            "Mpca 284 Mlda 10 Accuracy 0.5480769230769231\n",
            "Mpca 284 Mlda 11 Accuracy 0.5961538461538461\n",
            "Mpca 284 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 284 Mlda 13 Accuracy 0.6442307692307693\n",
            "Mpca 284 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 284 Mlda 15 Accuracy 0.6442307692307693\n",
            "Mpca 284 Mlda 16 Accuracy 0.6634615384615384\n",
            "Mpca 284 Mlda 17 Accuracy 0.6923076923076923\n",
            "Mpca 284 Mlda 18 Accuracy 0.7019230769230769\n",
            "Mpca 284 Mlda 19 Accuracy 0.7019230769230769\n",
            "Mpca 284 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 284 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 284 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 284 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 284 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 284 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 284 Mlda 26 Accuracy 0.75\n",
            "Mpca 284 Mlda 27 Accuracy 0.7596153846153846\n",
            "Mpca 284 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 284 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 284 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 284 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 284 Mlda 32 Accuracy 0.8076923076923077\n",
            "Mpca 284 Mlda 33 Accuracy 0.8076923076923077\n",
            "Mpca 284 Mlda 34 Accuracy 0.8173076923076923\n",
            "Mpca 284 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 284 Mlda 36 Accuracy 0.8269230769230769\n",
            "Mpca 284 Mlda 37 Accuracy 0.8173076923076923\n",
            "Mpca 284 Mlda 38 Accuracy 0.8365384615384616\n",
            "Mpca 284 Mlda 39 Accuracy 0.8365384615384616\n",
            "Mpca 284 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 284 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 284 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 284 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 284 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 284 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 284 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 284 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 284 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 284 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 284 Mlda 50 Accuracy 0.8557692307692307\n",
            "Mpca 285 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 285 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 285 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 285 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 285 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 285 Mlda 6 Accuracy 0.375\n",
            "Mpca 285 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 285 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 285 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 285 Mlda 10 Accuracy 0.5673076923076923\n",
            "Mpca 285 Mlda 11 Accuracy 0.6057692307692307\n",
            "Mpca 285 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 285 Mlda 13 Accuracy 0.6634615384615384\n",
            "Mpca 285 Mlda 14 Accuracy 0.6442307692307693\n",
            "Mpca 285 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 285 Mlda 16 Accuracy 0.6634615384615384\n",
            "Mpca 285 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 285 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 285 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 285 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 285 Mlda 21 Accuracy 0.7115384615384616\n",
            "Mpca 285 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 285 Mlda 23 Accuracy 0.75\n",
            "Mpca 285 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 285 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 285 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 285 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 285 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 285 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 285 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 285 Mlda 31 Accuracy 0.7692307692307693\n",
            "Mpca 285 Mlda 32 Accuracy 0.7980769230769231\n",
            "Mpca 285 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 285 Mlda 34 Accuracy 0.7788461538461539\n",
            "Mpca 285 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 285 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 285 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 285 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 285 Mlda 39 Accuracy 0.8269230769230769\n",
            "Mpca 285 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 285 Mlda 41 Accuracy 0.8365384615384616\n",
            "Mpca 285 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 285 Mlda 43 Accuracy 0.8461538461538461\n",
            "Mpca 285 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 285 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 285 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 285 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 285 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 285 Mlda 49 Accuracy 0.8365384615384616\n",
            "Mpca 285 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 286 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 286 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 286 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 286 Mlda 4 Accuracy 0.19230769230769232\n",
            "Mpca 286 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 286 Mlda 6 Accuracy 0.375\n",
            "Mpca 286 Mlda 7 Accuracy 0.41346153846153844\n",
            "Mpca 286 Mlda 8 Accuracy 0.5\n",
            "Mpca 286 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 286 Mlda 10 Accuracy 0.5961538461538461\n",
            "Mpca 286 Mlda 11 Accuracy 0.625\n",
            "Mpca 286 Mlda 12 Accuracy 0.6442307692307693\n",
            "Mpca 286 Mlda 13 Accuracy 0.6153846153846154\n",
            "Mpca 286 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 286 Mlda 15 Accuracy 0.6538461538461539\n",
            "Mpca 286 Mlda 16 Accuracy 0.6538461538461539\n",
            "Mpca 286 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 286 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 286 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 286 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 286 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 286 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 286 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 286 Mlda 24 Accuracy 0.75\n",
            "Mpca 286 Mlda 25 Accuracy 0.75\n",
            "Mpca 286 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 286 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 286 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 286 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 286 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 286 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 286 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 286 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 286 Mlda 34 Accuracy 0.7884615384615384\n",
            "Mpca 286 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 286 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 286 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 286 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 286 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 286 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 286 Mlda 41 Accuracy 0.8173076923076923\n",
            "Mpca 286 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 286 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 286 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 286 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 286 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 286 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 286 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 286 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 286 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 287 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 287 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 287 Mlda 3 Accuracy 0.16346153846153846\n",
            "Mpca 287 Mlda 4 Accuracy 0.2403846153846154\n",
            "Mpca 287 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 287 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 287 Mlda 7 Accuracy 0.41346153846153844\n",
            "Mpca 287 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 287 Mlda 9 Accuracy 0.5384615384615384\n",
            "Mpca 287 Mlda 10 Accuracy 0.5576923076923077\n",
            "Mpca 287 Mlda 11 Accuracy 0.6057692307692307\n",
            "Mpca 287 Mlda 12 Accuracy 0.6346153846153846\n",
            "Mpca 287 Mlda 13 Accuracy 0.625\n",
            "Mpca 287 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 287 Mlda 15 Accuracy 0.6442307692307693\n",
            "Mpca 287 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 287 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 287 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 287 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 287 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 287 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 287 Mlda 22 Accuracy 0.7211538461538461\n",
            "Mpca 287 Mlda 23 Accuracy 0.7403846153846154\n",
            "Mpca 287 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 287 Mlda 25 Accuracy 0.7692307692307693\n",
            "Mpca 287 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 287 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 287 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 287 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 287 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 287 Mlda 31 Accuracy 0.7884615384615384\n",
            "Mpca 287 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 287 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 287 Mlda 34 Accuracy 0.7884615384615384\n",
            "Mpca 287 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 287 Mlda 36 Accuracy 0.7980769230769231\n",
            "Mpca 287 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 287 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 287 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 287 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 287 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 287 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 287 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 287 Mlda 44 Accuracy 0.8461538461538461\n",
            "Mpca 287 Mlda 45 Accuracy 0.8365384615384616\n",
            "Mpca 287 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 287 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 287 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 287 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 287 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 288 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 288 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 288 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 288 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 288 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 288 Mlda 6 Accuracy 0.41346153846153844\n",
            "Mpca 288 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 288 Mlda 8 Accuracy 0.5192307692307693\n",
            "Mpca 288 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 288 Mlda 10 Accuracy 0.5384615384615384\n",
            "Mpca 288 Mlda 11 Accuracy 0.6057692307692307\n",
            "Mpca 288 Mlda 12 Accuracy 0.6538461538461539\n",
            "Mpca 288 Mlda 13 Accuracy 0.6057692307692307\n",
            "Mpca 288 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 288 Mlda 15 Accuracy 0.6442307692307693\n",
            "Mpca 288 Mlda 16 Accuracy 0.6634615384615384\n",
            "Mpca 288 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 288 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 288 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 288 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 288 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 288 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 288 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 288 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 288 Mlda 25 Accuracy 0.75\n",
            "Mpca 288 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 288 Mlda 27 Accuracy 0.8076923076923077\n",
            "Mpca 288 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 288 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 288 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 288 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 288 Mlda 32 Accuracy 0.7788461538461539\n",
            "Mpca 288 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 288 Mlda 34 Accuracy 0.7980769230769231\n",
            "Mpca 288 Mlda 35 Accuracy 0.8269230769230769\n",
            "Mpca 288 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 288 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 288 Mlda 38 Accuracy 0.8173076923076923\n",
            "Mpca 288 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 288 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 288 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 288 Mlda 42 Accuracy 0.8365384615384616\n",
            "Mpca 288 Mlda 43 Accuracy 0.8269230769230769\n",
            "Mpca 288 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 288 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 288 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 288 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 288 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 288 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 288 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 289 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 289 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 289 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 289 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 289 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 289 Mlda 6 Accuracy 0.4230769230769231\n",
            "Mpca 289 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 289 Mlda 8 Accuracy 0.5096153846153846\n",
            "Mpca 289 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 289 Mlda 10 Accuracy 0.5480769230769231\n",
            "Mpca 289 Mlda 11 Accuracy 0.6057692307692307\n",
            "Mpca 289 Mlda 12 Accuracy 0.6826923076923077\n",
            "Mpca 289 Mlda 13 Accuracy 0.6442307692307693\n",
            "Mpca 289 Mlda 14 Accuracy 0.6538461538461539\n",
            "Mpca 289 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 289 Mlda 16 Accuracy 0.6634615384615384\n",
            "Mpca 289 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 289 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 289 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 289 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 289 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 289 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 289 Mlda 23 Accuracy 0.7692307692307693\n",
            "Mpca 289 Mlda 24 Accuracy 0.7596153846153846\n",
            "Mpca 289 Mlda 25 Accuracy 0.7788461538461539\n",
            "Mpca 289 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 289 Mlda 27 Accuracy 0.7980769230769231\n",
            "Mpca 289 Mlda 28 Accuracy 0.7980769230769231\n",
            "Mpca 289 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 289 Mlda 30 Accuracy 0.7692307692307693\n",
            "Mpca 289 Mlda 31 Accuracy 0.7692307692307693\n",
            "Mpca 289 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 289 Mlda 33 Accuracy 0.7980769230769231\n",
            "Mpca 289 Mlda 34 Accuracy 0.7884615384615384\n",
            "Mpca 289 Mlda 35 Accuracy 0.7980769230769231\n",
            "Mpca 289 Mlda 36 Accuracy 0.8173076923076923\n",
            "Mpca 289 Mlda 37 Accuracy 0.8076923076923077\n",
            "Mpca 289 Mlda 38 Accuracy 0.8269230769230769\n",
            "Mpca 289 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 289 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 289 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 289 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 289 Mlda 43 Accuracy 0.8365384615384616\n",
            "Mpca 289 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 289 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 289 Mlda 46 Accuracy 0.8557692307692307\n",
            "Mpca 289 Mlda 47 Accuracy 0.8557692307692307\n",
            "Mpca 289 Mlda 48 Accuracy 0.8557692307692307\n",
            "Mpca 289 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 289 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 290 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 290 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 290 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 290 Mlda 4 Accuracy 0.19230769230769232\n",
            "Mpca 290 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 290 Mlda 6 Accuracy 0.38461538461538464\n",
            "Mpca 290 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 290 Mlda 8 Accuracy 0.47115384615384615\n",
            "Mpca 290 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 290 Mlda 10 Accuracy 0.5384615384615384\n",
            "Mpca 290 Mlda 11 Accuracy 0.5865384615384616\n",
            "Mpca 290 Mlda 12 Accuracy 0.6057692307692307\n",
            "Mpca 290 Mlda 13 Accuracy 0.625\n",
            "Mpca 290 Mlda 14 Accuracy 0.625\n",
            "Mpca 290 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 290 Mlda 16 Accuracy 0.6538461538461539\n",
            "Mpca 290 Mlda 17 Accuracy 0.6442307692307693\n",
            "Mpca 290 Mlda 18 Accuracy 0.6923076923076923\n",
            "Mpca 290 Mlda 19 Accuracy 0.7211538461538461\n",
            "Mpca 290 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 290 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 290 Mlda 22 Accuracy 0.75\n",
            "Mpca 290 Mlda 23 Accuracy 0.75\n",
            "Mpca 290 Mlda 24 Accuracy 0.7403846153846154\n",
            "Mpca 290 Mlda 25 Accuracy 0.7403846153846154\n",
            "Mpca 290 Mlda 26 Accuracy 0.7788461538461539\n",
            "Mpca 290 Mlda 27 Accuracy 0.7884615384615384\n",
            "Mpca 290 Mlda 28 Accuracy 0.7884615384615384\n",
            "Mpca 290 Mlda 29 Accuracy 0.7884615384615384\n",
            "Mpca 290 Mlda 30 Accuracy 0.7884615384615384\n",
            "Mpca 290 Mlda 31 Accuracy 0.7788461538461539\n",
            "Mpca 290 Mlda 32 Accuracy 0.7884615384615384\n",
            "Mpca 290 Mlda 33 Accuracy 0.7788461538461539\n",
            "Mpca 290 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 290 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 290 Mlda 36 Accuracy 0.7692307692307693\n",
            "Mpca 290 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 290 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 290 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 290 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 290 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 290 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 290 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 290 Mlda 44 Accuracy 0.8365384615384616\n",
            "Mpca 290 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 290 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 290 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 290 Mlda 48 Accuracy 0.8461538461538461\n",
            "Mpca 290 Mlda 49 Accuracy 0.8461538461538461\n",
            "Mpca 290 Mlda 50 Accuracy 0.8461538461538461\n",
            "Mpca 291 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 291 Mlda 2 Accuracy 0.125\n",
            "Mpca 291 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 291 Mlda 4 Accuracy 0.19230769230769232\n",
            "Mpca 291 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 291 Mlda 6 Accuracy 0.375\n",
            "Mpca 291 Mlda 7 Accuracy 0.41346153846153844\n",
            "Mpca 291 Mlda 8 Accuracy 0.49038461538461536\n",
            "Mpca 291 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 291 Mlda 10 Accuracy 0.5288461538461539\n",
            "Mpca 291 Mlda 11 Accuracy 0.6153846153846154\n",
            "Mpca 291 Mlda 12 Accuracy 0.5865384615384616\n",
            "Mpca 291 Mlda 13 Accuracy 0.625\n",
            "Mpca 291 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 291 Mlda 15 Accuracy 0.6730769230769231\n",
            "Mpca 291 Mlda 16 Accuracy 0.6730769230769231\n",
            "Mpca 291 Mlda 17 Accuracy 0.7115384615384616\n",
            "Mpca 291 Mlda 18 Accuracy 0.7019230769230769\n",
            "Mpca 291 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 291 Mlda 20 Accuracy 0.7403846153846154\n",
            "Mpca 291 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 291 Mlda 22 Accuracy 0.7596153846153846\n",
            "Mpca 291 Mlda 23 Accuracy 0.75\n",
            "Mpca 291 Mlda 24 Accuracy 0.75\n",
            "Mpca 291 Mlda 25 Accuracy 0.75\n",
            "Mpca 291 Mlda 26 Accuracy 0.7884615384615384\n",
            "Mpca 291 Mlda 27 Accuracy 0.7788461538461539\n",
            "Mpca 291 Mlda 28 Accuracy 0.7788461538461539\n",
            "Mpca 291 Mlda 29 Accuracy 0.7788461538461539\n",
            "Mpca 291 Mlda 30 Accuracy 0.7788461538461539\n",
            "Mpca 291 Mlda 31 Accuracy 0.7596153846153846\n",
            "Mpca 291 Mlda 32 Accuracy 0.7692307692307693\n",
            "Mpca 291 Mlda 33 Accuracy 0.7884615384615384\n",
            "Mpca 291 Mlda 34 Accuracy 0.7788461538461539\n",
            "Mpca 291 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 291 Mlda 36 Accuracy 0.7788461538461539\n",
            "Mpca 291 Mlda 37 Accuracy 0.7980769230769231\n",
            "Mpca 291 Mlda 38 Accuracy 0.8076923076923077\n",
            "Mpca 291 Mlda 39 Accuracy 0.8076923076923077\n",
            "Mpca 291 Mlda 40 Accuracy 0.8173076923076923\n",
            "Mpca 291 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 291 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 291 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 291 Mlda 44 Accuracy 0.8269230769230769\n",
            "Mpca 291 Mlda 45 Accuracy 0.8269230769230769\n",
            "Mpca 291 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 291 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 291 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 291 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 291 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 292 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 292 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 292 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 292 Mlda 4 Accuracy 0.23076923076923078\n",
            "Mpca 292 Mlda 5 Accuracy 0.27884615384615385\n",
            "Mpca 292 Mlda 6 Accuracy 0.375\n",
            "Mpca 292 Mlda 7 Accuracy 0.41346153846153844\n",
            "Mpca 292 Mlda 8 Accuracy 0.47115384615384615\n",
            "Mpca 292 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 292 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 292 Mlda 11 Accuracy 0.5769230769230769\n",
            "Mpca 292 Mlda 12 Accuracy 0.5961538461538461\n",
            "Mpca 292 Mlda 13 Accuracy 0.6057692307692307\n",
            "Mpca 292 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 292 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 292 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 292 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 292 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 292 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 292 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 292 Mlda 21 Accuracy 0.7307692307692307\n",
            "Mpca 292 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 292 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 292 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 292 Mlda 25 Accuracy 0.7211538461538461\n",
            "Mpca 292 Mlda 26 Accuracy 0.7596153846153846\n",
            "Mpca 292 Mlda 27 Accuracy 0.7403846153846154\n",
            "Mpca 292 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 292 Mlda 29 Accuracy 0.75\n",
            "Mpca 292 Mlda 30 Accuracy 0.75\n",
            "Mpca 292 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 292 Mlda 32 Accuracy 0.7403846153846154\n",
            "Mpca 292 Mlda 33 Accuracy 0.7692307692307693\n",
            "Mpca 292 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 292 Mlda 35 Accuracy 0.7692307692307693\n",
            "Mpca 292 Mlda 36 Accuracy 0.7692307692307693\n",
            "Mpca 292 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 292 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 292 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 292 Mlda 40 Accuracy 0.8269230769230769\n",
            "Mpca 292 Mlda 41 Accuracy 0.8269230769230769\n",
            "Mpca 292 Mlda 42 Accuracy 0.8269230769230769\n",
            "Mpca 292 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 292 Mlda 44 Accuracy 0.8173076923076923\n",
            "Mpca 292 Mlda 45 Accuracy 0.8461538461538461\n",
            "Mpca 292 Mlda 46 Accuracy 0.8461538461538461\n",
            "Mpca 292 Mlda 47 Accuracy 0.8461538461538461\n",
            "Mpca 292 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 292 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 292 Mlda 50 Accuracy 0.8365384615384616\n",
            "Mpca 293 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 293 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 293 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 293 Mlda 4 Accuracy 0.25\n",
            "Mpca 293 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 293 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 293 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 293 Mlda 8 Accuracy 0.4519230769230769\n",
            "Mpca 293 Mlda 9 Accuracy 0.5480769230769231\n",
            "Mpca 293 Mlda 10 Accuracy 0.5769230769230769\n",
            "Mpca 293 Mlda 11 Accuracy 0.5865384615384616\n",
            "Mpca 293 Mlda 12 Accuracy 0.5961538461538461\n",
            "Mpca 293 Mlda 13 Accuracy 0.5961538461538461\n",
            "Mpca 293 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 293 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 293 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 293 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 293 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 293 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 293 Mlda 20 Accuracy 0.7019230769230769\n",
            "Mpca 293 Mlda 21 Accuracy 0.7403846153846154\n",
            "Mpca 293 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 293 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 293 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 293 Mlda 25 Accuracy 0.7307692307692307\n",
            "Mpca 293 Mlda 26 Accuracy 0.7403846153846154\n",
            "Mpca 293 Mlda 27 Accuracy 0.75\n",
            "Mpca 293 Mlda 28 Accuracy 0.7596153846153846\n",
            "Mpca 293 Mlda 29 Accuracy 0.75\n",
            "Mpca 293 Mlda 30 Accuracy 0.75\n",
            "Mpca 293 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 293 Mlda 32 Accuracy 0.7596153846153846\n",
            "Mpca 293 Mlda 33 Accuracy 0.7596153846153846\n",
            "Mpca 293 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 293 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 293 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 293 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 293 Mlda 38 Accuracy 0.7980769230769231\n",
            "Mpca 293 Mlda 39 Accuracy 0.8173076923076923\n",
            "Mpca 293 Mlda 40 Accuracy 0.8076923076923077\n",
            "Mpca 293 Mlda 41 Accuracy 0.8076923076923077\n",
            "Mpca 293 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 293 Mlda 43 Accuracy 0.8173076923076923\n",
            "Mpca 293 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 293 Mlda 45 Accuracy 0.8076923076923077\n",
            "Mpca 293 Mlda 46 Accuracy 0.8365384615384616\n",
            "Mpca 293 Mlda 47 Accuracy 0.8365384615384616\n",
            "Mpca 293 Mlda 48 Accuracy 0.8365384615384616\n",
            "Mpca 293 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 293 Mlda 50 Accuracy 0.8173076923076923\n",
            "Mpca 294 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 294 Mlda 2 Accuracy 0.125\n",
            "Mpca 294 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 294 Mlda 4 Accuracy 0.25\n",
            "Mpca 294 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 294 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 294 Mlda 7 Accuracy 0.38461538461538464\n",
            "Mpca 294 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 294 Mlda 9 Accuracy 0.5\n",
            "Mpca 294 Mlda 10 Accuracy 0.5673076923076923\n",
            "Mpca 294 Mlda 11 Accuracy 0.5480769230769231\n",
            "Mpca 294 Mlda 12 Accuracy 0.5673076923076923\n",
            "Mpca 294 Mlda 13 Accuracy 0.5673076923076923\n",
            "Mpca 294 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 294 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 294 Mlda 16 Accuracy 0.625\n",
            "Mpca 294 Mlda 17 Accuracy 0.6442307692307693\n",
            "Mpca 294 Mlda 18 Accuracy 0.6923076923076923\n",
            "Mpca 294 Mlda 19 Accuracy 0.7019230769230769\n",
            "Mpca 294 Mlda 20 Accuracy 0.7211538461538461\n",
            "Mpca 294 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 294 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 294 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 294 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 294 Mlda 25 Accuracy 0.7211538461538461\n",
            "Mpca 294 Mlda 26 Accuracy 0.7307692307692307\n",
            "Mpca 294 Mlda 27 Accuracy 0.7211538461538461\n",
            "Mpca 294 Mlda 28 Accuracy 0.7403846153846154\n",
            "Mpca 294 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 294 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 294 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 294 Mlda 32 Accuracy 0.7403846153846154\n",
            "Mpca 294 Mlda 33 Accuracy 0.7692307692307693\n",
            "Mpca 294 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 294 Mlda 35 Accuracy 0.75\n",
            "Mpca 294 Mlda 36 Accuracy 0.75\n",
            "Mpca 294 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 294 Mlda 38 Accuracy 0.7692307692307693\n",
            "Mpca 294 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 294 Mlda 40 Accuracy 0.7884615384615384\n",
            "Mpca 294 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 294 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 294 Mlda 43 Accuracy 0.7884615384615384\n",
            "Mpca 294 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 294 Mlda 45 Accuracy 0.7884615384615384\n",
            "Mpca 294 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 294 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 294 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 294 Mlda 49 Accuracy 0.8076923076923077\n",
            "Mpca 294 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 295 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 295 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 295 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 295 Mlda 4 Accuracy 0.25\n",
            "Mpca 295 Mlda 5 Accuracy 0.25961538461538464\n",
            "Mpca 295 Mlda 6 Accuracy 0.3173076923076923\n",
            "Mpca 295 Mlda 7 Accuracy 0.3942307692307692\n",
            "Mpca 295 Mlda 8 Accuracy 0.4519230769230769\n",
            "Mpca 295 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 295 Mlda 10 Accuracy 0.5\n",
            "Mpca 295 Mlda 11 Accuracy 0.5576923076923077\n",
            "Mpca 295 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 295 Mlda 13 Accuracy 0.5480769230769231\n",
            "Mpca 295 Mlda 14 Accuracy 0.5769230769230769\n",
            "Mpca 295 Mlda 15 Accuracy 0.5961538461538461\n",
            "Mpca 295 Mlda 16 Accuracy 0.6153846153846154\n",
            "Mpca 295 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 295 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 295 Mlda 19 Accuracy 0.7019230769230769\n",
            "Mpca 295 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 295 Mlda 21 Accuracy 0.7115384615384616\n",
            "Mpca 295 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 295 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 295 Mlda 24 Accuracy 0.7115384615384616\n",
            "Mpca 295 Mlda 25 Accuracy 0.7211538461538461\n",
            "Mpca 295 Mlda 26 Accuracy 0.75\n",
            "Mpca 295 Mlda 27 Accuracy 0.75\n",
            "Mpca 295 Mlda 28 Accuracy 0.75\n",
            "Mpca 295 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 295 Mlda 30 Accuracy 0.7403846153846154\n",
            "Mpca 295 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 295 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 295 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 295 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 295 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 295 Mlda 36 Accuracy 0.7403846153846154\n",
            "Mpca 295 Mlda 37 Accuracy 0.75\n",
            "Mpca 295 Mlda 38 Accuracy 0.75\n",
            "Mpca 295 Mlda 39 Accuracy 0.75\n",
            "Mpca 295 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 295 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 295 Mlda 42 Accuracy 0.8173076923076923\n",
            "Mpca 295 Mlda 43 Accuracy 0.8076923076923077\n",
            "Mpca 295 Mlda 44 Accuracy 0.8076923076923077\n",
            "Mpca 295 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 295 Mlda 46 Accuracy 0.8173076923076923\n",
            "Mpca 295 Mlda 47 Accuracy 0.8269230769230769\n",
            "Mpca 295 Mlda 48 Accuracy 0.8173076923076923\n",
            "Mpca 295 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 295 Mlda 50 Accuracy 0.8269230769230769\n",
            "Mpca 296 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 296 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 296 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 296 Mlda 4 Accuracy 0.25\n",
            "Mpca 296 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 296 Mlda 6 Accuracy 0.3076923076923077\n",
            "Mpca 296 Mlda 7 Accuracy 0.375\n",
            "Mpca 296 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 296 Mlda 9 Accuracy 0.4807692307692308\n",
            "Mpca 296 Mlda 10 Accuracy 0.5\n",
            "Mpca 296 Mlda 11 Accuracy 0.5480769230769231\n",
            "Mpca 296 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 296 Mlda 13 Accuracy 0.5769230769230769\n",
            "Mpca 296 Mlda 14 Accuracy 0.5769230769230769\n",
            "Mpca 296 Mlda 15 Accuracy 0.625\n",
            "Mpca 296 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 296 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 296 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 296 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 296 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 296 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 296 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 296 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 296 Mlda 24 Accuracy 0.6730769230769231\n",
            "Mpca 296 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 296 Mlda 26 Accuracy 0.7115384615384616\n",
            "Mpca 296 Mlda 27 Accuracy 0.7307692307692307\n",
            "Mpca 296 Mlda 28 Accuracy 0.75\n",
            "Mpca 296 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 296 Mlda 30 Accuracy 0.7211538461538461\n",
            "Mpca 296 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 296 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 296 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 296 Mlda 34 Accuracy 0.7403846153846154\n",
            "Mpca 296 Mlda 35 Accuracy 0.75\n",
            "Mpca 296 Mlda 36 Accuracy 0.75\n",
            "Mpca 296 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 296 Mlda 38 Accuracy 0.7692307692307693\n",
            "Mpca 296 Mlda 39 Accuracy 0.75\n",
            "Mpca 296 Mlda 40 Accuracy 0.7692307692307693\n",
            "Mpca 296 Mlda 41 Accuracy 0.7692307692307693\n",
            "Mpca 296 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 296 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 296 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 296 Mlda 45 Accuracy 0.7884615384615384\n",
            "Mpca 296 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 296 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 296 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 296 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 296 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 297 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 297 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 297 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 297 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 297 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 297 Mlda 6 Accuracy 0.27884615384615385\n",
            "Mpca 297 Mlda 7 Accuracy 0.375\n",
            "Mpca 297 Mlda 8 Accuracy 0.46153846153846156\n",
            "Mpca 297 Mlda 9 Accuracy 0.49038461538461536\n",
            "Mpca 297 Mlda 10 Accuracy 0.5096153846153846\n",
            "Mpca 297 Mlda 11 Accuracy 0.5480769230769231\n",
            "Mpca 297 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 297 Mlda 13 Accuracy 0.6057692307692307\n",
            "Mpca 297 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 297 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 297 Mlda 16 Accuracy 0.6634615384615384\n",
            "Mpca 297 Mlda 17 Accuracy 0.6826923076923077\n",
            "Mpca 297 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 297 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 297 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 297 Mlda 21 Accuracy 0.6923076923076923\n",
            "Mpca 297 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 297 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 297 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 297 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 297 Mlda 26 Accuracy 0.7211538461538461\n",
            "Mpca 297 Mlda 27 Accuracy 0.7403846153846154\n",
            "Mpca 297 Mlda 28 Accuracy 0.75\n",
            "Mpca 297 Mlda 29 Accuracy 0.7403846153846154\n",
            "Mpca 297 Mlda 30 Accuracy 0.7211538461538461\n",
            "Mpca 297 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 297 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 297 Mlda 33 Accuracy 0.75\n",
            "Mpca 297 Mlda 34 Accuracy 0.7403846153846154\n",
            "Mpca 297 Mlda 35 Accuracy 0.75\n",
            "Mpca 297 Mlda 36 Accuracy 0.75\n",
            "Mpca 297 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 297 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 297 Mlda 39 Accuracy 0.7884615384615384\n",
            "Mpca 297 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 297 Mlda 41 Accuracy 0.7884615384615384\n",
            "Mpca 297 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 297 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 297 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 297 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 297 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 297 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 297 Mlda 48 Accuracy 0.7980769230769231\n",
            "Mpca 297 Mlda 49 Accuracy 0.8173076923076923\n",
            "Mpca 297 Mlda 50 Accuracy 0.7980769230769231\n",
            "Mpca 298 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 298 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 298 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 298 Mlda 4 Accuracy 0.25\n",
            "Mpca 298 Mlda 5 Accuracy 0.25961538461538464\n",
            "Mpca 298 Mlda 6 Accuracy 0.3269230769230769\n",
            "Mpca 298 Mlda 7 Accuracy 0.36538461538461536\n",
            "Mpca 298 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 298 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 298 Mlda 10 Accuracy 0.5096153846153846\n",
            "Mpca 298 Mlda 11 Accuracy 0.5673076923076923\n",
            "Mpca 298 Mlda 12 Accuracy 0.5769230769230769\n",
            "Mpca 298 Mlda 13 Accuracy 0.5961538461538461\n",
            "Mpca 298 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 298 Mlda 15 Accuracy 0.625\n",
            "Mpca 298 Mlda 16 Accuracy 0.6634615384615384\n",
            "Mpca 298 Mlda 17 Accuracy 0.6923076923076923\n",
            "Mpca 298 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 298 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 298 Mlda 20 Accuracy 0.7019230769230769\n",
            "Mpca 298 Mlda 21 Accuracy 0.6923076923076923\n",
            "Mpca 298 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 298 Mlda 23 Accuracy 0.7019230769230769\n",
            "Mpca 298 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 298 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 298 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 298 Mlda 27 Accuracy 0.7307692307692307\n",
            "Mpca 298 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 298 Mlda 29 Accuracy 0.7403846153846154\n",
            "Mpca 298 Mlda 30 Accuracy 0.7211538461538461\n",
            "Mpca 298 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 298 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 298 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 298 Mlda 34 Accuracy 0.7403846153846154\n",
            "Mpca 298 Mlda 35 Accuracy 0.75\n",
            "Mpca 298 Mlda 36 Accuracy 0.75\n",
            "Mpca 298 Mlda 37 Accuracy 0.75\n",
            "Mpca 298 Mlda 38 Accuracy 0.75\n",
            "Mpca 298 Mlda 39 Accuracy 0.7692307692307693\n",
            "Mpca 298 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 298 Mlda 41 Accuracy 0.7788461538461539\n",
            "Mpca 298 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 298 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 298 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 298 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 298 Mlda 46 Accuracy 0.8076923076923077\n",
            "Mpca 298 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 298 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 298 Mlda 49 Accuracy 0.8076923076923077\n",
            "Mpca 298 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 299 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 299 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 299 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 299 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 299 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 299 Mlda 6 Accuracy 0.3269230769230769\n",
            "Mpca 299 Mlda 7 Accuracy 0.375\n",
            "Mpca 299 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 299 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 299 Mlda 10 Accuracy 0.5096153846153846\n",
            "Mpca 299 Mlda 11 Accuracy 0.5480769230769231\n",
            "Mpca 299 Mlda 12 Accuracy 0.5673076923076923\n",
            "Mpca 299 Mlda 13 Accuracy 0.5865384615384616\n",
            "Mpca 299 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 299 Mlda 15 Accuracy 0.5961538461538461\n",
            "Mpca 299 Mlda 16 Accuracy 0.625\n",
            "Mpca 299 Mlda 17 Accuracy 0.6442307692307693\n",
            "Mpca 299 Mlda 18 Accuracy 0.6538461538461539\n",
            "Mpca 299 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 299 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 299 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 299 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 299 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 299 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 299 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 299 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 299 Mlda 27 Accuracy 0.7115384615384616\n",
            "Mpca 299 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 299 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 299 Mlda 30 Accuracy 0.6923076923076923\n",
            "Mpca 299 Mlda 31 Accuracy 0.6923076923076923\n",
            "Mpca 299 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 299 Mlda 33 Accuracy 0.7115384615384616\n",
            "Mpca 299 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 299 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 299 Mlda 36 Accuracy 0.7403846153846154\n",
            "Mpca 299 Mlda 37 Accuracy 0.75\n",
            "Mpca 299 Mlda 38 Accuracy 0.75\n",
            "Mpca 299 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 299 Mlda 40 Accuracy 0.7692307692307693\n",
            "Mpca 299 Mlda 41 Accuracy 0.7692307692307693\n",
            "Mpca 299 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 48 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 299 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 300 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 300 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 300 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 300 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 300 Mlda 5 Accuracy 0.375\n",
            "Mpca 300 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 300 Mlda 7 Accuracy 0.3557692307692308\n",
            "Mpca 300 Mlda 8 Accuracy 0.41346153846153844\n",
            "Mpca 300 Mlda 9 Accuracy 0.5\n",
            "Mpca 300 Mlda 10 Accuracy 0.5192307692307693\n",
            "Mpca 300 Mlda 11 Accuracy 0.5576923076923077\n",
            "Mpca 300 Mlda 12 Accuracy 0.5673076923076923\n",
            "Mpca 300 Mlda 13 Accuracy 0.6057692307692307\n",
            "Mpca 300 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 300 Mlda 15 Accuracy 0.6057692307692307\n",
            "Mpca 300 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 300 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 300 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 300 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 300 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 300 Mlda 21 Accuracy 0.6730769230769231\n",
            "Mpca 300 Mlda 22 Accuracy 0.6826923076923077\n",
            "Mpca 300 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 300 Mlda 24 Accuracy 0.6730769230769231\n",
            "Mpca 300 Mlda 25 Accuracy 0.6634615384615384\n",
            "Mpca 300 Mlda 26 Accuracy 0.6634615384615384\n",
            "Mpca 300 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 300 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 300 Mlda 29 Accuracy 0.6826923076923077\n",
            "Mpca 300 Mlda 30 Accuracy 0.6923076923076923\n",
            "Mpca 300 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 300 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 300 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 300 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 300 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 300 Mlda 36 Accuracy 0.7307692307692307\n",
            "Mpca 300 Mlda 37 Accuracy 0.7211538461538461\n",
            "Mpca 300 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 300 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 300 Mlda 40 Accuracy 0.75\n",
            "Mpca 300 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 300 Mlda 42 Accuracy 0.7692307692307693\n",
            "Mpca 300 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 300 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 300 Mlda 45 Accuracy 0.7884615384615384\n",
            "Mpca 300 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 300 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 300 Mlda 48 Accuracy 0.8076923076923077\n",
            "Mpca 300 Mlda 49 Accuracy 0.8076923076923077\n",
            "Mpca 300 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 301 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 301 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 301 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 301 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 301 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 301 Mlda 6 Accuracy 0.33653846153846156\n",
            "Mpca 301 Mlda 7 Accuracy 0.3942307692307692\n",
            "Mpca 301 Mlda 8 Accuracy 0.4423076923076923\n",
            "Mpca 301 Mlda 9 Accuracy 0.5\n",
            "Mpca 301 Mlda 10 Accuracy 0.5192307692307693\n",
            "Mpca 301 Mlda 11 Accuracy 0.5769230769230769\n",
            "Mpca 301 Mlda 12 Accuracy 0.6153846153846154\n",
            "Mpca 301 Mlda 13 Accuracy 0.6153846153846154\n",
            "Mpca 301 Mlda 14 Accuracy 0.6442307692307693\n",
            "Mpca 301 Mlda 15 Accuracy 0.6538461538461539\n",
            "Mpca 301 Mlda 16 Accuracy 0.625\n",
            "Mpca 301 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 301 Mlda 18 Accuracy 0.7115384615384616\n",
            "Mpca 301 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 301 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 301 Mlda 21 Accuracy 0.6923076923076923\n",
            "Mpca 301 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 301 Mlda 23 Accuracy 0.7115384615384616\n",
            "Mpca 301 Mlda 24 Accuracy 0.7019230769230769\n",
            "Mpca 301 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 301 Mlda 26 Accuracy 0.7115384615384616\n",
            "Mpca 301 Mlda 27 Accuracy 0.7115384615384616\n",
            "Mpca 301 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 301 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 301 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 301 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 301 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 301 Mlda 33 Accuracy 0.7403846153846154\n",
            "Mpca 301 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 301 Mlda 35 Accuracy 0.7884615384615384\n",
            "Mpca 301 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 301 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 301 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 301 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 301 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 301 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 301 Mlda 42 Accuracy 0.7884615384615384\n",
            "Mpca 301 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 301 Mlda 44 Accuracy 0.7884615384615384\n",
            "Mpca 301 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 301 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 301 Mlda 47 Accuracy 0.8076923076923077\n",
            "Mpca 301 Mlda 48 Accuracy 0.8269230769230769\n",
            "Mpca 301 Mlda 49 Accuracy 0.8269230769230769\n",
            "Mpca 301 Mlda 50 Accuracy 0.8076923076923077\n",
            "Mpca 302 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 302 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 302 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 302 Mlda 4 Accuracy 0.25\n",
            "Mpca 302 Mlda 5 Accuracy 0.33653846153846156\n",
            "Mpca 302 Mlda 6 Accuracy 0.34615384615384615\n",
            "Mpca 302 Mlda 7 Accuracy 0.375\n",
            "Mpca 302 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 302 Mlda 9 Accuracy 0.4807692307692308\n",
            "Mpca 302 Mlda 10 Accuracy 0.5288461538461539\n",
            "Mpca 302 Mlda 11 Accuracy 0.5673076923076923\n",
            "Mpca 302 Mlda 12 Accuracy 0.6057692307692307\n",
            "Mpca 302 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 302 Mlda 14 Accuracy 0.6634615384615384\n",
            "Mpca 302 Mlda 15 Accuracy 0.6634615384615384\n",
            "Mpca 302 Mlda 16 Accuracy 0.6826923076923077\n",
            "Mpca 302 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 302 Mlda 18 Accuracy 0.6923076923076923\n",
            "Mpca 302 Mlda 19 Accuracy 0.7115384615384616\n",
            "Mpca 302 Mlda 20 Accuracy 0.7307692307692307\n",
            "Mpca 302 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 302 Mlda 22 Accuracy 0.7307692307692307\n",
            "Mpca 302 Mlda 23 Accuracy 0.7307692307692307\n",
            "Mpca 302 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 302 Mlda 25 Accuracy 0.7115384615384616\n",
            "Mpca 302 Mlda 26 Accuracy 0.7115384615384616\n",
            "Mpca 302 Mlda 27 Accuracy 0.7307692307692307\n",
            "Mpca 302 Mlda 28 Accuracy 0.7403846153846154\n",
            "Mpca 302 Mlda 29 Accuracy 0.75\n",
            "Mpca 302 Mlda 30 Accuracy 0.7403846153846154\n",
            "Mpca 302 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 302 Mlda 32 Accuracy 0.7403846153846154\n",
            "Mpca 302 Mlda 33 Accuracy 0.7596153846153846\n",
            "Mpca 302 Mlda 34 Accuracy 0.7788461538461539\n",
            "Mpca 302 Mlda 35 Accuracy 0.7788461538461539\n",
            "Mpca 302 Mlda 36 Accuracy 0.7884615384615384\n",
            "Mpca 302 Mlda 37 Accuracy 0.7884615384615384\n",
            "Mpca 302 Mlda 38 Accuracy 0.7884615384615384\n",
            "Mpca 302 Mlda 39 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 40 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 41 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 42 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 43 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 44 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 45 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 46 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 47 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 48 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 49 Accuracy 0.7980769230769231\n",
            "Mpca 302 Mlda 50 Accuracy 0.7980769230769231\n",
            "Mpca 303 Mlda 1 Accuracy 0.125\n",
            "Mpca 303 Mlda 2 Accuracy 0.15384615384615385\n",
            "Mpca 303 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 303 Mlda 4 Accuracy 0.25\n",
            "Mpca 303 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 303 Mlda 6 Accuracy 0.3269230769230769\n",
            "Mpca 303 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 303 Mlda 8 Accuracy 0.38461538461538464\n",
            "Mpca 303 Mlda 9 Accuracy 0.49038461538461536\n",
            "Mpca 303 Mlda 10 Accuracy 0.5192307692307693\n",
            "Mpca 303 Mlda 11 Accuracy 0.5769230769230769\n",
            "Mpca 303 Mlda 12 Accuracy 0.5865384615384616\n",
            "Mpca 303 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 303 Mlda 14 Accuracy 0.625\n",
            "Mpca 303 Mlda 15 Accuracy 0.6442307692307693\n",
            "Mpca 303 Mlda 16 Accuracy 0.625\n",
            "Mpca 303 Mlda 17 Accuracy 0.625\n",
            "Mpca 303 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 303 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 303 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 303 Mlda 21 Accuracy 0.7211538461538461\n",
            "Mpca 303 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 303 Mlda 23 Accuracy 0.7211538461538461\n",
            "Mpca 303 Mlda 24 Accuracy 0.7211538461538461\n",
            "Mpca 303 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 303 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 303 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 303 Mlda 28 Accuracy 0.7019230769230769\n",
            "Mpca 303 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 303 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 303 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 303 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 303 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 303 Mlda 34 Accuracy 0.75\n",
            "Mpca 303 Mlda 35 Accuracy 0.7596153846153846\n",
            "Mpca 303 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 303 Mlda 37 Accuracy 0.7692307692307693\n",
            "Mpca 303 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 40 Accuracy 0.7692307692307693\n",
            "Mpca 303 Mlda 41 Accuracy 0.7692307692307693\n",
            "Mpca 303 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 47 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 49 Accuracy 0.7788461538461539\n",
            "Mpca 303 Mlda 50 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 304 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 304 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 304 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 304 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 304 Mlda 6 Accuracy 0.3269230769230769\n",
            "Mpca 304 Mlda 7 Accuracy 0.36538461538461536\n",
            "Mpca 304 Mlda 8 Accuracy 0.3942307692307692\n",
            "Mpca 304 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 304 Mlda 10 Accuracy 0.5096153846153846\n",
            "Mpca 304 Mlda 11 Accuracy 0.5576923076923077\n",
            "Mpca 304 Mlda 12 Accuracy 0.5961538461538461\n",
            "Mpca 304 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 304 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 304 Mlda 15 Accuracy 0.6442307692307693\n",
            "Mpca 304 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 304 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 304 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 304 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 304 Mlda 20 Accuracy 0.7115384615384616\n",
            "Mpca 304 Mlda 21 Accuracy 0.6923076923076923\n",
            "Mpca 304 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 304 Mlda 23 Accuracy 0.7019230769230769\n",
            "Mpca 304 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 304 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 304 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 304 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 304 Mlda 28 Accuracy 0.7019230769230769\n",
            "Mpca 304 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 304 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 304 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 304 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 304 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 304 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 304 Mlda 35 Accuracy 0.7596153846153846\n",
            "Mpca 304 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 304 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 40 Accuracy 0.7692307692307693\n",
            "Mpca 304 Mlda 41 Accuracy 0.7692307692307693\n",
            "Mpca 304 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 304 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 304 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 304 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 304 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 305 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 305 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 305 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 305 Mlda 4 Accuracy 0.25\n",
            "Mpca 305 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 305 Mlda 6 Accuracy 0.33653846153846156\n",
            "Mpca 305 Mlda 7 Accuracy 0.3557692307692308\n",
            "Mpca 305 Mlda 8 Accuracy 0.375\n",
            "Mpca 305 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 305 Mlda 10 Accuracy 0.4807692307692308\n",
            "Mpca 305 Mlda 11 Accuracy 0.5576923076923077\n",
            "Mpca 305 Mlda 12 Accuracy 0.5865384615384616\n",
            "Mpca 305 Mlda 13 Accuracy 0.6346153846153846\n",
            "Mpca 305 Mlda 14 Accuracy 0.6346153846153846\n",
            "Mpca 305 Mlda 15 Accuracy 0.6538461538461539\n",
            "Mpca 305 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 305 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 305 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 305 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 305 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 305 Mlda 21 Accuracy 0.7115384615384616\n",
            "Mpca 305 Mlda 22 Accuracy 0.7115384615384616\n",
            "Mpca 305 Mlda 23 Accuracy 0.7019230769230769\n",
            "Mpca 305 Mlda 24 Accuracy 0.7115384615384616\n",
            "Mpca 305 Mlda 25 Accuracy 0.7115384615384616\n",
            "Mpca 305 Mlda 26 Accuracy 0.7211538461538461\n",
            "Mpca 305 Mlda 27 Accuracy 0.7115384615384616\n",
            "Mpca 305 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 305 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 305 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 305 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 305 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 305 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 305 Mlda 34 Accuracy 0.7692307692307693\n",
            "Mpca 305 Mlda 35 Accuracy 0.7692307692307693\n",
            "Mpca 305 Mlda 36 Accuracy 0.7692307692307693\n",
            "Mpca 305 Mlda 37 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 41 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 305 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 305 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 305 Mlda 49 Accuracy 0.7884615384615384\n",
            "Mpca 305 Mlda 50 Accuracy 0.7884615384615384\n",
            "Mpca 306 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 306 Mlda 2 Accuracy 0.125\n",
            "Mpca 306 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 306 Mlda 4 Accuracy 0.2403846153846154\n",
            "Mpca 306 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 306 Mlda 6 Accuracy 0.3269230769230769\n",
            "Mpca 306 Mlda 7 Accuracy 0.34615384615384615\n",
            "Mpca 306 Mlda 8 Accuracy 0.375\n",
            "Mpca 306 Mlda 9 Accuracy 0.4326923076923077\n",
            "Mpca 306 Mlda 10 Accuracy 0.4807692307692308\n",
            "Mpca 306 Mlda 11 Accuracy 0.5576923076923077\n",
            "Mpca 306 Mlda 12 Accuracy 0.6057692307692307\n",
            "Mpca 306 Mlda 13 Accuracy 0.625\n",
            "Mpca 306 Mlda 14 Accuracy 0.625\n",
            "Mpca 306 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 306 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 306 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 306 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 306 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 306 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 306 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 306 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 306 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 306 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 306 Mlda 25 Accuracy 0.7307692307692307\n",
            "Mpca 306 Mlda 26 Accuracy 0.7211538461538461\n",
            "Mpca 306 Mlda 27 Accuracy 0.7211538461538461\n",
            "Mpca 306 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 306 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 306 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 306 Mlda 31 Accuracy 0.7403846153846154\n",
            "Mpca 306 Mlda 32 Accuracy 0.7403846153846154\n",
            "Mpca 306 Mlda 33 Accuracy 0.75\n",
            "Mpca 306 Mlda 34 Accuracy 0.7596153846153846\n",
            "Mpca 306 Mlda 35 Accuracy 0.7692307692307693\n",
            "Mpca 306 Mlda 36 Accuracy 0.7692307692307693\n",
            "Mpca 306 Mlda 37 Accuracy 0.7692307692307693\n",
            "Mpca 306 Mlda 38 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 39 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 40 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 41 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 42 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 44 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 47 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 49 Accuracy 0.7788461538461539\n",
            "Mpca 306 Mlda 50 Accuracy 0.7788461538461539\n",
            "Mpca 307 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 307 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 307 Mlda 3 Accuracy 0.20192307692307693\n",
            "Mpca 307 Mlda 4 Accuracy 0.22115384615384615\n",
            "Mpca 307 Mlda 5 Accuracy 0.25961538461538464\n",
            "Mpca 307 Mlda 6 Accuracy 0.34615384615384615\n",
            "Mpca 307 Mlda 7 Accuracy 0.34615384615384615\n",
            "Mpca 307 Mlda 8 Accuracy 0.36538461538461536\n",
            "Mpca 307 Mlda 9 Accuracy 0.40384615384615385\n",
            "Mpca 307 Mlda 10 Accuracy 0.4519230769230769\n",
            "Mpca 307 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 307 Mlda 12 Accuracy 0.5673076923076923\n",
            "Mpca 307 Mlda 13 Accuracy 0.5961538461538461\n",
            "Mpca 307 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 307 Mlda 15 Accuracy 0.625\n",
            "Mpca 307 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 307 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 307 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 307 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 307 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 307 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 307 Mlda 22 Accuracy 0.6826923076923077\n",
            "Mpca 307 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 307 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 307 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 307 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 307 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 307 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 307 Mlda 29 Accuracy 0.6923076923076923\n",
            "Mpca 307 Mlda 30 Accuracy 0.7211538461538461\n",
            "Mpca 307 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 307 Mlda 32 Accuracy 0.7403846153846154\n",
            "Mpca 307 Mlda 33 Accuracy 0.75\n",
            "Mpca 307 Mlda 34 Accuracy 0.75\n",
            "Mpca 307 Mlda 35 Accuracy 0.7596153846153846\n",
            "Mpca 307 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 307 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 307 Mlda 38 Accuracy 0.7596153846153846\n",
            "Mpca 307 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 307 Mlda 40 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 41 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 42 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 43 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 44 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 307 Mlda 46 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 47 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 48 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 49 Accuracy 0.7692307692307693\n",
            "Mpca 307 Mlda 50 Accuracy 0.7788461538461539\n",
            "Mpca 308 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 308 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 308 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 308 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 308 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 308 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 308 Mlda 7 Accuracy 0.36538461538461536\n",
            "Mpca 308 Mlda 8 Accuracy 0.375\n",
            "Mpca 308 Mlda 9 Accuracy 0.375\n",
            "Mpca 308 Mlda 10 Accuracy 0.4326923076923077\n",
            "Mpca 308 Mlda 11 Accuracy 0.5\n",
            "Mpca 308 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 308 Mlda 13 Accuracy 0.5673076923076923\n",
            "Mpca 308 Mlda 14 Accuracy 0.5673076923076923\n",
            "Mpca 308 Mlda 15 Accuracy 0.6057692307692307\n",
            "Mpca 308 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 308 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 308 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 308 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 308 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 308 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 308 Mlda 22 Accuracy 0.6634615384615384\n",
            "Mpca 308 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 308 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 308 Mlda 25 Accuracy 0.6730769230769231\n",
            "Mpca 308 Mlda 26 Accuracy 0.6730769230769231\n",
            "Mpca 308 Mlda 27 Accuracy 0.6826923076923077\n",
            "Mpca 308 Mlda 28 Accuracy 0.6826923076923077\n",
            "Mpca 308 Mlda 29 Accuracy 0.6730769230769231\n",
            "Mpca 308 Mlda 30 Accuracy 0.6826923076923077\n",
            "Mpca 308 Mlda 31 Accuracy 0.6826923076923077\n",
            "Mpca 308 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 308 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 308 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 308 Mlda 35 Accuracy 0.75\n",
            "Mpca 308 Mlda 36 Accuracy 0.75\n",
            "Mpca 308 Mlda 37 Accuracy 0.75\n",
            "Mpca 308 Mlda 38 Accuracy 0.75\n",
            "Mpca 308 Mlda 39 Accuracy 0.75\n",
            "Mpca 308 Mlda 40 Accuracy 0.75\n",
            "Mpca 308 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 308 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 308 Mlda 43 Accuracy 0.75\n",
            "Mpca 308 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 308 Mlda 45 Accuracy 0.7788461538461539\n",
            "Mpca 308 Mlda 46 Accuracy 0.7692307692307693\n",
            "Mpca 308 Mlda 47 Accuracy 0.7788461538461539\n",
            "Mpca 308 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 308 Mlda 49 Accuracy 0.7788461538461539\n",
            "Mpca 308 Mlda 50 Accuracy 0.7788461538461539\n",
            "Mpca 309 Mlda 1 Accuracy 0.11538461538461539\n",
            "Mpca 309 Mlda 2 Accuracy 0.16346153846153846\n",
            "Mpca 309 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 309 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 309 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 309 Mlda 6 Accuracy 0.33653846153846156\n",
            "Mpca 309 Mlda 7 Accuracy 0.375\n",
            "Mpca 309 Mlda 8 Accuracy 0.38461538461538464\n",
            "Mpca 309 Mlda 9 Accuracy 0.4326923076923077\n",
            "Mpca 309 Mlda 10 Accuracy 0.4519230769230769\n",
            "Mpca 309 Mlda 11 Accuracy 0.5\n",
            "Mpca 309 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 309 Mlda 13 Accuracy 0.5576923076923077\n",
            "Mpca 309 Mlda 14 Accuracy 0.5865384615384616\n",
            "Mpca 309 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 309 Mlda 16 Accuracy 0.625\n",
            "Mpca 309 Mlda 17 Accuracy 0.6442307692307693\n",
            "Mpca 309 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 309 Mlda 19 Accuracy 0.6538461538461539\n",
            "Mpca 309 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 309 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 309 Mlda 22 Accuracy 0.6634615384615384\n",
            "Mpca 309 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 309 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 309 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 309 Mlda 26 Accuracy 0.6730769230769231\n",
            "Mpca 309 Mlda 27 Accuracy 0.6826923076923077\n",
            "Mpca 309 Mlda 28 Accuracy 0.6826923076923077\n",
            "Mpca 309 Mlda 29 Accuracy 0.6730769230769231\n",
            "Mpca 309 Mlda 30 Accuracy 0.6730769230769231\n",
            "Mpca 309 Mlda 31 Accuracy 0.6923076923076923\n",
            "Mpca 309 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 309 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 309 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 309 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 309 Mlda 36 Accuracy 0.7403846153846154\n",
            "Mpca 309 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 309 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 309 Mlda 39 Accuracy 0.75\n",
            "Mpca 309 Mlda 40 Accuracy 0.7596153846153846\n",
            "Mpca 309 Mlda 41 Accuracy 0.75\n",
            "Mpca 309 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 309 Mlda 43 Accuracy 0.7692307692307693\n",
            "Mpca 309 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 309 Mlda 45 Accuracy 0.7692307692307693\n",
            "Mpca 309 Mlda 46 Accuracy 0.7692307692307693\n",
            "Mpca 309 Mlda 47 Accuracy 0.7596153846153846\n",
            "Mpca 309 Mlda 48 Accuracy 0.75\n",
            "Mpca 309 Mlda 49 Accuracy 0.75\n",
            "Mpca 309 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 310 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 310 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 310 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 310 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 310 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 310 Mlda 7 Accuracy 0.34615384615384615\n",
            "Mpca 310 Mlda 8 Accuracy 0.38461538461538464\n",
            "Mpca 310 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 310 Mlda 10 Accuracy 0.4519230769230769\n",
            "Mpca 310 Mlda 11 Accuracy 0.5\n",
            "Mpca 310 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 310 Mlda 13 Accuracy 0.5769230769230769\n",
            "Mpca 310 Mlda 14 Accuracy 0.5865384615384616\n",
            "Mpca 310 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 310 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 310 Mlda 17 Accuracy 0.6442307692307693\n",
            "Mpca 310 Mlda 18 Accuracy 0.6442307692307693\n",
            "Mpca 310 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 310 Mlda 20 Accuracy 0.6442307692307693\n",
            "Mpca 310 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 310 Mlda 22 Accuracy 0.6538461538461539\n",
            "Mpca 310 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 310 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 310 Mlda 25 Accuracy 0.6730769230769231\n",
            "Mpca 310 Mlda 26 Accuracy 0.6730769230769231\n",
            "Mpca 310 Mlda 27 Accuracy 0.6826923076923077\n",
            "Mpca 310 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 310 Mlda 29 Accuracy 0.6826923076923077\n",
            "Mpca 310 Mlda 30 Accuracy 0.6923076923076923\n",
            "Mpca 310 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 310 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 310 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 310 Mlda 34 Accuracy 0.7403846153846154\n",
            "Mpca 310 Mlda 35 Accuracy 0.75\n",
            "Mpca 310 Mlda 36 Accuracy 0.75\n",
            "Mpca 310 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 310 Mlda 38 Accuracy 0.75\n",
            "Mpca 310 Mlda 39 Accuracy 0.7403846153846154\n",
            "Mpca 310 Mlda 40 Accuracy 0.75\n",
            "Mpca 310 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 45 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 46 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 47 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 48 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 49 Accuracy 0.7596153846153846\n",
            "Mpca 310 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 311 Mlda 1 Accuracy 0.09615384615384616\n",
            "Mpca 311 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 311 Mlda 3 Accuracy 0.22115384615384615\n",
            "Mpca 311 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 311 Mlda 5 Accuracy 0.3076923076923077\n",
            "Mpca 311 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 311 Mlda 7 Accuracy 0.38461538461538464\n",
            "Mpca 311 Mlda 8 Accuracy 0.40384615384615385\n",
            "Mpca 311 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 311 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 311 Mlda 11 Accuracy 0.5192307692307693\n",
            "Mpca 311 Mlda 12 Accuracy 0.5576923076923077\n",
            "Mpca 311 Mlda 13 Accuracy 0.5961538461538461\n",
            "Mpca 311 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 311 Mlda 15 Accuracy 0.625\n",
            "Mpca 311 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 311 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 311 Mlda 18 Accuracy 0.6538461538461539\n",
            "Mpca 311 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 311 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 311 Mlda 21 Accuracy 0.6730769230769231\n",
            "Mpca 311 Mlda 22 Accuracy 0.6538461538461539\n",
            "Mpca 311 Mlda 23 Accuracy 0.6442307692307693\n",
            "Mpca 311 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 311 Mlda 25 Accuracy 0.7115384615384616\n",
            "Mpca 311 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 311 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 311 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 311 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 311 Mlda 30 Accuracy 0.7211538461538461\n",
            "Mpca 311 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 311 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 311 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 311 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 311 Mlda 35 Accuracy 0.75\n",
            "Mpca 311 Mlda 36 Accuracy 0.75\n",
            "Mpca 311 Mlda 37 Accuracy 0.75\n",
            "Mpca 311 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 311 Mlda 39 Accuracy 0.75\n",
            "Mpca 311 Mlda 40 Accuracy 0.75\n",
            "Mpca 311 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 311 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 311 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 311 Mlda 44 Accuracy 0.7692307692307693\n",
            "Mpca 311 Mlda 45 Accuracy 0.7692307692307693\n",
            "Mpca 311 Mlda 46 Accuracy 0.7692307692307693\n",
            "Mpca 311 Mlda 47 Accuracy 0.7692307692307693\n",
            "Mpca 311 Mlda 48 Accuracy 0.7692307692307693\n",
            "Mpca 311 Mlda 49 Accuracy 0.7692307692307693\n",
            "Mpca 311 Mlda 50 Accuracy 0.7692307692307693\n",
            "Mpca 312 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 312 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 312 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 312 Mlda 4 Accuracy 0.2980769230769231\n",
            "Mpca 312 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 312 Mlda 6 Accuracy 0.34615384615384615\n",
            "Mpca 312 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 312 Mlda 8 Accuracy 0.3942307692307692\n",
            "Mpca 312 Mlda 9 Accuracy 0.46153846153846156\n",
            "Mpca 312 Mlda 10 Accuracy 0.4807692307692308\n",
            "Mpca 312 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 312 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 312 Mlda 13 Accuracy 0.5961538461538461\n",
            "Mpca 312 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 312 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 312 Mlda 16 Accuracy 0.625\n",
            "Mpca 312 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 312 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 312 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 312 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 312 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 312 Mlda 22 Accuracy 0.6442307692307693\n",
            "Mpca 312 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 312 Mlda 24 Accuracy 0.6730769230769231\n",
            "Mpca 312 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 312 Mlda 26 Accuracy 0.6730769230769231\n",
            "Mpca 312 Mlda 27 Accuracy 0.6730769230769231\n",
            "Mpca 312 Mlda 28 Accuracy 0.6730769230769231\n",
            "Mpca 312 Mlda 29 Accuracy 0.6730769230769231\n",
            "Mpca 312 Mlda 30 Accuracy 0.6923076923076923\n",
            "Mpca 312 Mlda 31 Accuracy 0.6826923076923077\n",
            "Mpca 312 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 312 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 312 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 312 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 36 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 39 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 40 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 41 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 42 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 45 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 312 Mlda 48 Accuracy 0.75\n",
            "Mpca 312 Mlda 49 Accuracy 0.75\n",
            "Mpca 312 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 313 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 313 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 313 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 313 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 313 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 313 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 313 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 313 Mlda 8 Accuracy 0.4423076923076923\n",
            "Mpca 313 Mlda 9 Accuracy 0.46153846153846156\n",
            "Mpca 313 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 313 Mlda 11 Accuracy 0.5192307692307693\n",
            "Mpca 313 Mlda 12 Accuracy 0.5288461538461539\n",
            "Mpca 313 Mlda 13 Accuracy 0.5673076923076923\n",
            "Mpca 313 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 313 Mlda 15 Accuracy 0.6057692307692307\n",
            "Mpca 313 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 313 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 313 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 313 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 313 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 313 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 313 Mlda 22 Accuracy 0.6538461538461539\n",
            "Mpca 313 Mlda 23 Accuracy 0.6538461538461539\n",
            "Mpca 313 Mlda 24 Accuracy 0.6730769230769231\n",
            "Mpca 313 Mlda 25 Accuracy 0.6730769230769231\n",
            "Mpca 313 Mlda 26 Accuracy 0.6730769230769231\n",
            "Mpca 313 Mlda 27 Accuracy 0.6730769230769231\n",
            "Mpca 313 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 313 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 313 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 313 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 313 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 313 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 36 Accuracy 0.7307692307692307\n",
            "Mpca 313 Mlda 37 Accuracy 0.7307692307692307\n",
            "Mpca 313 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 39 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 40 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 41 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 42 Accuracy 0.7211538461538461\n",
            "Mpca 313 Mlda 43 Accuracy 0.7307692307692307\n",
            "Mpca 313 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 313 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 313 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 313 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 313 Mlda 48 Accuracy 0.75\n",
            "Mpca 313 Mlda 49 Accuracy 0.75\n",
            "Mpca 313 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 314 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 314 Mlda 2 Accuracy 0.17307692307692307\n",
            "Mpca 314 Mlda 3 Accuracy 0.2403846153846154\n",
            "Mpca 314 Mlda 4 Accuracy 0.3269230769230769\n",
            "Mpca 314 Mlda 5 Accuracy 0.3557692307692308\n",
            "Mpca 314 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 314 Mlda 7 Accuracy 0.4519230769230769\n",
            "Mpca 314 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 314 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 314 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 314 Mlda 11 Accuracy 0.5\n",
            "Mpca 314 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 314 Mlda 13 Accuracy 0.5673076923076923\n",
            "Mpca 314 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 314 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 314 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 314 Mlda 17 Accuracy 0.6538461538461539\n",
            "Mpca 314 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 314 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 314 Mlda 20 Accuracy 0.6538461538461539\n",
            "Mpca 314 Mlda 21 Accuracy 0.6442307692307693\n",
            "Mpca 314 Mlda 22 Accuracy 0.6442307692307693\n",
            "Mpca 314 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 314 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 314 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 314 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 314 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 314 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 314 Mlda 29 Accuracy 0.6923076923076923\n",
            "Mpca 314 Mlda 30 Accuracy 0.7019230769230769\n",
            "Mpca 314 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 314 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 314 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 314 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 314 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 314 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 314 Mlda 37 Accuracy 0.7307692307692307\n",
            "Mpca 314 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 314 Mlda 39 Accuracy 0.7307692307692307\n",
            "Mpca 314 Mlda 40 Accuracy 0.7403846153846154\n",
            "Mpca 314 Mlda 41 Accuracy 0.7307692307692307\n",
            "Mpca 314 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 314 Mlda 43 Accuracy 0.7307692307692307\n",
            "Mpca 314 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 314 Mlda 45 Accuracy 0.7403846153846154\n",
            "Mpca 314 Mlda 46 Accuracy 0.75\n",
            "Mpca 314 Mlda 47 Accuracy 0.75\n",
            "Mpca 314 Mlda 48 Accuracy 0.75\n",
            "Mpca 314 Mlda 49 Accuracy 0.7596153846153846\n",
            "Mpca 314 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 315 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 315 Mlda 2 Accuracy 0.125\n",
            "Mpca 315 Mlda 3 Accuracy 0.23076923076923078\n",
            "Mpca 315 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 315 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 315 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 315 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 315 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 315 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 315 Mlda 10 Accuracy 0.4807692307692308\n",
            "Mpca 315 Mlda 11 Accuracy 0.5096153846153846\n",
            "Mpca 315 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 315 Mlda 13 Accuracy 0.5480769230769231\n",
            "Mpca 315 Mlda 14 Accuracy 0.625\n",
            "Mpca 315 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 315 Mlda 16 Accuracy 0.6538461538461539\n",
            "Mpca 315 Mlda 17 Accuracy 0.6730769230769231\n",
            "Mpca 315 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 315 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 315 Mlda 20 Accuracy 0.6538461538461539\n",
            "Mpca 315 Mlda 21 Accuracy 0.6538461538461539\n",
            "Mpca 315 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 315 Mlda 23 Accuracy 0.6730769230769231\n",
            "Mpca 315 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 315 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 315 Mlda 26 Accuracy 0.6923076923076923\n",
            "Mpca 315 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 315 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 315 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 315 Mlda 30 Accuracy 0.7019230769230769\n",
            "Mpca 315 Mlda 31 Accuracy 0.7019230769230769\n",
            "Mpca 315 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 315 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 315 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 315 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 315 Mlda 36 Accuracy 0.7307692307692307\n",
            "Mpca 315 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 315 Mlda 38 Accuracy 0.75\n",
            "Mpca 315 Mlda 39 Accuracy 0.75\n",
            "Mpca 315 Mlda 40 Accuracy 0.75\n",
            "Mpca 315 Mlda 41 Accuracy 0.75\n",
            "Mpca 315 Mlda 42 Accuracy 0.75\n",
            "Mpca 315 Mlda 43 Accuracy 0.75\n",
            "Mpca 315 Mlda 44 Accuracy 0.75\n",
            "Mpca 315 Mlda 45 Accuracy 0.75\n",
            "Mpca 315 Mlda 46 Accuracy 0.75\n",
            "Mpca 315 Mlda 47 Accuracy 0.75\n",
            "Mpca 315 Mlda 48 Accuracy 0.75\n",
            "Mpca 315 Mlda 49 Accuracy 0.75\n",
            "Mpca 315 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 316 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 316 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 316 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 316 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 316 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 316 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 316 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 316 Mlda 8 Accuracy 0.3942307692307692\n",
            "Mpca 316 Mlda 9 Accuracy 0.46153846153846156\n",
            "Mpca 316 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 316 Mlda 11 Accuracy 0.5096153846153846\n",
            "Mpca 316 Mlda 12 Accuracy 0.5288461538461539\n",
            "Mpca 316 Mlda 13 Accuracy 0.5576923076923077\n",
            "Mpca 316 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 316 Mlda 15 Accuracy 0.625\n",
            "Mpca 316 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 316 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 316 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 316 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 316 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 316 Mlda 21 Accuracy 0.6730769230769231\n",
            "Mpca 316 Mlda 22 Accuracy 0.6826923076923077\n",
            "Mpca 316 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 316 Mlda 24 Accuracy 0.7019230769230769\n",
            "Mpca 316 Mlda 25 Accuracy 0.7115384615384616\n",
            "Mpca 316 Mlda 26 Accuracy 0.7211538461538461\n",
            "Mpca 316 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 316 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 316 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 316 Mlda 30 Accuracy 0.7019230769230769\n",
            "Mpca 316 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 316 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 316 Mlda 33 Accuracy 0.7115384615384616\n",
            "Mpca 316 Mlda 34 Accuracy 0.7403846153846154\n",
            "Mpca 316 Mlda 35 Accuracy 0.7403846153846154\n",
            "Mpca 316 Mlda 36 Accuracy 0.7596153846153846\n",
            "Mpca 316 Mlda 37 Accuracy 0.7596153846153846\n",
            "Mpca 316 Mlda 38 Accuracy 0.75\n",
            "Mpca 316 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 316 Mlda 40 Accuracy 0.7596153846153846\n",
            "Mpca 316 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 316 Mlda 42 Accuracy 0.7692307692307693\n",
            "Mpca 316 Mlda 43 Accuracy 0.7692307692307693\n",
            "Mpca 316 Mlda 44 Accuracy 0.7692307692307693\n",
            "Mpca 316 Mlda 45 Accuracy 0.7692307692307693\n",
            "Mpca 316 Mlda 46 Accuracy 0.7692307692307693\n",
            "Mpca 316 Mlda 47 Accuracy 0.7692307692307693\n",
            "Mpca 316 Mlda 48 Accuracy 0.7788461538461539\n",
            "Mpca 316 Mlda 49 Accuracy 0.7788461538461539\n",
            "Mpca 316 Mlda 50 Accuracy 0.7692307692307693\n",
            "Mpca 317 Mlda 1 Accuracy 0.10576923076923077\n",
            "Mpca 317 Mlda 2 Accuracy 0.14423076923076922\n",
            "Mpca 317 Mlda 3 Accuracy 0.14423076923076922\n",
            "Mpca 317 Mlda 4 Accuracy 0.2403846153846154\n",
            "Mpca 317 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 317 Mlda 6 Accuracy 0.375\n",
            "Mpca 317 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 317 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 317 Mlda 9 Accuracy 0.4423076923076923\n",
            "Mpca 317 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 317 Mlda 11 Accuracy 0.49038461538461536\n",
            "Mpca 317 Mlda 12 Accuracy 0.5288461538461539\n",
            "Mpca 317 Mlda 13 Accuracy 0.5576923076923077\n",
            "Mpca 317 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 317 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 317 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 317 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 317 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 317 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 317 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 317 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 317 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 317 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 317 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 317 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 317 Mlda 26 Accuracy 0.7115384615384616\n",
            "Mpca 317 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 317 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 317 Mlda 29 Accuracy 0.7307692307692307\n",
            "Mpca 317 Mlda 30 Accuracy 0.7307692307692307\n",
            "Mpca 317 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 317 Mlda 32 Accuracy 0.7211538461538461\n",
            "Mpca 317 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 317 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 317 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 317 Mlda 36 Accuracy 0.75\n",
            "Mpca 317 Mlda 37 Accuracy 0.75\n",
            "Mpca 317 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 317 Mlda 39 Accuracy 0.75\n",
            "Mpca 317 Mlda 40 Accuracy 0.7596153846153846\n",
            "Mpca 317 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 317 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 317 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 317 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 317 Mlda 45 Accuracy 0.7596153846153846\n",
            "Mpca 317 Mlda 46 Accuracy 0.7692307692307693\n",
            "Mpca 317 Mlda 47 Accuracy 0.7692307692307693\n",
            "Mpca 317 Mlda 48 Accuracy 0.7692307692307693\n",
            "Mpca 317 Mlda 49 Accuracy 0.7692307692307693\n",
            "Mpca 317 Mlda 50 Accuracy 0.7692307692307693\n",
            "Mpca 318 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 318 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 318 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 318 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 318 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 318 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 318 Mlda 7 Accuracy 0.46153846153846156\n",
            "Mpca 318 Mlda 8 Accuracy 0.5\n",
            "Mpca 318 Mlda 9 Accuracy 0.4807692307692308\n",
            "Mpca 318 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 318 Mlda 11 Accuracy 0.5\n",
            "Mpca 318 Mlda 12 Accuracy 0.5576923076923077\n",
            "Mpca 318 Mlda 13 Accuracy 0.5480769230769231\n",
            "Mpca 318 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 318 Mlda 15 Accuracy 0.625\n",
            "Mpca 318 Mlda 16 Accuracy 0.625\n",
            "Mpca 318 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 318 Mlda 18 Accuracy 0.6730769230769231\n",
            "Mpca 318 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 318 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 318 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 318 Mlda 22 Accuracy 0.6826923076923077\n",
            "Mpca 318 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 318 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 318 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 318 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 318 Mlda 27 Accuracy 0.6730769230769231\n",
            "Mpca 318 Mlda 28 Accuracy 0.6826923076923077\n",
            "Mpca 318 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 318 Mlda 30 Accuracy 0.7211538461538461\n",
            "Mpca 318 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 318 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 318 Mlda 33 Accuracy 0.7115384615384616\n",
            "Mpca 318 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 318 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 318 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 318 Mlda 37 Accuracy 0.7307692307692307\n",
            "Mpca 318 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 318 Mlda 39 Accuracy 0.75\n",
            "Mpca 318 Mlda 40 Accuracy 0.75\n",
            "Mpca 318 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 318 Mlda 42 Accuracy 0.75\n",
            "Mpca 318 Mlda 43 Accuracy 0.7788461538461539\n",
            "Mpca 318 Mlda 44 Accuracy 0.7692307692307693\n",
            "Mpca 318 Mlda 45 Accuracy 0.7692307692307693\n",
            "Mpca 318 Mlda 46 Accuracy 0.7788461538461539\n",
            "Mpca 318 Mlda 47 Accuracy 0.7884615384615384\n",
            "Mpca 318 Mlda 48 Accuracy 0.7884615384615384\n",
            "Mpca 318 Mlda 49 Accuracy 0.7692307692307693\n",
            "Mpca 318 Mlda 50 Accuracy 0.7788461538461539\n",
            "Mpca 319 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 319 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 319 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 319 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 319 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 319 Mlda 6 Accuracy 0.34615384615384615\n",
            "Mpca 319 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 319 Mlda 8 Accuracy 0.4519230769230769\n",
            "Mpca 319 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 319 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 319 Mlda 11 Accuracy 0.5192307692307693\n",
            "Mpca 319 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 319 Mlda 13 Accuracy 0.5673076923076923\n",
            "Mpca 319 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 319 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 319 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 319 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 319 Mlda 18 Accuracy 0.6826923076923077\n",
            "Mpca 319 Mlda 19 Accuracy 0.7019230769230769\n",
            "Mpca 319 Mlda 20 Accuracy 0.7019230769230769\n",
            "Mpca 319 Mlda 21 Accuracy 0.7019230769230769\n",
            "Mpca 319 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 319 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 319 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 319 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 319 Mlda 26 Accuracy 0.6923076923076923\n",
            "Mpca 319 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 319 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 319 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 319 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 319 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 319 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 319 Mlda 33 Accuracy 0.7211538461538461\n",
            "Mpca 319 Mlda 34 Accuracy 0.7211538461538461\n",
            "Mpca 319 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 319 Mlda 36 Accuracy 0.7307692307692307\n",
            "Mpca 319 Mlda 37 Accuracy 0.7403846153846154\n",
            "Mpca 319 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 319 Mlda 39 Accuracy 0.75\n",
            "Mpca 319 Mlda 40 Accuracy 0.75\n",
            "Mpca 319 Mlda 41 Accuracy 0.75\n",
            "Mpca 319 Mlda 42 Accuracy 0.75\n",
            "Mpca 319 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 319 Mlda 44 Accuracy 0.75\n",
            "Mpca 319 Mlda 45 Accuracy 0.75\n",
            "Mpca 319 Mlda 46 Accuracy 0.75\n",
            "Mpca 319 Mlda 47 Accuracy 0.75\n",
            "Mpca 319 Mlda 48 Accuracy 0.75\n",
            "Mpca 319 Mlda 49 Accuracy 0.7596153846153846\n",
            "Mpca 319 Mlda 50 Accuracy 0.7788461538461539\n",
            "Mpca 320 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 320 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 320 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 320 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 320 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 320 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 320 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 320 Mlda 8 Accuracy 0.46153846153846156\n",
            "Mpca 320 Mlda 9 Accuracy 0.5096153846153846\n",
            "Mpca 320 Mlda 10 Accuracy 0.5288461538461539\n",
            "Mpca 320 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 320 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 320 Mlda 13 Accuracy 0.5576923076923077\n",
            "Mpca 320 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 320 Mlda 15 Accuracy 0.5961538461538461\n",
            "Mpca 320 Mlda 16 Accuracy 0.625\n",
            "Mpca 320 Mlda 17 Accuracy 0.6442307692307693\n",
            "Mpca 320 Mlda 18 Accuracy 0.6346153846153846\n",
            "Mpca 320 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 320 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 320 Mlda 21 Accuracy 0.7019230769230769\n",
            "Mpca 320 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 320 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 320 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 320 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 320 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 320 Mlda 27 Accuracy 0.7115384615384616\n",
            "Mpca 320 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 320 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 320 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 320 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 320 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 320 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 320 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 320 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 320 Mlda 36 Accuracy 0.75\n",
            "Mpca 320 Mlda 37 Accuracy 0.75\n",
            "Mpca 320 Mlda 38 Accuracy 0.75\n",
            "Mpca 320 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 40 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 43 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 45 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 46 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 47 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 48 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 49 Accuracy 0.7596153846153846\n",
            "Mpca 320 Mlda 50 Accuracy 0.7692307692307693\n",
            "Mpca 321 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 321 Mlda 2 Accuracy 0.1346153846153846\n",
            "Mpca 321 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 321 Mlda 4 Accuracy 0.28846153846153844\n",
            "Mpca 321 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 321 Mlda 6 Accuracy 0.375\n",
            "Mpca 321 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 321 Mlda 8 Accuracy 0.46153846153846156\n",
            "Mpca 321 Mlda 9 Accuracy 0.5192307692307693\n",
            "Mpca 321 Mlda 10 Accuracy 0.5\n",
            "Mpca 321 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 321 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 321 Mlda 13 Accuracy 0.5769230769230769\n",
            "Mpca 321 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 321 Mlda 15 Accuracy 0.5769230769230769\n",
            "Mpca 321 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 321 Mlda 17 Accuracy 0.6346153846153846\n",
            "Mpca 321 Mlda 18 Accuracy 0.6442307692307693\n",
            "Mpca 321 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 321 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 321 Mlda 21 Accuracy 0.6923076923076923\n",
            "Mpca 321 Mlda 22 Accuracy 0.7019230769230769\n",
            "Mpca 321 Mlda 23 Accuracy 0.7019230769230769\n",
            "Mpca 321 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 321 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 321 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 321 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 321 Mlda 28 Accuracy 0.7211538461538461\n",
            "Mpca 321 Mlda 29 Accuracy 0.7211538461538461\n",
            "Mpca 321 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 321 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 321 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 321 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 321 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 321 Mlda 35 Accuracy 0.7307692307692307\n",
            "Mpca 321 Mlda 36 Accuracy 0.75\n",
            "Mpca 321 Mlda 37 Accuracy 0.75\n",
            "Mpca 321 Mlda 38 Accuracy 0.75\n",
            "Mpca 321 Mlda 39 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 40 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 41 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 42 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 43 Accuracy 0.75\n",
            "Mpca 321 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 45 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 46 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 47 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 48 Accuracy 0.7596153846153846\n",
            "Mpca 321 Mlda 49 Accuracy 0.7692307692307693\n",
            "Mpca 321 Mlda 50 Accuracy 0.7692307692307693\n",
            "Mpca 322 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 322 Mlda 2 Accuracy 0.125\n",
            "Mpca 322 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 322 Mlda 4 Accuracy 0.22115384615384615\n",
            "Mpca 322 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 322 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 322 Mlda 7 Accuracy 0.38461538461538464\n",
            "Mpca 322 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 322 Mlda 9 Accuracy 0.5096153846153846\n",
            "Mpca 322 Mlda 10 Accuracy 0.5096153846153846\n",
            "Mpca 322 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 322 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 322 Mlda 13 Accuracy 0.5576923076923077\n",
            "Mpca 322 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 322 Mlda 15 Accuracy 0.625\n",
            "Mpca 322 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 322 Mlda 17 Accuracy 0.6346153846153846\n",
            "Mpca 322 Mlda 18 Accuracy 0.625\n",
            "Mpca 322 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 322 Mlda 20 Accuracy 0.6923076923076923\n",
            "Mpca 322 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 322 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 322 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 322 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 322 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 322 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 322 Mlda 27 Accuracy 0.6826923076923077\n",
            "Mpca 322 Mlda 28 Accuracy 0.7019230769230769\n",
            "Mpca 322 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 322 Mlda 30 Accuracy 0.7019230769230769\n",
            "Mpca 322 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 322 Mlda 32 Accuracy 0.7115384615384616\n",
            "Mpca 322 Mlda 33 Accuracy 0.7019230769230769\n",
            "Mpca 322 Mlda 34 Accuracy 0.7115384615384616\n",
            "Mpca 322 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 322 Mlda 36 Accuracy 0.7115384615384616\n",
            "Mpca 322 Mlda 37 Accuracy 0.7115384615384616\n",
            "Mpca 322 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 322 Mlda 39 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 40 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 41 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 42 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 322 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 48 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 322 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 323 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 323 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 323 Mlda 3 Accuracy 0.125\n",
            "Mpca 323 Mlda 4 Accuracy 0.19230769230769232\n",
            "Mpca 323 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 323 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 323 Mlda 7 Accuracy 0.38461538461538464\n",
            "Mpca 323 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 323 Mlda 9 Accuracy 0.49038461538461536\n",
            "Mpca 323 Mlda 10 Accuracy 0.5192307692307693\n",
            "Mpca 323 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 323 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 323 Mlda 13 Accuracy 0.5576923076923077\n",
            "Mpca 323 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 323 Mlda 15 Accuracy 0.6057692307692307\n",
            "Mpca 323 Mlda 16 Accuracy 0.6153846153846154\n",
            "Mpca 323 Mlda 17 Accuracy 0.6153846153846154\n",
            "Mpca 323 Mlda 18 Accuracy 0.625\n",
            "Mpca 323 Mlda 19 Accuracy 0.6442307692307693\n",
            "Mpca 323 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 323 Mlda 21 Accuracy 0.6730769230769231\n",
            "Mpca 323 Mlda 22 Accuracy 0.6730769230769231\n",
            "Mpca 323 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 323 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 323 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 323 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 323 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 323 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 323 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 323 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 323 Mlda 31 Accuracy 0.7307692307692307\n",
            "Mpca 323 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 323 Mlda 33 Accuracy 0.7307692307692307\n",
            "Mpca 323 Mlda 34 Accuracy 0.7307692307692307\n",
            "Mpca 323 Mlda 35 Accuracy 0.7211538461538461\n",
            "Mpca 323 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 323 Mlda 37 Accuracy 0.7307692307692307\n",
            "Mpca 323 Mlda 38 Accuracy 0.7307692307692307\n",
            "Mpca 323 Mlda 39 Accuracy 0.7403846153846154\n",
            "Mpca 323 Mlda 40 Accuracy 0.75\n",
            "Mpca 323 Mlda 41 Accuracy 0.75\n",
            "Mpca 323 Mlda 42 Accuracy 0.75\n",
            "Mpca 323 Mlda 43 Accuracy 0.75\n",
            "Mpca 323 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 323 Mlda 45 Accuracy 0.7596153846153846\n",
            "Mpca 323 Mlda 46 Accuracy 0.7596153846153846\n",
            "Mpca 323 Mlda 47 Accuracy 0.75\n",
            "Mpca 323 Mlda 48 Accuracy 0.75\n",
            "Mpca 323 Mlda 49 Accuracy 0.7596153846153846\n",
            "Mpca 323 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 324 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 324 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 324 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 324 Mlda 4 Accuracy 0.18269230769230768\n",
            "Mpca 324 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 324 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 324 Mlda 7 Accuracy 0.3942307692307692\n",
            "Mpca 324 Mlda 8 Accuracy 0.41346153846153844\n",
            "Mpca 324 Mlda 9 Accuracy 0.4807692307692308\n",
            "Mpca 324 Mlda 10 Accuracy 0.5096153846153846\n",
            "Mpca 324 Mlda 11 Accuracy 0.5480769230769231\n",
            "Mpca 324 Mlda 12 Accuracy 0.5384615384615384\n",
            "Mpca 324 Mlda 13 Accuracy 0.5673076923076923\n",
            "Mpca 324 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 324 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 324 Mlda 16 Accuracy 0.6153846153846154\n",
            "Mpca 324 Mlda 17 Accuracy 0.625\n",
            "Mpca 324 Mlda 18 Accuracy 0.6442307692307693\n",
            "Mpca 324 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 324 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 324 Mlda 21 Accuracy 0.6730769230769231\n",
            "Mpca 324 Mlda 22 Accuracy 0.6826923076923077\n",
            "Mpca 324 Mlda 23 Accuracy 0.7019230769230769\n",
            "Mpca 324 Mlda 24 Accuracy 0.7019230769230769\n",
            "Mpca 324 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 324 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 324 Mlda 27 Accuracy 0.7115384615384616\n",
            "Mpca 324 Mlda 28 Accuracy 0.7019230769230769\n",
            "Mpca 324 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 324 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 324 Mlda 31 Accuracy 0.7211538461538461\n",
            "Mpca 324 Mlda 32 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 33 Accuracy 0.7115384615384616\n",
            "Mpca 324 Mlda 34 Accuracy 0.7115384615384616\n",
            "Mpca 324 Mlda 35 Accuracy 0.7115384615384616\n",
            "Mpca 324 Mlda 36 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 37 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 38 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 39 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 40 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 41 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 43 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 46 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 47 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 324 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 324 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 325 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 325 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 325 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 325 Mlda 4 Accuracy 0.20192307692307693\n",
            "Mpca 325 Mlda 5 Accuracy 0.2403846153846154\n",
            "Mpca 325 Mlda 6 Accuracy 0.3269230769230769\n",
            "Mpca 325 Mlda 7 Accuracy 0.3557692307692308\n",
            "Mpca 325 Mlda 8 Accuracy 0.41346153846153844\n",
            "Mpca 325 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 325 Mlda 10 Accuracy 0.4807692307692308\n",
            "Mpca 325 Mlda 11 Accuracy 0.5192307692307693\n",
            "Mpca 325 Mlda 12 Accuracy 0.5288461538461539\n",
            "Mpca 325 Mlda 13 Accuracy 0.5480769230769231\n",
            "Mpca 325 Mlda 14 Accuracy 0.5673076923076923\n",
            "Mpca 325 Mlda 15 Accuracy 0.6538461538461539\n",
            "Mpca 325 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 325 Mlda 17 Accuracy 0.6346153846153846\n",
            "Mpca 325 Mlda 18 Accuracy 0.6442307692307693\n",
            "Mpca 325 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 325 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 325 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 325 Mlda 22 Accuracy 0.6730769230769231\n",
            "Mpca 325 Mlda 23 Accuracy 0.6730769230769231\n",
            "Mpca 325 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 26 Accuracy 0.6730769230769231\n",
            "Mpca 325 Mlda 27 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 28 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 29 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 30 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 31 Accuracy 0.6730769230769231\n",
            "Mpca 325 Mlda 32 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 33 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 34 Accuracy 0.6730769230769231\n",
            "Mpca 325 Mlda 35 Accuracy 0.6826923076923077\n",
            "Mpca 325 Mlda 36 Accuracy 0.7019230769230769\n",
            "Mpca 325 Mlda 37 Accuracy 0.7115384615384616\n",
            "Mpca 325 Mlda 38 Accuracy 0.7115384615384616\n",
            "Mpca 325 Mlda 39 Accuracy 0.7115384615384616\n",
            "Mpca 325 Mlda 40 Accuracy 0.7211538461538461\n",
            "Mpca 325 Mlda 41 Accuracy 0.7307692307692307\n",
            "Mpca 325 Mlda 42 Accuracy 0.7403846153846154\n",
            "Mpca 325 Mlda 43 Accuracy 0.7307692307692307\n",
            "Mpca 325 Mlda 44 Accuracy 0.7211538461538461\n",
            "Mpca 325 Mlda 45 Accuracy 0.7211538461538461\n",
            "Mpca 325 Mlda 46 Accuracy 0.7211538461538461\n",
            "Mpca 325 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 325 Mlda 48 Accuracy 0.7403846153846154\n",
            "Mpca 325 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 325 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 326 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 326 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 326 Mlda 3 Accuracy 0.11538461538461539\n",
            "Mpca 326 Mlda 4 Accuracy 0.21153846153846154\n",
            "Mpca 326 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 326 Mlda 6 Accuracy 0.3269230769230769\n",
            "Mpca 326 Mlda 7 Accuracy 0.3557692307692308\n",
            "Mpca 326 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 326 Mlda 9 Accuracy 0.49038461538461536\n",
            "Mpca 326 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 326 Mlda 11 Accuracy 0.5480769230769231\n",
            "Mpca 326 Mlda 12 Accuracy 0.5576923076923077\n",
            "Mpca 326 Mlda 13 Accuracy 0.5865384615384616\n",
            "Mpca 326 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 326 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 326 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 326 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 326 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 326 Mlda 19 Accuracy 0.6923076923076923\n",
            "Mpca 326 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 326 Mlda 21 Accuracy 0.6826923076923077\n",
            "Mpca 326 Mlda 22 Accuracy 0.6923076923076923\n",
            "Mpca 326 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 326 Mlda 24 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 326 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 326 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 326 Mlda 31 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 33 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 326 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 326 Mlda 37 Accuracy 0.7211538461538461\n",
            "Mpca 326 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 326 Mlda 39 Accuracy 0.7307692307692307\n",
            "Mpca 326 Mlda 40 Accuracy 0.7307692307692307\n",
            "Mpca 326 Mlda 41 Accuracy 0.7307692307692307\n",
            "Mpca 326 Mlda 42 Accuracy 0.75\n",
            "Mpca 326 Mlda 43 Accuracy 0.75\n",
            "Mpca 326 Mlda 44 Accuracy 0.75\n",
            "Mpca 326 Mlda 45 Accuracy 0.75\n",
            "Mpca 326 Mlda 46 Accuracy 0.75\n",
            "Mpca 326 Mlda 47 Accuracy 0.75\n",
            "Mpca 326 Mlda 48 Accuracy 0.75\n",
            "Mpca 326 Mlda 49 Accuracy 0.75\n",
            "Mpca 326 Mlda 50 Accuracy 0.75\n",
            "Mpca 327 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 327 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 327 Mlda 3 Accuracy 0.21153846153846154\n",
            "Mpca 327 Mlda 4 Accuracy 0.20192307692307693\n",
            "Mpca 327 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 327 Mlda 6 Accuracy 0.3557692307692308\n",
            "Mpca 327 Mlda 7 Accuracy 0.3557692307692308\n",
            "Mpca 327 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 327 Mlda 9 Accuracy 0.49038461538461536\n",
            "Mpca 327 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 327 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 327 Mlda 12 Accuracy 0.5673076923076923\n",
            "Mpca 327 Mlda 13 Accuracy 0.5865384615384616\n",
            "Mpca 327 Mlda 14 Accuracy 0.625\n",
            "Mpca 327 Mlda 15 Accuracy 0.625\n",
            "Mpca 327 Mlda 16 Accuracy 0.6346153846153846\n",
            "Mpca 327 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 327 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 327 Mlda 19 Accuracy 0.6826923076923077\n",
            "Mpca 327 Mlda 20 Accuracy 0.6826923076923077\n",
            "Mpca 327 Mlda 21 Accuracy 0.6730769230769231\n",
            "Mpca 327 Mlda 22 Accuracy 0.6826923076923077\n",
            "Mpca 327 Mlda 23 Accuracy 0.6923076923076923\n",
            "Mpca 327 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 327 Mlda 25 Accuracy 0.6923076923076923\n",
            "Mpca 327 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 28 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 29 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 30 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 31 Accuracy 0.6923076923076923\n",
            "Mpca 327 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 33 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 327 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 327 Mlda 37 Accuracy 0.7211538461538461\n",
            "Mpca 327 Mlda 38 Accuracy 0.7211538461538461\n",
            "Mpca 327 Mlda 39 Accuracy 0.7307692307692307\n",
            "Mpca 327 Mlda 40 Accuracy 0.7307692307692307\n",
            "Mpca 327 Mlda 41 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 42 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 43 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 44 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 45 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 46 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 48 Accuracy 0.7403846153846154\n",
            "Mpca 327 Mlda 49 Accuracy 0.75\n",
            "Mpca 327 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 328 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 328 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 328 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 328 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 328 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 328 Mlda 6 Accuracy 0.375\n",
            "Mpca 328 Mlda 7 Accuracy 0.4230769230769231\n",
            "Mpca 328 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 328 Mlda 9 Accuracy 0.4807692307692308\n",
            "Mpca 328 Mlda 10 Accuracy 0.5192307692307693\n",
            "Mpca 328 Mlda 11 Accuracy 0.5384615384615384\n",
            "Mpca 328 Mlda 12 Accuracy 0.5673076923076923\n",
            "Mpca 328 Mlda 13 Accuracy 0.5961538461538461\n",
            "Mpca 328 Mlda 14 Accuracy 0.6153846153846154\n",
            "Mpca 328 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 328 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 328 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 328 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 328 Mlda 19 Accuracy 0.6634615384615384\n",
            "Mpca 328 Mlda 20 Accuracy 0.6634615384615384\n",
            "Mpca 328 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 328 Mlda 22 Accuracy 0.6730769230769231\n",
            "Mpca 328 Mlda 23 Accuracy 0.6826923076923077\n",
            "Mpca 328 Mlda 24 Accuracy 0.6923076923076923\n",
            "Mpca 328 Mlda 25 Accuracy 0.7019230769230769\n",
            "Mpca 328 Mlda 26 Accuracy 0.7019230769230769\n",
            "Mpca 328 Mlda 27 Accuracy 0.7115384615384616\n",
            "Mpca 328 Mlda 28 Accuracy 0.7115384615384616\n",
            "Mpca 328 Mlda 29 Accuracy 0.7115384615384616\n",
            "Mpca 328 Mlda 30 Accuracy 0.7115384615384616\n",
            "Mpca 328 Mlda 31 Accuracy 0.7115384615384616\n",
            "Mpca 328 Mlda 32 Accuracy 0.7019230769230769\n",
            "Mpca 328 Mlda 33 Accuracy 0.7019230769230769\n",
            "Mpca 328 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 328 Mlda 35 Accuracy 0.7115384615384616\n",
            "Mpca 328 Mlda 36 Accuracy 0.7403846153846154\n",
            "Mpca 328 Mlda 37 Accuracy 0.7307692307692307\n",
            "Mpca 328 Mlda 38 Accuracy 0.7403846153846154\n",
            "Mpca 328 Mlda 39 Accuracy 0.75\n",
            "Mpca 328 Mlda 40 Accuracy 0.75\n",
            "Mpca 328 Mlda 41 Accuracy 0.75\n",
            "Mpca 328 Mlda 42 Accuracy 0.75\n",
            "Mpca 328 Mlda 43 Accuracy 0.75\n",
            "Mpca 328 Mlda 44 Accuracy 0.7596153846153846\n",
            "Mpca 328 Mlda 45 Accuracy 0.7596153846153846\n",
            "Mpca 328 Mlda 46 Accuracy 0.7596153846153846\n",
            "Mpca 328 Mlda 47 Accuracy 0.7596153846153846\n",
            "Mpca 328 Mlda 48 Accuracy 0.7596153846153846\n",
            "Mpca 328 Mlda 49 Accuracy 0.7596153846153846\n",
            "Mpca 328 Mlda 50 Accuracy 0.7596153846153846\n",
            "Mpca 329 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 329 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 329 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 329 Mlda 4 Accuracy 0.23076923076923078\n",
            "Mpca 329 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 329 Mlda 6 Accuracy 0.36538461538461536\n",
            "Mpca 329 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 329 Mlda 8 Accuracy 0.4519230769230769\n",
            "Mpca 329 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 329 Mlda 10 Accuracy 0.5096153846153846\n",
            "Mpca 329 Mlda 11 Accuracy 0.5384615384615384\n",
            "Mpca 329 Mlda 12 Accuracy 0.5865384615384616\n",
            "Mpca 329 Mlda 13 Accuracy 0.5865384615384616\n",
            "Mpca 329 Mlda 14 Accuracy 0.6057692307692307\n",
            "Mpca 329 Mlda 15 Accuracy 0.6346153846153846\n",
            "Mpca 329 Mlda 16 Accuracy 0.6442307692307693\n",
            "Mpca 329 Mlda 17 Accuracy 0.6634615384615384\n",
            "Mpca 329 Mlda 18 Accuracy 0.6634615384615384\n",
            "Mpca 329 Mlda 19 Accuracy 0.6730769230769231\n",
            "Mpca 329 Mlda 20 Accuracy 0.6730769230769231\n",
            "Mpca 329 Mlda 21 Accuracy 0.6634615384615384\n",
            "Mpca 329 Mlda 22 Accuracy 0.6634615384615384\n",
            "Mpca 329 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 329 Mlda 24 Accuracy 0.6826923076923077\n",
            "Mpca 329 Mlda 25 Accuracy 0.6826923076923077\n",
            "Mpca 329 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 329 Mlda 27 Accuracy 0.7019230769230769\n",
            "Mpca 329 Mlda 28 Accuracy 0.7019230769230769\n",
            "Mpca 329 Mlda 29 Accuracy 0.6923076923076923\n",
            "Mpca 329 Mlda 30 Accuracy 0.6923076923076923\n",
            "Mpca 329 Mlda 31 Accuracy 0.6923076923076923\n",
            "Mpca 329 Mlda 32 Accuracy 0.6923076923076923\n",
            "Mpca 329 Mlda 33 Accuracy 0.7019230769230769\n",
            "Mpca 329 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 329 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 329 Mlda 36 Accuracy 0.7019230769230769\n",
            "Mpca 329 Mlda 37 Accuracy 0.7019230769230769\n",
            "Mpca 329 Mlda 38 Accuracy 0.7115384615384616\n",
            "Mpca 329 Mlda 39 Accuracy 0.7211538461538461\n",
            "Mpca 329 Mlda 40 Accuracy 0.7211538461538461\n",
            "Mpca 329 Mlda 41 Accuracy 0.7211538461538461\n",
            "Mpca 329 Mlda 42 Accuracy 0.7211538461538461\n",
            "Mpca 329 Mlda 43 Accuracy 0.7307692307692307\n",
            "Mpca 329 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 329 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 329 Mlda 46 Accuracy 0.7307692307692307\n",
            "Mpca 329 Mlda 47 Accuracy 0.7403846153846154\n",
            "Mpca 329 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 329 Mlda 49 Accuracy 0.7403846153846154\n",
            "Mpca 329 Mlda 50 Accuracy 0.7403846153846154\n",
            "Mpca 330 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 330 Mlda 2 Accuracy 0.125\n",
            "Mpca 330 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 330 Mlda 4 Accuracy 0.22115384615384615\n",
            "Mpca 330 Mlda 5 Accuracy 0.34615384615384615\n",
            "Mpca 330 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 330 Mlda 7 Accuracy 0.4423076923076923\n",
            "Mpca 330 Mlda 8 Accuracy 0.4423076923076923\n",
            "Mpca 330 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 330 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 330 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 330 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 330 Mlda 13 Accuracy 0.5673076923076923\n",
            "Mpca 330 Mlda 14 Accuracy 0.5961538461538461\n",
            "Mpca 330 Mlda 15 Accuracy 0.6153846153846154\n",
            "Mpca 330 Mlda 16 Accuracy 0.6153846153846154\n",
            "Mpca 330 Mlda 17 Accuracy 0.625\n",
            "Mpca 330 Mlda 18 Accuracy 0.625\n",
            "Mpca 330 Mlda 19 Accuracy 0.6442307692307693\n",
            "Mpca 330 Mlda 20 Accuracy 0.6442307692307693\n",
            "Mpca 330 Mlda 21 Accuracy 0.6346153846153846\n",
            "Mpca 330 Mlda 22 Accuracy 0.6442307692307693\n",
            "Mpca 330 Mlda 23 Accuracy 0.6538461538461539\n",
            "Mpca 330 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 330 Mlda 25 Accuracy 0.6730769230769231\n",
            "Mpca 330 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 330 Mlda 27 Accuracy 0.6826923076923077\n",
            "Mpca 330 Mlda 28 Accuracy 0.6826923076923077\n",
            "Mpca 330 Mlda 29 Accuracy 0.6826923076923077\n",
            "Mpca 330 Mlda 30 Accuracy 0.6826923076923077\n",
            "Mpca 330 Mlda 31 Accuracy 0.6826923076923077\n",
            "Mpca 330 Mlda 32 Accuracy 0.6923076923076923\n",
            "Mpca 330 Mlda 33 Accuracy 0.6923076923076923\n",
            "Mpca 330 Mlda 34 Accuracy 0.6923076923076923\n",
            "Mpca 330 Mlda 35 Accuracy 0.7115384615384616\n",
            "Mpca 330 Mlda 36 Accuracy 0.7211538461538461\n",
            "Mpca 330 Mlda 37 Accuracy 0.7211538461538461\n",
            "Mpca 330 Mlda 38 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 39 Accuracy 0.7211538461538461\n",
            "Mpca 330 Mlda 40 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 41 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 42 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 43 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 44 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 45 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 46 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 47 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 48 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 49 Accuracy 0.7307692307692307\n",
            "Mpca 330 Mlda 50 Accuracy 0.7307692307692307\n",
            "Mpca 331 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 331 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 331 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 331 Mlda 4 Accuracy 0.23076923076923078\n",
            "Mpca 331 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 331 Mlda 6 Accuracy 0.40384615384615385\n",
            "Mpca 331 Mlda 7 Accuracy 0.4326923076923077\n",
            "Mpca 331 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 331 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 331 Mlda 10 Accuracy 0.49038461538461536\n",
            "Mpca 331 Mlda 11 Accuracy 0.5096153846153846\n",
            "Mpca 331 Mlda 12 Accuracy 0.5192307692307693\n",
            "Mpca 331 Mlda 13 Accuracy 0.5384615384615384\n",
            "Mpca 331 Mlda 14 Accuracy 0.5576923076923077\n",
            "Mpca 331 Mlda 15 Accuracy 0.6057692307692307\n",
            "Mpca 331 Mlda 16 Accuracy 0.625\n",
            "Mpca 331 Mlda 17 Accuracy 0.6153846153846154\n",
            "Mpca 331 Mlda 18 Accuracy 0.6057692307692307\n",
            "Mpca 331 Mlda 19 Accuracy 0.6153846153846154\n",
            "Mpca 331 Mlda 20 Accuracy 0.6442307692307693\n",
            "Mpca 331 Mlda 21 Accuracy 0.6442307692307693\n",
            "Mpca 331 Mlda 22 Accuracy 0.6442307692307693\n",
            "Mpca 331 Mlda 23 Accuracy 0.6442307692307693\n",
            "Mpca 331 Mlda 24 Accuracy 0.6730769230769231\n",
            "Mpca 331 Mlda 25 Accuracy 0.6634615384615384\n",
            "Mpca 331 Mlda 26 Accuracy 0.6730769230769231\n",
            "Mpca 331 Mlda 27 Accuracy 0.6826923076923077\n",
            "Mpca 331 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 331 Mlda 29 Accuracy 0.6923076923076923\n",
            "Mpca 331 Mlda 30 Accuracy 0.6826923076923077\n",
            "Mpca 331 Mlda 31 Accuracy 0.6923076923076923\n",
            "Mpca 331 Mlda 32 Accuracy 0.6923076923076923\n",
            "Mpca 331 Mlda 33 Accuracy 0.6923076923076923\n",
            "Mpca 331 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 331 Mlda 35 Accuracy 0.7019230769230769\n",
            "Mpca 331 Mlda 36 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 37 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 38 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 39 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 40 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 41 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 42 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 43 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 44 Accuracy 0.7115384615384616\n",
            "Mpca 331 Mlda 45 Accuracy 0.7211538461538461\n",
            "Mpca 331 Mlda 46 Accuracy 0.7211538461538461\n",
            "Mpca 331 Mlda 47 Accuracy 0.7211538461538461\n",
            "Mpca 331 Mlda 48 Accuracy 0.7211538461538461\n",
            "Mpca 331 Mlda 49 Accuracy 0.7211538461538461\n",
            "Mpca 331 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 332 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 332 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 332 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 332 Mlda 4 Accuracy 0.23076923076923078\n",
            "Mpca 332 Mlda 5 Accuracy 0.3269230769230769\n",
            "Mpca 332 Mlda 6 Accuracy 0.3942307692307692\n",
            "Mpca 332 Mlda 7 Accuracy 0.4230769230769231\n",
            "Mpca 332 Mlda 8 Accuracy 0.40384615384615385\n",
            "Mpca 332 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 332 Mlda 10 Accuracy 0.5\n",
            "Mpca 332 Mlda 11 Accuracy 0.5384615384615384\n",
            "Mpca 332 Mlda 12 Accuracy 0.5480769230769231\n",
            "Mpca 332 Mlda 13 Accuracy 0.5480769230769231\n",
            "Mpca 332 Mlda 14 Accuracy 0.5673076923076923\n",
            "Mpca 332 Mlda 15 Accuracy 0.5865384615384616\n",
            "Mpca 332 Mlda 16 Accuracy 0.5961538461538461\n",
            "Mpca 332 Mlda 17 Accuracy 0.6153846153846154\n",
            "Mpca 332 Mlda 18 Accuracy 0.6153846153846154\n",
            "Mpca 332 Mlda 19 Accuracy 0.625\n",
            "Mpca 332 Mlda 20 Accuracy 0.6346153846153846\n",
            "Mpca 332 Mlda 21 Accuracy 0.6346153846153846\n",
            "Mpca 332 Mlda 22 Accuracy 0.6346153846153846\n",
            "Mpca 332 Mlda 23 Accuracy 0.6346153846153846\n",
            "Mpca 332 Mlda 24 Accuracy 0.6538461538461539\n",
            "Mpca 332 Mlda 25 Accuracy 0.6538461538461539\n",
            "Mpca 332 Mlda 26 Accuracy 0.6634615384615384\n",
            "Mpca 332 Mlda 27 Accuracy 0.6634615384615384\n",
            "Mpca 332 Mlda 28 Accuracy 0.6730769230769231\n",
            "Mpca 332 Mlda 29 Accuracy 0.6730769230769231\n",
            "Mpca 332 Mlda 30 Accuracy 0.6634615384615384\n",
            "Mpca 332 Mlda 31 Accuracy 0.6634615384615384\n",
            "Mpca 332 Mlda 32 Accuracy 0.6538461538461539\n",
            "Mpca 332 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 332 Mlda 34 Accuracy 0.7019230769230769\n",
            "Mpca 332 Mlda 35 Accuracy 0.6826923076923077\n",
            "Mpca 332 Mlda 36 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 37 Accuracy 0.7211538461538461\n",
            "Mpca 332 Mlda 38 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 39 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 332 Mlda 41 Accuracy 0.7019230769230769\n",
            "Mpca 332 Mlda 42 Accuracy 0.7019230769230769\n",
            "Mpca 332 Mlda 43 Accuracy 0.7019230769230769\n",
            "Mpca 332 Mlda 44 Accuracy 0.7019230769230769\n",
            "Mpca 332 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 46 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 47 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 48 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 332 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 333 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 333 Mlda 2 Accuracy 0.125\n",
            "Mpca 333 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 333 Mlda 4 Accuracy 0.27884615384615385\n",
            "Mpca 333 Mlda 5 Accuracy 0.2692307692307692\n",
            "Mpca 333 Mlda 6 Accuracy 0.33653846153846156\n",
            "Mpca 333 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 333 Mlda 8 Accuracy 0.4423076923076923\n",
            "Mpca 333 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 333 Mlda 10 Accuracy 0.4519230769230769\n",
            "Mpca 333 Mlda 11 Accuracy 0.5288461538461539\n",
            "Mpca 333 Mlda 12 Accuracy 0.5288461538461539\n",
            "Mpca 333 Mlda 13 Accuracy 0.5288461538461539\n",
            "Mpca 333 Mlda 14 Accuracy 0.5673076923076923\n",
            "Mpca 333 Mlda 15 Accuracy 0.5961538461538461\n",
            "Mpca 333 Mlda 16 Accuracy 0.5769230769230769\n",
            "Mpca 333 Mlda 17 Accuracy 0.6057692307692307\n",
            "Mpca 333 Mlda 18 Accuracy 0.6057692307692307\n",
            "Mpca 333 Mlda 19 Accuracy 0.5961538461538461\n",
            "Mpca 333 Mlda 20 Accuracy 0.6153846153846154\n",
            "Mpca 333 Mlda 21 Accuracy 0.625\n",
            "Mpca 333 Mlda 22 Accuracy 0.6442307692307693\n",
            "Mpca 333 Mlda 23 Accuracy 0.6442307692307693\n",
            "Mpca 333 Mlda 24 Accuracy 0.6346153846153846\n",
            "Mpca 333 Mlda 25 Accuracy 0.625\n",
            "Mpca 333 Mlda 26 Accuracy 0.6346153846153846\n",
            "Mpca 333 Mlda 27 Accuracy 0.6634615384615384\n",
            "Mpca 333 Mlda 28 Accuracy 0.6634615384615384\n",
            "Mpca 333 Mlda 29 Accuracy 0.6730769230769231\n",
            "Mpca 333 Mlda 30 Accuracy 0.6730769230769231\n",
            "Mpca 333 Mlda 31 Accuracy 0.6634615384615384\n",
            "Mpca 333 Mlda 32 Accuracy 0.6634615384615384\n",
            "Mpca 333 Mlda 33 Accuracy 0.6826923076923077\n",
            "Mpca 333 Mlda 34 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 35 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 36 Accuracy 0.7019230769230769\n",
            "Mpca 333 Mlda 37 Accuracy 0.7019230769230769\n",
            "Mpca 333 Mlda 38 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 39 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 41 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 42 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 43 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 44 Accuracy 0.6923076923076923\n",
            "Mpca 333 Mlda 45 Accuracy 0.7019230769230769\n",
            "Mpca 333 Mlda 46 Accuracy 0.7019230769230769\n",
            "Mpca 333 Mlda 47 Accuracy 0.7019230769230769\n",
            "Mpca 333 Mlda 48 Accuracy 0.7019230769230769\n",
            "Mpca 333 Mlda 49 Accuracy 0.7019230769230769\n",
            "Mpca 333 Mlda 50 Accuracy 0.7019230769230769\n",
            "Mpca 334 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 334 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 334 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 334 Mlda 4 Accuracy 0.2692307692307692\n",
            "Mpca 334 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 334 Mlda 6 Accuracy 0.34615384615384615\n",
            "Mpca 334 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 334 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 334 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 334 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 334 Mlda 11 Accuracy 0.5096153846153846\n",
            "Mpca 334 Mlda 12 Accuracy 0.49038461538461536\n",
            "Mpca 334 Mlda 13 Accuracy 0.5384615384615384\n",
            "Mpca 334 Mlda 14 Accuracy 0.5673076923076923\n",
            "Mpca 334 Mlda 15 Accuracy 0.5865384615384616\n",
            "Mpca 334 Mlda 16 Accuracy 0.5961538461538461\n",
            "Mpca 334 Mlda 17 Accuracy 0.6057692307692307\n",
            "Mpca 334 Mlda 18 Accuracy 0.6057692307692307\n",
            "Mpca 334 Mlda 19 Accuracy 0.5961538461538461\n",
            "Mpca 334 Mlda 20 Accuracy 0.6346153846153846\n",
            "Mpca 334 Mlda 21 Accuracy 0.6346153846153846\n",
            "Mpca 334 Mlda 22 Accuracy 0.6634615384615384\n",
            "Mpca 334 Mlda 23 Accuracy 0.6634615384615384\n",
            "Mpca 334 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 334 Mlda 25 Accuracy 0.6634615384615384\n",
            "Mpca 334 Mlda 26 Accuracy 0.6826923076923077\n",
            "Mpca 334 Mlda 27 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 28 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 29 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 30 Accuracy 0.6826923076923077\n",
            "Mpca 334 Mlda 31 Accuracy 0.6826923076923077\n",
            "Mpca 334 Mlda 32 Accuracy 0.6826923076923077\n",
            "Mpca 334 Mlda 33 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 34 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 35 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 36 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 37 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 38 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 39 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 41 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 42 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 43 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 44 Accuracy 0.6923076923076923\n",
            "Mpca 334 Mlda 45 Accuracy 0.7019230769230769\n",
            "Mpca 334 Mlda 46 Accuracy 0.7115384615384616\n",
            "Mpca 334 Mlda 47 Accuracy 0.7115384615384616\n",
            "Mpca 334 Mlda 48 Accuracy 0.7115384615384616\n",
            "Mpca 334 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 334 Mlda 50 Accuracy 0.7211538461538461\n",
            "Mpca 335 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 335 Mlda 2 Accuracy 0.057692307692307696\n",
            "Mpca 335 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 335 Mlda 4 Accuracy 0.21153846153846154\n",
            "Mpca 335 Mlda 5 Accuracy 0.27884615384615385\n",
            "Mpca 335 Mlda 6 Accuracy 0.2980769230769231\n",
            "Mpca 335 Mlda 7 Accuracy 0.40384615384615385\n",
            "Mpca 335 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 335 Mlda 9 Accuracy 0.46153846153846156\n",
            "Mpca 335 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 335 Mlda 11 Accuracy 0.49038461538461536\n",
            "Mpca 335 Mlda 12 Accuracy 0.49038461538461536\n",
            "Mpca 335 Mlda 13 Accuracy 0.5096153846153846\n",
            "Mpca 335 Mlda 14 Accuracy 0.5384615384615384\n",
            "Mpca 335 Mlda 15 Accuracy 0.5384615384615384\n",
            "Mpca 335 Mlda 16 Accuracy 0.5384615384615384\n",
            "Mpca 335 Mlda 17 Accuracy 0.5673076923076923\n",
            "Mpca 335 Mlda 18 Accuracy 0.5865384615384616\n",
            "Mpca 335 Mlda 19 Accuracy 0.5769230769230769\n",
            "Mpca 335 Mlda 20 Accuracy 0.5769230769230769\n",
            "Mpca 335 Mlda 21 Accuracy 0.5865384615384616\n",
            "Mpca 335 Mlda 22 Accuracy 0.6153846153846154\n",
            "Mpca 335 Mlda 23 Accuracy 0.6346153846153846\n",
            "Mpca 335 Mlda 24 Accuracy 0.6538461538461539\n",
            "Mpca 335 Mlda 25 Accuracy 0.6442307692307693\n",
            "Mpca 335 Mlda 26 Accuracy 0.6442307692307693\n",
            "Mpca 335 Mlda 27 Accuracy 0.6346153846153846\n",
            "Mpca 335 Mlda 28 Accuracy 0.6442307692307693\n",
            "Mpca 335 Mlda 29 Accuracy 0.6442307692307693\n",
            "Mpca 335 Mlda 30 Accuracy 0.6538461538461539\n",
            "Mpca 335 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 335 Mlda 32 Accuracy 0.6538461538461539\n",
            "Mpca 335 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 34 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 35 Accuracy 0.6538461538461539\n",
            "Mpca 335 Mlda 36 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 37 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 38 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 39 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 40 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 41 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 42 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 43 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 44 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 45 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 46 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 47 Accuracy 0.6634615384615384\n",
            "Mpca 335 Mlda 48 Accuracy 0.6826923076923077\n",
            "Mpca 335 Mlda 49 Accuracy 0.6730769230769231\n",
            "Mpca 335 Mlda 50 Accuracy 0.6826923076923077\n",
            "Mpca 336 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 336 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 336 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 336 Mlda 4 Accuracy 0.21153846153846154\n",
            "Mpca 336 Mlda 5 Accuracy 0.25961538461538464\n",
            "Mpca 336 Mlda 6 Accuracy 0.2980769230769231\n",
            "Mpca 336 Mlda 7 Accuracy 0.38461538461538464\n",
            "Mpca 336 Mlda 8 Accuracy 0.375\n",
            "Mpca 336 Mlda 9 Accuracy 0.4326923076923077\n",
            "Mpca 336 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 336 Mlda 11 Accuracy 0.49038461538461536\n",
            "Mpca 336 Mlda 12 Accuracy 0.5192307692307693\n",
            "Mpca 336 Mlda 13 Accuracy 0.5096153846153846\n",
            "Mpca 336 Mlda 14 Accuracy 0.5384615384615384\n",
            "Mpca 336 Mlda 15 Accuracy 0.5769230769230769\n",
            "Mpca 336 Mlda 16 Accuracy 0.5480769230769231\n",
            "Mpca 336 Mlda 17 Accuracy 0.5384615384615384\n",
            "Mpca 336 Mlda 18 Accuracy 0.5673076923076923\n",
            "Mpca 336 Mlda 19 Accuracy 0.5576923076923077\n",
            "Mpca 336 Mlda 20 Accuracy 0.5769230769230769\n",
            "Mpca 336 Mlda 21 Accuracy 0.5961538461538461\n",
            "Mpca 336 Mlda 22 Accuracy 0.625\n",
            "Mpca 336 Mlda 23 Accuracy 0.6442307692307693\n",
            "Mpca 336 Mlda 24 Accuracy 0.6634615384615384\n",
            "Mpca 336 Mlda 25 Accuracy 0.6442307692307693\n",
            "Mpca 336 Mlda 26 Accuracy 0.6346153846153846\n",
            "Mpca 336 Mlda 27 Accuracy 0.6346153846153846\n",
            "Mpca 336 Mlda 28 Accuracy 0.6346153846153846\n",
            "Mpca 336 Mlda 29 Accuracy 0.6538461538461539\n",
            "Mpca 336 Mlda 30 Accuracy 0.6634615384615384\n",
            "Mpca 336 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 336 Mlda 32 Accuracy 0.6538461538461539\n",
            "Mpca 336 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 336 Mlda 34 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 35 Accuracy 0.6634615384615384\n",
            "Mpca 336 Mlda 36 Accuracy 0.6826923076923077\n",
            "Mpca 336 Mlda 37 Accuracy 0.6826923076923077\n",
            "Mpca 336 Mlda 38 Accuracy 0.6826923076923077\n",
            "Mpca 336 Mlda 39 Accuracy 0.6826923076923077\n",
            "Mpca 336 Mlda 40 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 41 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 42 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 43 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 44 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 45 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 46 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 47 Accuracy 0.6730769230769231\n",
            "Mpca 336 Mlda 48 Accuracy 0.6826923076923077\n",
            "Mpca 336 Mlda 49 Accuracy 0.6923076923076923\n",
            "Mpca 336 Mlda 50 Accuracy 0.6923076923076923\n",
            "Mpca 337 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 337 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 337 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 337 Mlda 4 Accuracy 0.22115384615384615\n",
            "Mpca 337 Mlda 5 Accuracy 0.2403846153846154\n",
            "Mpca 337 Mlda 6 Accuracy 0.27884615384615385\n",
            "Mpca 337 Mlda 7 Accuracy 0.375\n",
            "Mpca 337 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 337 Mlda 9 Accuracy 0.4230769230769231\n",
            "Mpca 337 Mlda 10 Accuracy 0.4423076923076923\n",
            "Mpca 337 Mlda 11 Accuracy 0.47115384615384615\n",
            "Mpca 337 Mlda 12 Accuracy 0.4807692307692308\n",
            "Mpca 337 Mlda 13 Accuracy 0.5\n",
            "Mpca 337 Mlda 14 Accuracy 0.5288461538461539\n",
            "Mpca 337 Mlda 15 Accuracy 0.5384615384615384\n",
            "Mpca 337 Mlda 16 Accuracy 0.5576923076923077\n",
            "Mpca 337 Mlda 17 Accuracy 0.5576923076923077\n",
            "Mpca 337 Mlda 18 Accuracy 0.5769230769230769\n",
            "Mpca 337 Mlda 19 Accuracy 0.5673076923076923\n",
            "Mpca 337 Mlda 20 Accuracy 0.5769230769230769\n",
            "Mpca 337 Mlda 21 Accuracy 0.5769230769230769\n",
            "Mpca 337 Mlda 22 Accuracy 0.5865384615384616\n",
            "Mpca 337 Mlda 23 Accuracy 0.5961538461538461\n",
            "Mpca 337 Mlda 24 Accuracy 0.6442307692307693\n",
            "Mpca 337 Mlda 25 Accuracy 0.6346153846153846\n",
            "Mpca 337 Mlda 26 Accuracy 0.6057692307692307\n",
            "Mpca 337 Mlda 27 Accuracy 0.6057692307692307\n",
            "Mpca 337 Mlda 28 Accuracy 0.625\n",
            "Mpca 337 Mlda 29 Accuracy 0.6442307692307693\n",
            "Mpca 337 Mlda 30 Accuracy 0.6346153846153846\n",
            "Mpca 337 Mlda 31 Accuracy 0.6442307692307693\n",
            "Mpca 337 Mlda 32 Accuracy 0.6442307692307693\n",
            "Mpca 337 Mlda 33 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 34 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 35 Accuracy 0.6442307692307693\n",
            "Mpca 337 Mlda 36 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 37 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 38 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 39 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 40 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 41 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 42 Accuracy 0.6538461538461539\n",
            "Mpca 337 Mlda 43 Accuracy 0.6634615384615384\n",
            "Mpca 337 Mlda 44 Accuracy 0.6634615384615384\n",
            "Mpca 337 Mlda 45 Accuracy 0.6634615384615384\n",
            "Mpca 337 Mlda 46 Accuracy 0.6634615384615384\n",
            "Mpca 337 Mlda 47 Accuracy 0.6634615384615384\n",
            "Mpca 337 Mlda 48 Accuracy 0.6634615384615384\n",
            "Mpca 337 Mlda 49 Accuracy 0.6634615384615384\n",
            "Mpca 337 Mlda 50 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 338 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 338 Mlda 3 Accuracy 0.17307692307692307\n",
            "Mpca 338 Mlda 4 Accuracy 0.21153846153846154\n",
            "Mpca 338 Mlda 5 Accuracy 0.27884615384615385\n",
            "Mpca 338 Mlda 6 Accuracy 0.2692307692307692\n",
            "Mpca 338 Mlda 7 Accuracy 0.36538461538461536\n",
            "Mpca 338 Mlda 8 Accuracy 0.40384615384615385\n",
            "Mpca 338 Mlda 9 Accuracy 0.41346153846153844\n",
            "Mpca 338 Mlda 10 Accuracy 0.4423076923076923\n",
            "Mpca 338 Mlda 11 Accuracy 0.46153846153846156\n",
            "Mpca 338 Mlda 12 Accuracy 0.47115384615384615\n",
            "Mpca 338 Mlda 13 Accuracy 0.5\n",
            "Mpca 338 Mlda 14 Accuracy 0.5480769230769231\n",
            "Mpca 338 Mlda 15 Accuracy 0.5673076923076923\n",
            "Mpca 338 Mlda 16 Accuracy 0.5673076923076923\n",
            "Mpca 338 Mlda 17 Accuracy 0.5769230769230769\n",
            "Mpca 338 Mlda 18 Accuracy 0.5576923076923077\n",
            "Mpca 338 Mlda 19 Accuracy 0.5576923076923077\n",
            "Mpca 338 Mlda 20 Accuracy 0.5769230769230769\n",
            "Mpca 338 Mlda 21 Accuracy 0.5961538461538461\n",
            "Mpca 338 Mlda 22 Accuracy 0.5961538461538461\n",
            "Mpca 338 Mlda 23 Accuracy 0.6153846153846154\n",
            "Mpca 338 Mlda 24 Accuracy 0.6153846153846154\n",
            "Mpca 338 Mlda 25 Accuracy 0.6346153846153846\n",
            "Mpca 338 Mlda 26 Accuracy 0.6153846153846154\n",
            "Mpca 338 Mlda 27 Accuracy 0.6153846153846154\n",
            "Mpca 338 Mlda 28 Accuracy 0.6346153846153846\n",
            "Mpca 338 Mlda 29 Accuracy 0.6442307692307693\n",
            "Mpca 338 Mlda 30 Accuracy 0.6538461538461539\n",
            "Mpca 338 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 338 Mlda 32 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 33 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 34 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 35 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 36 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 37 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 38 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 39 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 40 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 41 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 42 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 43 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 44 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 45 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 46 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 47 Accuracy 0.6634615384615384\n",
            "Mpca 338 Mlda 48 Accuracy 0.6730769230769231\n",
            "Mpca 338 Mlda 49 Accuracy 0.6826923076923077\n",
            "Mpca 338 Mlda 50 Accuracy 0.6826923076923077\n",
            "Mpca 339 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 339 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 339 Mlda 3 Accuracy 0.14423076923076922\n",
            "Mpca 339 Mlda 4 Accuracy 0.21153846153846154\n",
            "Mpca 339 Mlda 5 Accuracy 0.2980769230769231\n",
            "Mpca 339 Mlda 6 Accuracy 0.27884615384615385\n",
            "Mpca 339 Mlda 7 Accuracy 0.34615384615384615\n",
            "Mpca 339 Mlda 8 Accuracy 0.41346153846153844\n",
            "Mpca 339 Mlda 9 Accuracy 0.4230769230769231\n",
            "Mpca 339 Mlda 10 Accuracy 0.40384615384615385\n",
            "Mpca 339 Mlda 11 Accuracy 0.4519230769230769\n",
            "Mpca 339 Mlda 12 Accuracy 0.46153846153846156\n",
            "Mpca 339 Mlda 13 Accuracy 0.5384615384615384\n",
            "Mpca 339 Mlda 14 Accuracy 0.5192307692307693\n",
            "Mpca 339 Mlda 15 Accuracy 0.5673076923076923\n",
            "Mpca 339 Mlda 16 Accuracy 0.5673076923076923\n",
            "Mpca 339 Mlda 17 Accuracy 0.5769230769230769\n",
            "Mpca 339 Mlda 18 Accuracy 0.5673076923076923\n",
            "Mpca 339 Mlda 19 Accuracy 0.5673076923076923\n",
            "Mpca 339 Mlda 20 Accuracy 0.5961538461538461\n",
            "Mpca 339 Mlda 21 Accuracy 0.5961538461538461\n",
            "Mpca 339 Mlda 22 Accuracy 0.5961538461538461\n",
            "Mpca 339 Mlda 23 Accuracy 0.625\n",
            "Mpca 339 Mlda 24 Accuracy 0.6442307692307693\n",
            "Mpca 339 Mlda 25 Accuracy 0.625\n",
            "Mpca 339 Mlda 26 Accuracy 0.6153846153846154\n",
            "Mpca 339 Mlda 27 Accuracy 0.6153846153846154\n",
            "Mpca 339 Mlda 28 Accuracy 0.6442307692307693\n",
            "Mpca 339 Mlda 29 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 30 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 32 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 34 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 35 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 36 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 37 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 38 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 39 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 40 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 41 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 42 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 43 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 44 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 45 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 46 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 47 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 48 Accuracy 0.6538461538461539\n",
            "Mpca 339 Mlda 49 Accuracy 0.6634615384615384\n",
            "Mpca 339 Mlda 50 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 1 Accuracy 0.08653846153846154\n",
            "Mpca 340 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 340 Mlda 3 Accuracy 0.16346153846153846\n",
            "Mpca 340 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 340 Mlda 5 Accuracy 0.25\n",
            "Mpca 340 Mlda 6 Accuracy 0.28846153846153844\n",
            "Mpca 340 Mlda 7 Accuracy 0.33653846153846156\n",
            "Mpca 340 Mlda 8 Accuracy 0.38461538461538464\n",
            "Mpca 340 Mlda 9 Accuracy 0.4423076923076923\n",
            "Mpca 340 Mlda 10 Accuracy 0.41346153846153844\n",
            "Mpca 340 Mlda 11 Accuracy 0.4807692307692308\n",
            "Mpca 340 Mlda 12 Accuracy 0.4807692307692308\n",
            "Mpca 340 Mlda 13 Accuracy 0.5192307692307693\n",
            "Mpca 340 Mlda 14 Accuracy 0.5288461538461539\n",
            "Mpca 340 Mlda 15 Accuracy 0.5384615384615384\n",
            "Mpca 340 Mlda 16 Accuracy 0.5384615384615384\n",
            "Mpca 340 Mlda 17 Accuracy 0.5673076923076923\n",
            "Mpca 340 Mlda 18 Accuracy 0.5673076923076923\n",
            "Mpca 340 Mlda 19 Accuracy 0.5673076923076923\n",
            "Mpca 340 Mlda 20 Accuracy 0.5576923076923077\n",
            "Mpca 340 Mlda 21 Accuracy 0.5673076923076923\n",
            "Mpca 340 Mlda 22 Accuracy 0.5961538461538461\n",
            "Mpca 340 Mlda 23 Accuracy 0.6153846153846154\n",
            "Mpca 340 Mlda 24 Accuracy 0.6442307692307693\n",
            "Mpca 340 Mlda 25 Accuracy 0.6153846153846154\n",
            "Mpca 340 Mlda 26 Accuracy 0.625\n",
            "Mpca 340 Mlda 27 Accuracy 0.625\n",
            "Mpca 340 Mlda 28 Accuracy 0.6346153846153846\n",
            "Mpca 340 Mlda 29 Accuracy 0.6153846153846154\n",
            "Mpca 340 Mlda 30 Accuracy 0.6442307692307693\n",
            "Mpca 340 Mlda 31 Accuracy 0.6538461538461539\n",
            "Mpca 340 Mlda 32 Accuracy 0.6538461538461539\n",
            "Mpca 340 Mlda 33 Accuracy 0.6538461538461539\n",
            "Mpca 340 Mlda 34 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 35 Accuracy 0.6538461538461539\n",
            "Mpca 340 Mlda 36 Accuracy 0.6538461538461539\n",
            "Mpca 340 Mlda 37 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 38 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 39 Accuracy 0.6730769230769231\n",
            "Mpca 340 Mlda 40 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 41 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 42 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 43 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 44 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 45 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 46 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 47 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 48 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 49 Accuracy 0.6634615384615384\n",
            "Mpca 340 Mlda 50 Accuracy 0.6538461538461539\n",
            "Mpca 341 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 341 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 341 Mlda 3 Accuracy 0.19230769230769232\n",
            "Mpca 341 Mlda 4 Accuracy 0.25\n",
            "Mpca 341 Mlda 5 Accuracy 0.3173076923076923\n",
            "Mpca 341 Mlda 6 Accuracy 0.3173076923076923\n",
            "Mpca 341 Mlda 7 Accuracy 0.38461538461538464\n",
            "Mpca 341 Mlda 8 Accuracy 0.4326923076923077\n",
            "Mpca 341 Mlda 9 Accuracy 0.4519230769230769\n",
            "Mpca 341 Mlda 10 Accuracy 0.46153846153846156\n",
            "Mpca 341 Mlda 11 Accuracy 0.47115384615384615\n",
            "Mpca 341 Mlda 12 Accuracy 0.4807692307692308\n",
            "Mpca 341 Mlda 13 Accuracy 0.5288461538461539\n",
            "Mpca 341 Mlda 14 Accuracy 0.5384615384615384\n",
            "Mpca 341 Mlda 15 Accuracy 0.5384615384615384\n",
            "Mpca 341 Mlda 16 Accuracy 0.5673076923076923\n",
            "Mpca 341 Mlda 17 Accuracy 0.5961538461538461\n",
            "Mpca 341 Mlda 18 Accuracy 0.5865384615384616\n",
            "Mpca 341 Mlda 19 Accuracy 0.5865384615384616\n",
            "Mpca 341 Mlda 20 Accuracy 0.5961538461538461\n",
            "Mpca 341 Mlda 21 Accuracy 0.5961538461538461\n",
            "Mpca 341 Mlda 22 Accuracy 0.6057692307692307\n",
            "Mpca 341 Mlda 23 Accuracy 0.6346153846153846\n",
            "Mpca 341 Mlda 24 Accuracy 0.6346153846153846\n",
            "Mpca 341 Mlda 25 Accuracy 0.625\n",
            "Mpca 341 Mlda 26 Accuracy 0.6153846153846154\n",
            "Mpca 341 Mlda 27 Accuracy 0.6346153846153846\n",
            "Mpca 341 Mlda 28 Accuracy 0.6538461538461539\n",
            "Mpca 341 Mlda 29 Accuracy 0.6538461538461539\n",
            "Mpca 341 Mlda 30 Accuracy 0.6634615384615384\n",
            "Mpca 341 Mlda 31 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 32 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 33 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 34 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 35 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 36 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 37 Accuracy 0.6826923076923077\n",
            "Mpca 341 Mlda 38 Accuracy 0.6826923076923077\n",
            "Mpca 341 Mlda 39 Accuracy 0.6826923076923077\n",
            "Mpca 341 Mlda 40 Accuracy 0.6826923076923077\n",
            "Mpca 341 Mlda 41 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 42 Accuracy 0.6826923076923077\n",
            "Mpca 341 Mlda 43 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 44 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 45 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 46 Accuracy 0.6730769230769231\n",
            "Mpca 341 Mlda 47 Accuracy 0.6826923076923077\n",
            "Mpca 341 Mlda 48 Accuracy 0.6826923076923077\n",
            "Mpca 341 Mlda 49 Accuracy 0.6923076923076923\n",
            "Mpca 341 Mlda 50 Accuracy 0.6923076923076923\n",
            "Mpca 342 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 342 Mlda 2 Accuracy 0.057692307692307696\n",
            "Mpca 342 Mlda 3 Accuracy 0.14423076923076922\n",
            "Mpca 342 Mlda 4 Accuracy 0.20192307692307693\n",
            "Mpca 342 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 342 Mlda 6 Accuracy 0.3173076923076923\n",
            "Mpca 342 Mlda 7 Accuracy 0.34615384615384615\n",
            "Mpca 342 Mlda 8 Accuracy 0.4230769230769231\n",
            "Mpca 342 Mlda 9 Accuracy 0.47115384615384615\n",
            "Mpca 342 Mlda 10 Accuracy 0.46153846153846156\n",
            "Mpca 342 Mlda 11 Accuracy 0.46153846153846156\n",
            "Mpca 342 Mlda 12 Accuracy 0.49038461538461536\n",
            "Mpca 342 Mlda 13 Accuracy 0.5\n",
            "Mpca 342 Mlda 14 Accuracy 0.5384615384615384\n",
            "Mpca 342 Mlda 15 Accuracy 0.5576923076923077\n",
            "Mpca 342 Mlda 16 Accuracy 0.5384615384615384\n",
            "Mpca 342 Mlda 17 Accuracy 0.5576923076923077\n",
            "Mpca 342 Mlda 18 Accuracy 0.5961538461538461\n",
            "Mpca 342 Mlda 19 Accuracy 0.5769230769230769\n",
            "Mpca 342 Mlda 20 Accuracy 0.6153846153846154\n",
            "Mpca 342 Mlda 21 Accuracy 0.625\n",
            "Mpca 342 Mlda 22 Accuracy 0.6153846153846154\n",
            "Mpca 342 Mlda 23 Accuracy 0.6346153846153846\n",
            "Mpca 342 Mlda 24 Accuracy 0.6442307692307693\n",
            "Mpca 342 Mlda 25 Accuracy 0.6442307692307693\n",
            "Mpca 342 Mlda 26 Accuracy 0.6442307692307693\n",
            "Mpca 342 Mlda 27 Accuracy 0.6538461538461539\n",
            "Mpca 342 Mlda 28 Accuracy 0.6442307692307693\n",
            "Mpca 342 Mlda 29 Accuracy 0.6442307692307693\n",
            "Mpca 342 Mlda 30 Accuracy 0.6442307692307693\n",
            "Mpca 342 Mlda 31 Accuracy 0.6634615384615384\n",
            "Mpca 342 Mlda 32 Accuracy 0.6634615384615384\n",
            "Mpca 342 Mlda 33 Accuracy 0.6634615384615384\n",
            "Mpca 342 Mlda 34 Accuracy 0.6730769230769231\n",
            "Mpca 342 Mlda 35 Accuracy 0.6730769230769231\n",
            "Mpca 342 Mlda 36 Accuracy 0.6634615384615384\n",
            "Mpca 342 Mlda 37 Accuracy 0.6730769230769231\n",
            "Mpca 342 Mlda 38 Accuracy 0.6730769230769231\n",
            "Mpca 342 Mlda 39 Accuracy 0.6826923076923077\n",
            "Mpca 342 Mlda 40 Accuracy 0.6923076923076923\n",
            "Mpca 342 Mlda 41 Accuracy 0.6923076923076923\n",
            "Mpca 342 Mlda 42 Accuracy 0.6923076923076923\n",
            "Mpca 342 Mlda 43 Accuracy 0.7019230769230769\n",
            "Mpca 342 Mlda 44 Accuracy 0.7115384615384616\n",
            "Mpca 342 Mlda 45 Accuracy 0.7115384615384616\n",
            "Mpca 342 Mlda 46 Accuracy 0.7115384615384616\n",
            "Mpca 342 Mlda 47 Accuracy 0.7019230769230769\n",
            "Mpca 342 Mlda 48 Accuracy 0.7019230769230769\n",
            "Mpca 342 Mlda 49 Accuracy 0.7115384615384616\n",
            "Mpca 342 Mlda 50 Accuracy 0.7115384615384616\n",
            "Mpca 343 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 343 Mlda 2 Accuracy 0.10576923076923077\n",
            "Mpca 343 Mlda 3 Accuracy 0.18269230769230768\n",
            "Mpca 343 Mlda 4 Accuracy 0.25961538461538464\n",
            "Mpca 343 Mlda 5 Accuracy 0.28846153846153844\n",
            "Mpca 343 Mlda 6 Accuracy 0.2980769230769231\n",
            "Mpca 343 Mlda 7 Accuracy 0.34615384615384615\n",
            "Mpca 343 Mlda 8 Accuracy 0.41346153846153844\n",
            "Mpca 343 Mlda 9 Accuracy 0.4423076923076923\n",
            "Mpca 343 Mlda 10 Accuracy 0.47115384615384615\n",
            "Mpca 343 Mlda 11 Accuracy 0.47115384615384615\n",
            "Mpca 343 Mlda 12 Accuracy 0.47115384615384615\n",
            "Mpca 343 Mlda 13 Accuracy 0.46153846153846156\n",
            "Mpca 343 Mlda 14 Accuracy 0.5096153846153846\n",
            "Mpca 343 Mlda 15 Accuracy 0.5192307692307693\n",
            "Mpca 343 Mlda 16 Accuracy 0.5288461538461539\n",
            "Mpca 343 Mlda 17 Accuracy 0.5384615384615384\n",
            "Mpca 343 Mlda 18 Accuracy 0.5480769230769231\n",
            "Mpca 343 Mlda 19 Accuracy 0.5480769230769231\n",
            "Mpca 343 Mlda 20 Accuracy 0.5576923076923077\n",
            "Mpca 343 Mlda 21 Accuracy 0.5865384615384616\n",
            "Mpca 343 Mlda 22 Accuracy 0.5769230769230769\n",
            "Mpca 343 Mlda 23 Accuracy 0.5961538461538461\n",
            "Mpca 343 Mlda 24 Accuracy 0.5961538461538461\n",
            "Mpca 343 Mlda 25 Accuracy 0.6057692307692307\n",
            "Mpca 343 Mlda 26 Accuracy 0.6153846153846154\n",
            "Mpca 343 Mlda 27 Accuracy 0.625\n",
            "Mpca 343 Mlda 28 Accuracy 0.625\n",
            "Mpca 343 Mlda 29 Accuracy 0.625\n",
            "Mpca 343 Mlda 30 Accuracy 0.625\n",
            "Mpca 343 Mlda 31 Accuracy 0.6346153846153846\n",
            "Mpca 343 Mlda 32 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 33 Accuracy 0.6442307692307693\n",
            "Mpca 343 Mlda 34 Accuracy 0.6346153846153846\n",
            "Mpca 343 Mlda 35 Accuracy 0.6442307692307693\n",
            "Mpca 343 Mlda 36 Accuracy 0.6442307692307693\n",
            "Mpca 343 Mlda 37 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 38 Accuracy 0.6442307692307693\n",
            "Mpca 343 Mlda 39 Accuracy 0.6442307692307693\n",
            "Mpca 343 Mlda 40 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 41 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 42 Accuracy 0.6634615384615384\n",
            "Mpca 343 Mlda 43 Accuracy 0.6442307692307693\n",
            "Mpca 343 Mlda 44 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 45 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 46 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 47 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 48 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 49 Accuracy 0.6538461538461539\n",
            "Mpca 343 Mlda 50 Accuracy 0.6538461538461539\n",
            "Mpca 344 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 344 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 344 Mlda 3 Accuracy 0.1346153846153846\n",
            "Mpca 344 Mlda 4 Accuracy 0.19230769230769232\n",
            "Mpca 344 Mlda 5 Accuracy 0.2403846153846154\n",
            "Mpca 344 Mlda 6 Accuracy 0.2692307692307692\n",
            "Mpca 344 Mlda 7 Accuracy 0.28846153846153844\n",
            "Mpca 344 Mlda 8 Accuracy 0.3269230769230769\n",
            "Mpca 344 Mlda 9 Accuracy 0.3557692307692308\n",
            "Mpca 344 Mlda 10 Accuracy 0.3557692307692308\n",
            "Mpca 344 Mlda 11 Accuracy 0.375\n",
            "Mpca 344 Mlda 12 Accuracy 0.40384615384615385\n",
            "Mpca 344 Mlda 13 Accuracy 0.41346153846153844\n",
            "Mpca 344 Mlda 14 Accuracy 0.40384615384615385\n",
            "Mpca 344 Mlda 15 Accuracy 0.4230769230769231\n",
            "Mpca 344 Mlda 16 Accuracy 0.4423076923076923\n",
            "Mpca 344 Mlda 17 Accuracy 0.4230769230769231\n",
            "Mpca 344 Mlda 18 Accuracy 0.4326923076923077\n",
            "Mpca 344 Mlda 19 Accuracy 0.4807692307692308\n",
            "Mpca 344 Mlda 20 Accuracy 0.5\n",
            "Mpca 344 Mlda 21 Accuracy 0.5\n",
            "Mpca 344 Mlda 22 Accuracy 0.5096153846153846\n",
            "Mpca 344 Mlda 23 Accuracy 0.5288461538461539\n",
            "Mpca 344 Mlda 24 Accuracy 0.5288461538461539\n",
            "Mpca 344 Mlda 25 Accuracy 0.5384615384615384\n",
            "Mpca 344 Mlda 26 Accuracy 0.5288461538461539\n",
            "Mpca 344 Mlda 27 Accuracy 0.5384615384615384\n",
            "Mpca 344 Mlda 28 Accuracy 0.5384615384615384\n",
            "Mpca 344 Mlda 29 Accuracy 0.5480769230769231\n",
            "Mpca 344 Mlda 30 Accuracy 0.5576923076923077\n",
            "Mpca 344 Mlda 31 Accuracy 0.5576923076923077\n",
            "Mpca 344 Mlda 32 Accuracy 0.5480769230769231\n",
            "Mpca 344 Mlda 33 Accuracy 0.5480769230769231\n",
            "Mpca 344 Mlda 34 Accuracy 0.5673076923076923\n",
            "Mpca 344 Mlda 35 Accuracy 0.5673076923076923\n",
            "Mpca 344 Mlda 36 Accuracy 0.5769230769230769\n",
            "Mpca 344 Mlda 37 Accuracy 0.5865384615384616\n",
            "Mpca 344 Mlda 38 Accuracy 0.5961538461538461\n",
            "Mpca 344 Mlda 39 Accuracy 0.5865384615384616\n",
            "Mpca 344 Mlda 40 Accuracy 0.5865384615384616\n",
            "Mpca 344 Mlda 41 Accuracy 0.5865384615384616\n",
            "Mpca 344 Mlda 42 Accuracy 0.5961538461538461\n",
            "Mpca 344 Mlda 43 Accuracy 0.5961538461538461\n",
            "Mpca 344 Mlda 44 Accuracy 0.6153846153846154\n",
            "Mpca 344 Mlda 45 Accuracy 0.6153846153846154\n",
            "Mpca 344 Mlda 46 Accuracy 0.6153846153846154\n",
            "Mpca 344 Mlda 47 Accuracy 0.6153846153846154\n",
            "Mpca 344 Mlda 48 Accuracy 0.6153846153846154\n",
            "Mpca 344 Mlda 49 Accuracy 0.6153846153846154\n",
            "Mpca 344 Mlda 50 Accuracy 0.6153846153846154\n",
            "Mpca 345 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 345 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 345 Mlda 3 Accuracy 0.11538461538461539\n",
            "Mpca 345 Mlda 4 Accuracy 0.18269230769230768\n",
            "Mpca 345 Mlda 5 Accuracy 0.22115384615384615\n",
            "Mpca 345 Mlda 6 Accuracy 0.2980769230769231\n",
            "Mpca 345 Mlda 7 Accuracy 0.25961538461538464\n",
            "Mpca 345 Mlda 8 Accuracy 0.3173076923076923\n",
            "Mpca 345 Mlda 9 Accuracy 0.375\n",
            "Mpca 345 Mlda 10 Accuracy 0.38461538461538464\n",
            "Mpca 345 Mlda 11 Accuracy 0.375\n",
            "Mpca 345 Mlda 12 Accuracy 0.3942307692307692\n",
            "Mpca 345 Mlda 13 Accuracy 0.40384615384615385\n",
            "Mpca 345 Mlda 14 Accuracy 0.41346153846153844\n",
            "Mpca 345 Mlda 15 Accuracy 0.41346153846153844\n",
            "Mpca 345 Mlda 16 Accuracy 0.41346153846153844\n",
            "Mpca 345 Mlda 17 Accuracy 0.4423076923076923\n",
            "Mpca 345 Mlda 18 Accuracy 0.4519230769230769\n",
            "Mpca 345 Mlda 19 Accuracy 0.4423076923076923\n",
            "Mpca 345 Mlda 20 Accuracy 0.47115384615384615\n",
            "Mpca 345 Mlda 21 Accuracy 0.5096153846153846\n",
            "Mpca 345 Mlda 22 Accuracy 0.5096153846153846\n",
            "Mpca 345 Mlda 23 Accuracy 0.5384615384615384\n",
            "Mpca 345 Mlda 24 Accuracy 0.5384615384615384\n",
            "Mpca 345 Mlda 25 Accuracy 0.5288461538461539\n",
            "Mpca 345 Mlda 26 Accuracy 0.5480769230769231\n",
            "Mpca 345 Mlda 27 Accuracy 0.5576923076923077\n",
            "Mpca 345 Mlda 28 Accuracy 0.5480769230769231\n",
            "Mpca 345 Mlda 29 Accuracy 0.5384615384615384\n",
            "Mpca 345 Mlda 30 Accuracy 0.5480769230769231\n",
            "Mpca 345 Mlda 31 Accuracy 0.5480769230769231\n",
            "Mpca 345 Mlda 32 Accuracy 0.5576923076923077\n",
            "Mpca 345 Mlda 33 Accuracy 0.5576923076923077\n",
            "Mpca 345 Mlda 34 Accuracy 0.5576923076923077\n",
            "Mpca 345 Mlda 35 Accuracy 0.5576923076923077\n",
            "Mpca 345 Mlda 36 Accuracy 0.5576923076923077\n",
            "Mpca 345 Mlda 37 Accuracy 0.5673076923076923\n",
            "Mpca 345 Mlda 38 Accuracy 0.5769230769230769\n",
            "Mpca 345 Mlda 39 Accuracy 0.5769230769230769\n",
            "Mpca 345 Mlda 40 Accuracy 0.5769230769230769\n",
            "Mpca 345 Mlda 41 Accuracy 0.5769230769230769\n",
            "Mpca 345 Mlda 42 Accuracy 0.5769230769230769\n",
            "Mpca 345 Mlda 43 Accuracy 0.5769230769230769\n",
            "Mpca 345 Mlda 44 Accuracy 0.5865384615384616\n",
            "Mpca 345 Mlda 45 Accuracy 0.5961538461538461\n",
            "Mpca 345 Mlda 46 Accuracy 0.6057692307692307\n",
            "Mpca 345 Mlda 47 Accuracy 0.6057692307692307\n",
            "Mpca 345 Mlda 48 Accuracy 0.6153846153846154\n",
            "Mpca 345 Mlda 49 Accuracy 0.625\n",
            "Mpca 345 Mlda 50 Accuracy 0.6346153846153846\n",
            "Mpca 346 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 346 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 346 Mlda 3 Accuracy 0.11538461538461539\n",
            "Mpca 346 Mlda 4 Accuracy 0.17307692307692307\n",
            "Mpca 346 Mlda 5 Accuracy 0.20192307692307693\n",
            "Mpca 346 Mlda 6 Accuracy 0.25961538461538464\n",
            "Mpca 346 Mlda 7 Accuracy 0.25961538461538464\n",
            "Mpca 346 Mlda 8 Accuracy 0.3173076923076923\n",
            "Mpca 346 Mlda 9 Accuracy 0.3557692307692308\n",
            "Mpca 346 Mlda 10 Accuracy 0.3942307692307692\n",
            "Mpca 346 Mlda 11 Accuracy 0.4230769230769231\n",
            "Mpca 346 Mlda 12 Accuracy 0.41346153846153844\n",
            "Mpca 346 Mlda 13 Accuracy 0.41346153846153844\n",
            "Mpca 346 Mlda 14 Accuracy 0.4230769230769231\n",
            "Mpca 346 Mlda 15 Accuracy 0.4230769230769231\n",
            "Mpca 346 Mlda 16 Accuracy 0.4326923076923077\n",
            "Mpca 346 Mlda 17 Accuracy 0.4423076923076923\n",
            "Mpca 346 Mlda 18 Accuracy 0.4519230769230769\n",
            "Mpca 346 Mlda 19 Accuracy 0.46153846153846156\n",
            "Mpca 346 Mlda 20 Accuracy 0.47115384615384615\n",
            "Mpca 346 Mlda 21 Accuracy 0.47115384615384615\n",
            "Mpca 346 Mlda 22 Accuracy 0.49038461538461536\n",
            "Mpca 346 Mlda 23 Accuracy 0.5\n",
            "Mpca 346 Mlda 24 Accuracy 0.5\n",
            "Mpca 346 Mlda 25 Accuracy 0.5096153846153846\n",
            "Mpca 346 Mlda 26 Accuracy 0.5288461538461539\n",
            "Mpca 346 Mlda 27 Accuracy 0.5192307692307693\n",
            "Mpca 346 Mlda 28 Accuracy 0.5096153846153846\n",
            "Mpca 346 Mlda 29 Accuracy 0.5288461538461539\n",
            "Mpca 346 Mlda 30 Accuracy 0.5480769230769231\n",
            "Mpca 346 Mlda 31 Accuracy 0.5384615384615384\n",
            "Mpca 346 Mlda 32 Accuracy 0.5480769230769231\n",
            "Mpca 346 Mlda 33 Accuracy 0.5480769230769231\n",
            "Mpca 346 Mlda 34 Accuracy 0.5576923076923077\n",
            "Mpca 346 Mlda 35 Accuracy 0.5576923076923077\n",
            "Mpca 346 Mlda 36 Accuracy 0.5673076923076923\n",
            "Mpca 346 Mlda 37 Accuracy 0.5673076923076923\n",
            "Mpca 346 Mlda 38 Accuracy 0.5769230769230769\n",
            "Mpca 346 Mlda 39 Accuracy 0.5865384615384616\n",
            "Mpca 346 Mlda 40 Accuracy 0.5769230769230769\n",
            "Mpca 346 Mlda 41 Accuracy 0.5865384615384616\n",
            "Mpca 346 Mlda 42 Accuracy 0.5673076923076923\n",
            "Mpca 346 Mlda 43 Accuracy 0.5673076923076923\n",
            "Mpca 346 Mlda 44 Accuracy 0.5865384615384616\n",
            "Mpca 346 Mlda 45 Accuracy 0.5865384615384616\n",
            "Mpca 346 Mlda 46 Accuracy 0.5865384615384616\n",
            "Mpca 346 Mlda 47 Accuracy 0.5865384615384616\n",
            "Mpca 346 Mlda 48 Accuracy 0.5769230769230769\n",
            "Mpca 346 Mlda 49 Accuracy 0.5769230769230769\n",
            "Mpca 346 Mlda 50 Accuracy 0.5769230769230769\n",
            "Mpca 347 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 347 Mlda 2 Accuracy 0.11538461538461539\n",
            "Mpca 347 Mlda 3 Accuracy 0.1346153846153846\n",
            "Mpca 347 Mlda 4 Accuracy 0.20192307692307693\n",
            "Mpca 347 Mlda 5 Accuracy 0.21153846153846154\n",
            "Mpca 347 Mlda 6 Accuracy 0.25961538461538464\n",
            "Mpca 347 Mlda 7 Accuracy 0.25961538461538464\n",
            "Mpca 347 Mlda 8 Accuracy 0.3269230769230769\n",
            "Mpca 347 Mlda 9 Accuracy 0.36538461538461536\n",
            "Mpca 347 Mlda 10 Accuracy 0.40384615384615385\n",
            "Mpca 347 Mlda 11 Accuracy 0.41346153846153844\n",
            "Mpca 347 Mlda 12 Accuracy 0.40384615384615385\n",
            "Mpca 347 Mlda 13 Accuracy 0.40384615384615385\n",
            "Mpca 347 Mlda 14 Accuracy 0.4230769230769231\n",
            "Mpca 347 Mlda 15 Accuracy 0.41346153846153844\n",
            "Mpca 347 Mlda 16 Accuracy 0.4230769230769231\n",
            "Mpca 347 Mlda 17 Accuracy 0.4230769230769231\n",
            "Mpca 347 Mlda 18 Accuracy 0.4326923076923077\n",
            "Mpca 347 Mlda 19 Accuracy 0.4423076923076923\n",
            "Mpca 347 Mlda 20 Accuracy 0.47115384615384615\n",
            "Mpca 347 Mlda 21 Accuracy 0.4807692307692308\n",
            "Mpca 347 Mlda 22 Accuracy 0.4807692307692308\n",
            "Mpca 347 Mlda 23 Accuracy 0.49038461538461536\n",
            "Mpca 347 Mlda 24 Accuracy 0.49038461538461536\n",
            "Mpca 347 Mlda 25 Accuracy 0.5\n",
            "Mpca 347 Mlda 26 Accuracy 0.5192307692307693\n",
            "Mpca 347 Mlda 27 Accuracy 0.5288461538461539\n",
            "Mpca 347 Mlda 28 Accuracy 0.5288461538461539\n",
            "Mpca 347 Mlda 29 Accuracy 0.5384615384615384\n",
            "Mpca 347 Mlda 30 Accuracy 0.5384615384615384\n",
            "Mpca 347 Mlda 31 Accuracy 0.5288461538461539\n",
            "Mpca 347 Mlda 32 Accuracy 0.5384615384615384\n",
            "Mpca 347 Mlda 33 Accuracy 0.5384615384615384\n",
            "Mpca 347 Mlda 34 Accuracy 0.5576923076923077\n",
            "Mpca 347 Mlda 35 Accuracy 0.5673076923076923\n",
            "Mpca 347 Mlda 36 Accuracy 0.5769230769230769\n",
            "Mpca 347 Mlda 37 Accuracy 0.5865384615384616\n",
            "Mpca 347 Mlda 38 Accuracy 0.5865384615384616\n",
            "Mpca 347 Mlda 39 Accuracy 0.5865384615384616\n",
            "Mpca 347 Mlda 40 Accuracy 0.5865384615384616\n",
            "Mpca 347 Mlda 41 Accuracy 0.5961538461538461\n",
            "Mpca 347 Mlda 42 Accuracy 0.5865384615384616\n",
            "Mpca 347 Mlda 43 Accuracy 0.5961538461538461\n",
            "Mpca 347 Mlda 44 Accuracy 0.6057692307692307\n",
            "Mpca 347 Mlda 45 Accuracy 0.6057692307692307\n",
            "Mpca 347 Mlda 46 Accuracy 0.6057692307692307\n",
            "Mpca 347 Mlda 47 Accuracy 0.6057692307692307\n",
            "Mpca 347 Mlda 48 Accuracy 0.5961538461538461\n",
            "Mpca 347 Mlda 49 Accuracy 0.5865384615384616\n",
            "Mpca 347 Mlda 50 Accuracy 0.5961538461538461\n",
            "Mpca 348 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 348 Mlda 2 Accuracy 0.09615384615384616\n",
            "Mpca 348 Mlda 3 Accuracy 0.1346153846153846\n",
            "Mpca 348 Mlda 4 Accuracy 0.15384615384615385\n",
            "Mpca 348 Mlda 5 Accuracy 0.19230769230769232\n",
            "Mpca 348 Mlda 6 Accuracy 0.20192307692307693\n",
            "Mpca 348 Mlda 7 Accuracy 0.27884615384615385\n",
            "Mpca 348 Mlda 8 Accuracy 0.28846153846153844\n",
            "Mpca 348 Mlda 9 Accuracy 0.3557692307692308\n",
            "Mpca 348 Mlda 10 Accuracy 0.375\n",
            "Mpca 348 Mlda 11 Accuracy 0.3942307692307692\n",
            "Mpca 348 Mlda 12 Accuracy 0.38461538461538464\n",
            "Mpca 348 Mlda 13 Accuracy 0.3942307692307692\n",
            "Mpca 348 Mlda 14 Accuracy 0.4423076923076923\n",
            "Mpca 348 Mlda 15 Accuracy 0.4230769230769231\n",
            "Mpca 348 Mlda 16 Accuracy 0.4423076923076923\n",
            "Mpca 348 Mlda 17 Accuracy 0.4423076923076923\n",
            "Mpca 348 Mlda 18 Accuracy 0.46153846153846156\n",
            "Mpca 348 Mlda 19 Accuracy 0.46153846153846156\n",
            "Mpca 348 Mlda 20 Accuracy 0.46153846153846156\n",
            "Mpca 348 Mlda 21 Accuracy 0.47115384615384615\n",
            "Mpca 348 Mlda 22 Accuracy 0.49038461538461536\n",
            "Mpca 348 Mlda 23 Accuracy 0.5192307692307693\n",
            "Mpca 348 Mlda 24 Accuracy 0.5288461538461539\n",
            "Mpca 348 Mlda 25 Accuracy 0.5480769230769231\n",
            "Mpca 348 Mlda 26 Accuracy 0.5480769230769231\n",
            "Mpca 348 Mlda 27 Accuracy 0.5480769230769231\n",
            "Mpca 348 Mlda 28 Accuracy 0.5576923076923077\n",
            "Mpca 348 Mlda 29 Accuracy 0.5673076923076923\n",
            "Mpca 348 Mlda 30 Accuracy 0.5576923076923077\n",
            "Mpca 348 Mlda 31 Accuracy 0.5673076923076923\n",
            "Mpca 348 Mlda 32 Accuracy 0.5769230769230769\n",
            "Mpca 348 Mlda 33 Accuracy 0.5769230769230769\n",
            "Mpca 348 Mlda 34 Accuracy 0.5769230769230769\n",
            "Mpca 348 Mlda 35 Accuracy 0.5865384615384616\n",
            "Mpca 348 Mlda 36 Accuracy 0.5865384615384616\n",
            "Mpca 348 Mlda 37 Accuracy 0.5865384615384616\n",
            "Mpca 348 Mlda 38 Accuracy 0.5865384615384616\n",
            "Mpca 348 Mlda 39 Accuracy 0.5961538461538461\n",
            "Mpca 348 Mlda 40 Accuracy 0.5961538461538461\n",
            "Mpca 348 Mlda 41 Accuracy 0.6057692307692307\n",
            "Mpca 348 Mlda 42 Accuracy 0.6153846153846154\n",
            "Mpca 348 Mlda 43 Accuracy 0.625\n",
            "Mpca 348 Mlda 44 Accuracy 0.625\n",
            "Mpca 348 Mlda 45 Accuracy 0.6153846153846154\n",
            "Mpca 348 Mlda 46 Accuracy 0.6057692307692307\n",
            "Mpca 348 Mlda 47 Accuracy 0.6153846153846154\n",
            "Mpca 348 Mlda 48 Accuracy 0.6153846153846154\n",
            "Mpca 348 Mlda 49 Accuracy 0.6153846153846154\n",
            "Mpca 348 Mlda 50 Accuracy 0.6153846153846154\n",
            "Mpca 349 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 349 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 349 Mlda 3 Accuracy 0.125\n",
            "Mpca 349 Mlda 4 Accuracy 0.20192307692307693\n",
            "Mpca 349 Mlda 5 Accuracy 0.20192307692307693\n",
            "Mpca 349 Mlda 6 Accuracy 0.21153846153846154\n",
            "Mpca 349 Mlda 7 Accuracy 0.2692307692307692\n",
            "Mpca 349 Mlda 8 Accuracy 0.2980769230769231\n",
            "Mpca 349 Mlda 9 Accuracy 0.375\n",
            "Mpca 349 Mlda 10 Accuracy 0.375\n",
            "Mpca 349 Mlda 11 Accuracy 0.40384615384615385\n",
            "Mpca 349 Mlda 12 Accuracy 0.41346153846153844\n",
            "Mpca 349 Mlda 13 Accuracy 0.41346153846153844\n",
            "Mpca 349 Mlda 14 Accuracy 0.4326923076923077\n",
            "Mpca 349 Mlda 15 Accuracy 0.4326923076923077\n",
            "Mpca 349 Mlda 16 Accuracy 0.4326923076923077\n",
            "Mpca 349 Mlda 17 Accuracy 0.4423076923076923\n",
            "Mpca 349 Mlda 18 Accuracy 0.4519230769230769\n",
            "Mpca 349 Mlda 19 Accuracy 0.4519230769230769\n",
            "Mpca 349 Mlda 20 Accuracy 0.4519230769230769\n",
            "Mpca 349 Mlda 21 Accuracy 0.47115384615384615\n",
            "Mpca 349 Mlda 22 Accuracy 0.49038461538461536\n",
            "Mpca 349 Mlda 23 Accuracy 0.5\n",
            "Mpca 349 Mlda 24 Accuracy 0.49038461538461536\n",
            "Mpca 349 Mlda 25 Accuracy 0.5\n",
            "Mpca 349 Mlda 26 Accuracy 0.5096153846153846\n",
            "Mpca 349 Mlda 27 Accuracy 0.5288461538461539\n",
            "Mpca 349 Mlda 28 Accuracy 0.5288461538461539\n",
            "Mpca 349 Mlda 29 Accuracy 0.5384615384615384\n",
            "Mpca 349 Mlda 30 Accuracy 0.5384615384615384\n",
            "Mpca 349 Mlda 31 Accuracy 0.5384615384615384\n",
            "Mpca 349 Mlda 32 Accuracy 0.5576923076923077\n",
            "Mpca 349 Mlda 33 Accuracy 0.5673076923076923\n",
            "Mpca 349 Mlda 34 Accuracy 0.5576923076923077\n",
            "Mpca 349 Mlda 35 Accuracy 0.5673076923076923\n",
            "Mpca 349 Mlda 36 Accuracy 0.5769230769230769\n",
            "Mpca 349 Mlda 37 Accuracy 0.5961538461538461\n",
            "Mpca 349 Mlda 38 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 39 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 40 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 41 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 42 Accuracy 0.5961538461538461\n",
            "Mpca 349 Mlda 43 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 44 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 45 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 46 Accuracy 0.6057692307692307\n",
            "Mpca 349 Mlda 47 Accuracy 0.6153846153846154\n",
            "Mpca 349 Mlda 48 Accuracy 0.6153846153846154\n",
            "Mpca 349 Mlda 49 Accuracy 0.6153846153846154\n",
            "Mpca 349 Mlda 50 Accuracy 0.6153846153846154\n",
            "Mpca 350 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 350 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 350 Mlda 3 Accuracy 0.1346153846153846\n",
            "Mpca 350 Mlda 4 Accuracy 0.19230769230769232\n",
            "Mpca 350 Mlda 5 Accuracy 0.2692307692307692\n",
            "Mpca 350 Mlda 6 Accuracy 0.3076923076923077\n",
            "Mpca 350 Mlda 7 Accuracy 0.2980769230769231\n",
            "Mpca 350 Mlda 8 Accuracy 0.3076923076923077\n",
            "Mpca 350 Mlda 9 Accuracy 0.3269230769230769\n",
            "Mpca 350 Mlda 10 Accuracy 0.36538461538461536\n",
            "Mpca 350 Mlda 11 Accuracy 0.36538461538461536\n",
            "Mpca 350 Mlda 12 Accuracy 0.38461538461538464\n",
            "Mpca 350 Mlda 13 Accuracy 0.40384615384615385\n",
            "Mpca 350 Mlda 14 Accuracy 0.40384615384615385\n",
            "Mpca 350 Mlda 15 Accuracy 0.4326923076923077\n",
            "Mpca 350 Mlda 16 Accuracy 0.4423076923076923\n",
            "Mpca 350 Mlda 17 Accuracy 0.4230769230769231\n",
            "Mpca 350 Mlda 18 Accuracy 0.4230769230769231\n",
            "Mpca 350 Mlda 19 Accuracy 0.41346153846153844\n",
            "Mpca 350 Mlda 20 Accuracy 0.4326923076923077\n",
            "Mpca 350 Mlda 21 Accuracy 0.4519230769230769\n",
            "Mpca 350 Mlda 22 Accuracy 0.47115384615384615\n",
            "Mpca 350 Mlda 23 Accuracy 0.4807692307692308\n",
            "Mpca 350 Mlda 24 Accuracy 0.5\n",
            "Mpca 350 Mlda 25 Accuracy 0.5096153846153846\n",
            "Mpca 350 Mlda 26 Accuracy 0.5096153846153846\n",
            "Mpca 350 Mlda 27 Accuracy 0.5096153846153846\n",
            "Mpca 350 Mlda 28 Accuracy 0.5192307692307693\n",
            "Mpca 350 Mlda 29 Accuracy 0.5288461538461539\n",
            "Mpca 350 Mlda 30 Accuracy 0.5480769230769231\n",
            "Mpca 350 Mlda 31 Accuracy 0.5384615384615384\n",
            "Mpca 350 Mlda 32 Accuracy 0.5384615384615384\n",
            "Mpca 350 Mlda 33 Accuracy 0.5384615384615384\n",
            "Mpca 350 Mlda 34 Accuracy 0.5384615384615384\n",
            "Mpca 350 Mlda 35 Accuracy 0.5480769230769231\n",
            "Mpca 350 Mlda 36 Accuracy 0.5480769230769231\n",
            "Mpca 350 Mlda 37 Accuracy 0.5673076923076923\n",
            "Mpca 350 Mlda 38 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 39 Accuracy 0.5769230769230769\n",
            "Mpca 350 Mlda 40 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 41 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 42 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 43 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 44 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 45 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 46 Accuracy 0.5865384615384616\n",
            "Mpca 350 Mlda 47 Accuracy 0.5769230769230769\n",
            "Mpca 350 Mlda 48 Accuracy 0.5673076923076923\n",
            "Mpca 350 Mlda 49 Accuracy 0.5769230769230769\n",
            "Mpca 350 Mlda 50 Accuracy 0.5769230769230769\n",
            "Mpca 351 Mlda 1 Accuracy 0.009615384615384616\n",
            "Mpca 351 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 351 Mlda 3 Accuracy 0.09615384615384616\n",
            "Mpca 351 Mlda 4 Accuracy 0.17307692307692307\n",
            "Mpca 351 Mlda 5 Accuracy 0.2403846153846154\n",
            "Mpca 351 Mlda 6 Accuracy 0.27884615384615385\n",
            "Mpca 351 Mlda 7 Accuracy 0.2692307692307692\n",
            "Mpca 351 Mlda 8 Accuracy 0.3269230769230769\n",
            "Mpca 351 Mlda 9 Accuracy 0.3173076923076923\n",
            "Mpca 351 Mlda 10 Accuracy 0.34615384615384615\n",
            "Mpca 351 Mlda 11 Accuracy 0.3557692307692308\n",
            "Mpca 351 Mlda 12 Accuracy 0.38461538461538464\n",
            "Mpca 351 Mlda 13 Accuracy 0.3942307692307692\n",
            "Mpca 351 Mlda 14 Accuracy 0.3942307692307692\n",
            "Mpca 351 Mlda 15 Accuracy 0.40384615384615385\n",
            "Mpca 351 Mlda 16 Accuracy 0.41346153846153844\n",
            "Mpca 351 Mlda 17 Accuracy 0.4326923076923077\n",
            "Mpca 351 Mlda 18 Accuracy 0.4326923076923077\n",
            "Mpca 351 Mlda 19 Accuracy 0.4423076923076923\n",
            "Mpca 351 Mlda 20 Accuracy 0.4519230769230769\n",
            "Mpca 351 Mlda 21 Accuracy 0.46153846153846156\n",
            "Mpca 351 Mlda 22 Accuracy 0.47115384615384615\n",
            "Mpca 351 Mlda 23 Accuracy 0.5\n",
            "Mpca 351 Mlda 24 Accuracy 0.5192307692307693\n",
            "Mpca 351 Mlda 25 Accuracy 0.5192307692307693\n",
            "Mpca 351 Mlda 26 Accuracy 0.5192307692307693\n",
            "Mpca 351 Mlda 27 Accuracy 0.5288461538461539\n",
            "Mpca 351 Mlda 28 Accuracy 0.5288461538461539\n",
            "Mpca 351 Mlda 29 Accuracy 0.5288461538461539\n",
            "Mpca 351 Mlda 30 Accuracy 0.5480769230769231\n",
            "Mpca 351 Mlda 31 Accuracy 0.5384615384615384\n",
            "Mpca 351 Mlda 32 Accuracy 0.5384615384615384\n",
            "Mpca 351 Mlda 33 Accuracy 0.5384615384615384\n",
            "Mpca 351 Mlda 34 Accuracy 0.5384615384615384\n",
            "Mpca 351 Mlda 35 Accuracy 0.5480769230769231\n",
            "Mpca 351 Mlda 36 Accuracy 0.5480769230769231\n",
            "Mpca 351 Mlda 37 Accuracy 0.5480769230769231\n",
            "Mpca 351 Mlda 38 Accuracy 0.5576923076923077\n",
            "Mpca 351 Mlda 39 Accuracy 0.5576923076923077\n",
            "Mpca 351 Mlda 40 Accuracy 0.5480769230769231\n",
            "Mpca 351 Mlda 41 Accuracy 0.5480769230769231\n",
            "Mpca 351 Mlda 42 Accuracy 0.5576923076923077\n",
            "Mpca 351 Mlda 43 Accuracy 0.5673076923076923\n",
            "Mpca 351 Mlda 44 Accuracy 0.5673076923076923\n",
            "Mpca 351 Mlda 45 Accuracy 0.5673076923076923\n",
            "Mpca 351 Mlda 46 Accuracy 0.5673076923076923\n",
            "Mpca 351 Mlda 47 Accuracy 0.5673076923076923\n",
            "Mpca 351 Mlda 48 Accuracy 0.5673076923076923\n",
            "Mpca 351 Mlda 49 Accuracy 0.5769230769230769\n",
            "Mpca 351 Mlda 50 Accuracy 0.5769230769230769\n",
            "Mpca 352 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 352 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 352 Mlda 3 Accuracy 0.15384615384615385\n",
            "Mpca 352 Mlda 4 Accuracy 0.18269230769230768\n",
            "Mpca 352 Mlda 5 Accuracy 0.2403846153846154\n",
            "Mpca 352 Mlda 6 Accuracy 0.25961538461538464\n",
            "Mpca 352 Mlda 7 Accuracy 0.2980769230769231\n",
            "Mpca 352 Mlda 8 Accuracy 0.28846153846153844\n",
            "Mpca 352 Mlda 9 Accuracy 0.3173076923076923\n",
            "Mpca 352 Mlda 10 Accuracy 0.34615384615384615\n",
            "Mpca 352 Mlda 11 Accuracy 0.36538461538461536\n",
            "Mpca 352 Mlda 12 Accuracy 0.375\n",
            "Mpca 352 Mlda 13 Accuracy 0.41346153846153844\n",
            "Mpca 352 Mlda 14 Accuracy 0.41346153846153844\n",
            "Mpca 352 Mlda 15 Accuracy 0.4326923076923077\n",
            "Mpca 352 Mlda 16 Accuracy 0.4326923076923077\n",
            "Mpca 352 Mlda 17 Accuracy 0.4326923076923077\n",
            "Mpca 352 Mlda 18 Accuracy 0.4326923076923077\n",
            "Mpca 352 Mlda 19 Accuracy 0.4423076923076923\n",
            "Mpca 352 Mlda 20 Accuracy 0.4519230769230769\n",
            "Mpca 352 Mlda 21 Accuracy 0.46153846153846156\n",
            "Mpca 352 Mlda 22 Accuracy 0.47115384615384615\n",
            "Mpca 352 Mlda 23 Accuracy 0.4807692307692308\n",
            "Mpca 352 Mlda 24 Accuracy 0.4807692307692308\n",
            "Mpca 352 Mlda 25 Accuracy 0.5096153846153846\n",
            "Mpca 352 Mlda 26 Accuracy 0.49038461538461536\n",
            "Mpca 352 Mlda 27 Accuracy 0.5\n",
            "Mpca 352 Mlda 28 Accuracy 0.5096153846153846\n",
            "Mpca 352 Mlda 29 Accuracy 0.5096153846153846\n",
            "Mpca 352 Mlda 30 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 31 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 32 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 33 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 34 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 35 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 36 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 37 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 38 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 39 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 40 Accuracy 0.5192307692307693\n",
            "Mpca 352 Mlda 41 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 42 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 43 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 44 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 45 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 46 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 47 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 48 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 49 Accuracy 0.5288461538461539\n",
            "Mpca 352 Mlda 50 Accuracy 0.5384615384615384\n",
            "Mpca 353 Mlda 1 Accuracy 0.019230769230769232\n",
            "Mpca 353 Mlda 2 Accuracy 0.08653846153846154\n",
            "Mpca 353 Mlda 3 Accuracy 0.10576923076923077\n",
            "Mpca 353 Mlda 4 Accuracy 0.14423076923076922\n",
            "Mpca 353 Mlda 5 Accuracy 0.21153846153846154\n",
            "Mpca 353 Mlda 6 Accuracy 0.23076923076923078\n",
            "Mpca 353 Mlda 7 Accuracy 0.28846153846153844\n",
            "Mpca 353 Mlda 8 Accuracy 0.27884615384615385\n",
            "Mpca 353 Mlda 9 Accuracy 0.3076923076923077\n",
            "Mpca 353 Mlda 10 Accuracy 0.33653846153846156\n",
            "Mpca 353 Mlda 11 Accuracy 0.3557692307692308\n",
            "Mpca 353 Mlda 12 Accuracy 0.34615384615384615\n",
            "Mpca 353 Mlda 13 Accuracy 0.36538461538461536\n",
            "Mpca 353 Mlda 14 Accuracy 0.375\n",
            "Mpca 353 Mlda 15 Accuracy 0.38461538461538464\n",
            "Mpca 353 Mlda 16 Accuracy 0.40384615384615385\n",
            "Mpca 353 Mlda 17 Accuracy 0.40384615384615385\n",
            "Mpca 353 Mlda 18 Accuracy 0.41346153846153844\n",
            "Mpca 353 Mlda 19 Accuracy 0.41346153846153844\n",
            "Mpca 353 Mlda 20 Accuracy 0.41346153846153844\n",
            "Mpca 353 Mlda 21 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 22 Accuracy 0.4230769230769231\n",
            "Mpca 353 Mlda 23 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 24 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 25 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 26 Accuracy 0.4423076923076923\n",
            "Mpca 353 Mlda 27 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 28 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 29 Accuracy 0.4230769230769231\n",
            "Mpca 353 Mlda 30 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 31 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 32 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 33 Accuracy 0.4230769230769231\n",
            "Mpca 353 Mlda 34 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 35 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 36 Accuracy 0.4326923076923077\n",
            "Mpca 353 Mlda 37 Accuracy 0.4423076923076923\n",
            "Mpca 353 Mlda 38 Accuracy 0.4519230769230769\n",
            "Mpca 353 Mlda 39 Accuracy 0.4519230769230769\n",
            "Mpca 353 Mlda 40 Accuracy 0.4519230769230769\n",
            "Mpca 353 Mlda 41 Accuracy 0.4423076923076923\n",
            "Mpca 353 Mlda 42 Accuracy 0.4423076923076923\n",
            "Mpca 353 Mlda 43 Accuracy 0.4423076923076923\n",
            "Mpca 353 Mlda 44 Accuracy 0.4519230769230769\n",
            "Mpca 353 Mlda 45 Accuracy 0.4519230769230769\n",
            "Mpca 353 Mlda 46 Accuracy 0.4423076923076923\n",
            "Mpca 353 Mlda 47 Accuracy 0.4423076923076923\n",
            "Mpca 353 Mlda 48 Accuracy 0.4519230769230769\n",
            "Mpca 353 Mlda 49 Accuracy 0.4519230769230769\n",
            "Mpca 353 Mlda 50 Accuracy 0.4519230769230769\n",
            "Mpca 354 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 354 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 354 Mlda 3 Accuracy 0.09615384615384616\n",
            "Mpca 354 Mlda 4 Accuracy 0.14423076923076922\n",
            "Mpca 354 Mlda 5 Accuracy 0.18269230769230768\n",
            "Mpca 354 Mlda 6 Accuracy 0.22115384615384615\n",
            "Mpca 354 Mlda 7 Accuracy 0.22115384615384615\n",
            "Mpca 354 Mlda 8 Accuracy 0.23076923076923078\n",
            "Mpca 354 Mlda 9 Accuracy 0.2692307692307692\n",
            "Mpca 354 Mlda 10 Accuracy 0.27884615384615385\n",
            "Mpca 354 Mlda 11 Accuracy 0.2692307692307692\n",
            "Mpca 354 Mlda 12 Accuracy 0.3076923076923077\n",
            "Mpca 354 Mlda 13 Accuracy 0.2980769230769231\n",
            "Mpca 354 Mlda 14 Accuracy 0.2980769230769231\n",
            "Mpca 354 Mlda 15 Accuracy 0.28846153846153844\n",
            "Mpca 354 Mlda 16 Accuracy 0.3076923076923077\n",
            "Mpca 354 Mlda 17 Accuracy 0.3173076923076923\n",
            "Mpca 354 Mlda 18 Accuracy 0.3269230769230769\n",
            "Mpca 354 Mlda 19 Accuracy 0.3269230769230769\n",
            "Mpca 354 Mlda 20 Accuracy 0.33653846153846156\n",
            "Mpca 354 Mlda 21 Accuracy 0.34615384615384615\n",
            "Mpca 354 Mlda 22 Accuracy 0.34615384615384615\n",
            "Mpca 354 Mlda 23 Accuracy 0.34615384615384615\n",
            "Mpca 354 Mlda 24 Accuracy 0.3557692307692308\n",
            "Mpca 354 Mlda 25 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 26 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 27 Accuracy 0.3557692307692308\n",
            "Mpca 354 Mlda 28 Accuracy 0.3557692307692308\n",
            "Mpca 354 Mlda 29 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 30 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 31 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 32 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 33 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 34 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 35 Accuracy 0.36538461538461536\n",
            "Mpca 354 Mlda 36 Accuracy 0.375\n",
            "Mpca 354 Mlda 37 Accuracy 0.375\n",
            "Mpca 354 Mlda 38 Accuracy 0.375\n",
            "Mpca 354 Mlda 39 Accuracy 0.375\n",
            "Mpca 354 Mlda 40 Accuracy 0.375\n",
            "Mpca 354 Mlda 41 Accuracy 0.375\n",
            "Mpca 354 Mlda 42 Accuracy 0.375\n",
            "Mpca 354 Mlda 43 Accuracy 0.375\n",
            "Mpca 354 Mlda 44 Accuracy 0.375\n",
            "Mpca 354 Mlda 45 Accuracy 0.375\n",
            "Mpca 354 Mlda 46 Accuracy 0.375\n",
            "Mpca 354 Mlda 47 Accuracy 0.375\n",
            "Mpca 354 Mlda 48 Accuracy 0.375\n",
            "Mpca 354 Mlda 49 Accuracy 0.375\n",
            "Mpca 354 Mlda 50 Accuracy 0.375\n",
            "Mpca 355 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 355 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 355 Mlda 3 Accuracy 0.10576923076923077\n",
            "Mpca 355 Mlda 4 Accuracy 0.1346153846153846\n",
            "Mpca 355 Mlda 5 Accuracy 0.16346153846153846\n",
            "Mpca 355 Mlda 6 Accuracy 0.21153846153846154\n",
            "Mpca 355 Mlda 7 Accuracy 0.22115384615384615\n",
            "Mpca 355 Mlda 8 Accuracy 0.25961538461538464\n",
            "Mpca 355 Mlda 9 Accuracy 0.28846153846153844\n",
            "Mpca 355 Mlda 10 Accuracy 0.3076923076923077\n",
            "Mpca 355 Mlda 11 Accuracy 0.3076923076923077\n",
            "Mpca 355 Mlda 12 Accuracy 0.3173076923076923\n",
            "Mpca 355 Mlda 13 Accuracy 0.3173076923076923\n",
            "Mpca 355 Mlda 14 Accuracy 0.33653846153846156\n",
            "Mpca 355 Mlda 15 Accuracy 0.3173076923076923\n",
            "Mpca 355 Mlda 16 Accuracy 0.3269230769230769\n",
            "Mpca 355 Mlda 17 Accuracy 0.33653846153846156\n",
            "Mpca 355 Mlda 18 Accuracy 0.34615384615384615\n",
            "Mpca 355 Mlda 19 Accuracy 0.36538461538461536\n",
            "Mpca 355 Mlda 20 Accuracy 0.36538461538461536\n",
            "Mpca 355 Mlda 21 Accuracy 0.3557692307692308\n",
            "Mpca 355 Mlda 22 Accuracy 0.3557692307692308\n",
            "Mpca 355 Mlda 23 Accuracy 0.3557692307692308\n",
            "Mpca 355 Mlda 24 Accuracy 0.3557692307692308\n",
            "Mpca 355 Mlda 25 Accuracy 0.36538461538461536\n",
            "Mpca 355 Mlda 26 Accuracy 0.375\n",
            "Mpca 355 Mlda 27 Accuracy 0.375\n",
            "Mpca 355 Mlda 28 Accuracy 0.375\n",
            "Mpca 355 Mlda 29 Accuracy 0.375\n",
            "Mpca 355 Mlda 30 Accuracy 0.375\n",
            "Mpca 355 Mlda 31 Accuracy 0.375\n",
            "Mpca 355 Mlda 32 Accuracy 0.375\n",
            "Mpca 355 Mlda 33 Accuracy 0.375\n",
            "Mpca 355 Mlda 34 Accuracy 0.375\n",
            "Mpca 355 Mlda 35 Accuracy 0.375\n",
            "Mpca 355 Mlda 36 Accuracy 0.375\n",
            "Mpca 355 Mlda 37 Accuracy 0.375\n",
            "Mpca 355 Mlda 38 Accuracy 0.375\n",
            "Mpca 355 Mlda 39 Accuracy 0.375\n",
            "Mpca 355 Mlda 40 Accuracy 0.375\n",
            "Mpca 355 Mlda 41 Accuracy 0.375\n",
            "Mpca 355 Mlda 42 Accuracy 0.375\n",
            "Mpca 355 Mlda 43 Accuracy 0.375\n",
            "Mpca 355 Mlda 44 Accuracy 0.375\n",
            "Mpca 355 Mlda 45 Accuracy 0.375\n",
            "Mpca 355 Mlda 46 Accuracy 0.375\n",
            "Mpca 355 Mlda 47 Accuracy 0.375\n",
            "Mpca 355 Mlda 48 Accuracy 0.375\n",
            "Mpca 355 Mlda 49 Accuracy 0.38461538461538464\n",
            "Mpca 355 Mlda 50 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 356 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 356 Mlda 3 Accuracy 0.11538461538461539\n",
            "Mpca 356 Mlda 4 Accuracy 0.125\n",
            "Mpca 356 Mlda 5 Accuracy 0.19230769230769232\n",
            "Mpca 356 Mlda 6 Accuracy 0.21153846153846154\n",
            "Mpca 356 Mlda 7 Accuracy 0.22115384615384615\n",
            "Mpca 356 Mlda 8 Accuracy 0.2692307692307692\n",
            "Mpca 356 Mlda 9 Accuracy 0.28846153846153844\n",
            "Mpca 356 Mlda 10 Accuracy 0.2980769230769231\n",
            "Mpca 356 Mlda 11 Accuracy 0.3173076923076923\n",
            "Mpca 356 Mlda 12 Accuracy 0.3269230769230769\n",
            "Mpca 356 Mlda 13 Accuracy 0.3269230769230769\n",
            "Mpca 356 Mlda 14 Accuracy 0.34615384615384615\n",
            "Mpca 356 Mlda 15 Accuracy 0.33653846153846156\n",
            "Mpca 356 Mlda 16 Accuracy 0.34615384615384615\n",
            "Mpca 356 Mlda 17 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 18 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 19 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 20 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 21 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 22 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 23 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 24 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 25 Accuracy 0.36538461538461536\n",
            "Mpca 356 Mlda 26 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 27 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 28 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 29 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 30 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 31 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 32 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 33 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 34 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 35 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 36 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 37 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 38 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 39 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 40 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 41 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 42 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 43 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 44 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 45 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 46 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 47 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 48 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 49 Accuracy 0.38461538461538464\n",
            "Mpca 356 Mlda 50 Accuracy 0.38461538461538464\n",
            "Mpca 357 Mlda 1 Accuracy 0.07692307692307693\n",
            "Mpca 357 Mlda 2 Accuracy 0.0673076923076923\n",
            "Mpca 357 Mlda 3 Accuracy 0.125\n",
            "Mpca 357 Mlda 4 Accuracy 0.16346153846153846\n",
            "Mpca 357 Mlda 5 Accuracy 0.17307692307692307\n",
            "Mpca 357 Mlda 6 Accuracy 0.21153846153846154\n",
            "Mpca 357 Mlda 7 Accuracy 0.2692307692307692\n",
            "Mpca 357 Mlda 8 Accuracy 0.2980769230769231\n",
            "Mpca 357 Mlda 9 Accuracy 0.28846153846153844\n",
            "Mpca 357 Mlda 10 Accuracy 0.28846153846153844\n",
            "Mpca 357 Mlda 11 Accuracy 0.2980769230769231\n",
            "Mpca 357 Mlda 12 Accuracy 0.3173076923076923\n",
            "Mpca 357 Mlda 13 Accuracy 0.3269230769230769\n",
            "Mpca 357 Mlda 14 Accuracy 0.33653846153846156\n",
            "Mpca 357 Mlda 15 Accuracy 0.3269230769230769\n",
            "Mpca 357 Mlda 16 Accuracy 0.33653846153846156\n",
            "Mpca 357 Mlda 17 Accuracy 0.33653846153846156\n",
            "Mpca 357 Mlda 18 Accuracy 0.33653846153846156\n",
            "Mpca 357 Mlda 19 Accuracy 0.33653846153846156\n",
            "Mpca 357 Mlda 20 Accuracy 0.3269230769230769\n",
            "Mpca 357 Mlda 21 Accuracy 0.34615384615384615\n",
            "Mpca 357 Mlda 22 Accuracy 0.34615384615384615\n",
            "Mpca 357 Mlda 23 Accuracy 0.34615384615384615\n",
            "Mpca 357 Mlda 24 Accuracy 0.34615384615384615\n",
            "Mpca 357 Mlda 25 Accuracy 0.34615384615384615\n",
            "Mpca 357 Mlda 26 Accuracy 0.34615384615384615\n",
            "Mpca 357 Mlda 27 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 28 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 29 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 30 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 31 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 32 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 33 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 34 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 35 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 36 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 37 Accuracy 0.3557692307692308\n",
            "Mpca 357 Mlda 38 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 39 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 40 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 41 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 42 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 43 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 44 Accuracy 0.375\n",
            "Mpca 357 Mlda 45 Accuracy 0.375\n",
            "Mpca 357 Mlda 46 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 47 Accuracy 0.36538461538461536\n",
            "Mpca 357 Mlda 48 Accuracy 0.375\n",
            "Mpca 357 Mlda 49 Accuracy 0.375\n",
            "Mpca 357 Mlda 50 Accuracy 0.375\n",
            "Mpca 358 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 358 Mlda 2 Accuracy 0.057692307692307696\n",
            "Mpca 358 Mlda 3 Accuracy 0.1346153846153846\n",
            "Mpca 358 Mlda 4 Accuracy 0.16346153846153846\n",
            "Mpca 358 Mlda 5 Accuracy 0.16346153846153846\n",
            "Mpca 358 Mlda 6 Accuracy 0.19230769230769232\n",
            "Mpca 358 Mlda 7 Accuracy 0.23076923076923078\n",
            "Mpca 358 Mlda 8 Accuracy 0.2403846153846154\n",
            "Mpca 358 Mlda 9 Accuracy 0.2692307692307692\n",
            "Mpca 358 Mlda 10 Accuracy 0.27884615384615385\n",
            "Mpca 358 Mlda 11 Accuracy 0.28846153846153844\n",
            "Mpca 358 Mlda 12 Accuracy 0.28846153846153844\n",
            "Mpca 358 Mlda 13 Accuracy 0.2980769230769231\n",
            "Mpca 358 Mlda 14 Accuracy 0.2980769230769231\n",
            "Mpca 358 Mlda 15 Accuracy 0.3076923076923077\n",
            "Mpca 358 Mlda 16 Accuracy 0.3076923076923077\n",
            "Mpca 358 Mlda 17 Accuracy 0.3076923076923077\n",
            "Mpca 358 Mlda 18 Accuracy 0.3076923076923077\n",
            "Mpca 358 Mlda 19 Accuracy 0.3076923076923077\n",
            "Mpca 358 Mlda 20 Accuracy 0.3076923076923077\n",
            "Mpca 358 Mlda 21 Accuracy 0.3173076923076923\n",
            "Mpca 358 Mlda 22 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 23 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 24 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 25 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 26 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 27 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 28 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 29 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 30 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 31 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 32 Accuracy 0.3269230769230769\n",
            "Mpca 358 Mlda 33 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 34 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 35 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 36 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 37 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 38 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 39 Accuracy 0.34615384615384615\n",
            "Mpca 358 Mlda 40 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 41 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 42 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 43 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 44 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 45 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 46 Accuracy 0.33653846153846156\n",
            "Mpca 358 Mlda 47 Accuracy 0.34615384615384615\n",
            "Mpca 358 Mlda 48 Accuracy 0.34615384615384615\n",
            "Mpca 358 Mlda 49 Accuracy 0.34615384615384615\n",
            "Mpca 358 Mlda 50 Accuracy 0.34615384615384615\n",
            "Mpca 359 Mlda 1 Accuracy 0.0673076923076923\n",
            "Mpca 359 Mlda 2 Accuracy 0.04807692307692308\n",
            "Mpca 359 Mlda 3 Accuracy 0.09615384615384616\n",
            "Mpca 359 Mlda 4 Accuracy 0.1346153846153846\n",
            "Mpca 359 Mlda 5 Accuracy 0.14423076923076922\n",
            "Mpca 359 Mlda 6 Accuracy 0.16346153846153846\n",
            "Mpca 359 Mlda 7 Accuracy 0.22115384615384615\n",
            "Mpca 359 Mlda 8 Accuracy 0.2403846153846154\n",
            "Mpca 359 Mlda 9 Accuracy 0.25\n",
            "Mpca 359 Mlda 10 Accuracy 0.2692307692307692\n",
            "Mpca 359 Mlda 11 Accuracy 0.2692307692307692\n",
            "Mpca 359 Mlda 12 Accuracy 0.27884615384615385\n",
            "Mpca 359 Mlda 13 Accuracy 0.28846153846153844\n",
            "Mpca 359 Mlda 14 Accuracy 0.2980769230769231\n",
            "Mpca 359 Mlda 15 Accuracy 0.2980769230769231\n",
            "Mpca 359 Mlda 16 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 17 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 18 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 19 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 20 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 21 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 22 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 23 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 24 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 25 Accuracy 0.3076923076923077\n",
            "Mpca 359 Mlda 26 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 27 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 28 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 29 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 30 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 31 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 32 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 33 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 34 Accuracy 0.3173076923076923\n",
            "Mpca 359 Mlda 35 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 36 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 37 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 38 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 39 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 40 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 41 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 42 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 43 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 44 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 45 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 46 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 47 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 48 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 49 Accuracy 0.3269230769230769\n",
            "Mpca 359 Mlda 50 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 1 Accuracy 0.057692307692307696\n",
            "Mpca 360 Mlda 2 Accuracy 0.057692307692307696\n",
            "Mpca 360 Mlda 3 Accuracy 0.07692307692307693\n",
            "Mpca 360 Mlda 4 Accuracy 0.125\n",
            "Mpca 360 Mlda 5 Accuracy 0.125\n",
            "Mpca 360 Mlda 6 Accuracy 0.16346153846153846\n",
            "Mpca 360 Mlda 7 Accuracy 0.20192307692307693\n",
            "Mpca 360 Mlda 8 Accuracy 0.23076923076923078\n",
            "Mpca 360 Mlda 9 Accuracy 0.25\n",
            "Mpca 360 Mlda 10 Accuracy 0.25\n",
            "Mpca 360 Mlda 11 Accuracy 0.2692307692307692\n",
            "Mpca 360 Mlda 12 Accuracy 0.2692307692307692\n",
            "Mpca 360 Mlda 13 Accuracy 0.28846153846153844\n",
            "Mpca 360 Mlda 14 Accuracy 0.27884615384615385\n",
            "Mpca 360 Mlda 15 Accuracy 0.27884615384615385\n",
            "Mpca 360 Mlda 16 Accuracy 0.28846153846153844\n",
            "Mpca 360 Mlda 17 Accuracy 0.2980769230769231\n",
            "Mpca 360 Mlda 18 Accuracy 0.2980769230769231\n",
            "Mpca 360 Mlda 19 Accuracy 0.2980769230769231\n",
            "Mpca 360 Mlda 20 Accuracy 0.3076923076923077\n",
            "Mpca 360 Mlda 21 Accuracy 0.2980769230769231\n",
            "Mpca 360 Mlda 22 Accuracy 0.3076923076923077\n",
            "Mpca 360 Mlda 23 Accuracy 0.3173076923076923\n",
            "Mpca 360 Mlda 24 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 25 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 26 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 27 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 28 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 29 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 30 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 31 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 32 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 33 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 34 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 35 Accuracy 0.3269230769230769\n",
            "Mpca 360 Mlda 36 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 37 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 38 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 39 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 40 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 41 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 42 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 43 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 44 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 45 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 46 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 47 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 48 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 49 Accuracy 0.33653846153846156\n",
            "Mpca 360 Mlda 50 Accuracy 0.33653846153846156\n",
            "Mpca 361 Mlda 1 Accuracy 0.028846153846153848\n",
            "Mpca 361 Mlda 2 Accuracy 0.038461538461538464\n",
            "Mpca 361 Mlda 3 Accuracy 0.0673076923076923\n",
            "Mpca 361 Mlda 4 Accuracy 0.1346153846153846\n",
            "Mpca 361 Mlda 5 Accuracy 0.17307692307692307\n",
            "Mpca 361 Mlda 6 Accuracy 0.20192307692307693\n",
            "Mpca 361 Mlda 7 Accuracy 0.23076923076923078\n",
            "Mpca 361 Mlda 8 Accuracy 0.25\n",
            "Mpca 361 Mlda 9 Accuracy 0.27884615384615385\n",
            "Mpca 361 Mlda 10 Accuracy 0.27884615384615385\n",
            "Mpca 361 Mlda 11 Accuracy 0.28846153846153844\n",
            "Mpca 361 Mlda 12 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 13 Accuracy 0.2980769230769231\n",
            "Mpca 361 Mlda 14 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 15 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 16 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 17 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 18 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 19 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 20 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 21 Accuracy 0.3076923076923077\n",
            "Mpca 361 Mlda 22 Accuracy 0.3269230769230769\n",
            "Mpca 361 Mlda 23 Accuracy 0.3269230769230769\n",
            "Mpca 361 Mlda 24 Accuracy 0.33653846153846156\n",
            "Mpca 361 Mlda 25 Accuracy 0.33653846153846156\n",
            "Mpca 361 Mlda 26 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 27 Accuracy 0.33653846153846156\n",
            "Mpca 361 Mlda 28 Accuracy 0.33653846153846156\n",
            "Mpca 361 Mlda 29 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 30 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 31 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 32 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 33 Accuracy 0.33653846153846156\n",
            "Mpca 361 Mlda 34 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 35 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 36 Accuracy 0.34615384615384615\n",
            "Mpca 361 Mlda 37 Accuracy 0.3557692307692308\n",
            "Mpca 361 Mlda 38 Accuracy 0.36538461538461536\n",
            "Mpca 361 Mlda 39 Accuracy 0.36538461538461536\n",
            "Mpca 361 Mlda 40 Accuracy 0.36538461538461536\n",
            "Mpca 361 Mlda 41 Accuracy 0.36538461538461536\n",
            "Mpca 361 Mlda 42 Accuracy 0.3557692307692308\n",
            "Mpca 361 Mlda 43 Accuracy 0.3557692307692308\n",
            "Mpca 361 Mlda 44 Accuracy 0.36538461538461536\n",
            "Mpca 361 Mlda 45 Accuracy 0.36538461538461536\n",
            "Mpca 361 Mlda 46 Accuracy 0.3557692307692308\n",
            "Mpca 361 Mlda 47 Accuracy 0.3557692307692308\n",
            "Mpca 361 Mlda 48 Accuracy 0.3557692307692308\n",
            "Mpca 361 Mlda 49 Accuracy 0.3557692307692308\n",
            "Mpca 361 Mlda 50 Accuracy 0.3557692307692308\n",
            "Mpca 362 Mlda 1 Accuracy 0.038461538461538464\n",
            "Mpca 362 Mlda 2 Accuracy 0.04807692307692308\n",
            "Mpca 362 Mlda 3 Accuracy 0.125\n",
            "Mpca 362 Mlda 4 Accuracy 0.11538461538461539\n",
            "Mpca 362 Mlda 5 Accuracy 0.16346153846153846\n",
            "Mpca 362 Mlda 6 Accuracy 0.20192307692307693\n",
            "Mpca 362 Mlda 7 Accuracy 0.22115384615384615\n",
            "Mpca 362 Mlda 8 Accuracy 0.25\n",
            "Mpca 362 Mlda 9 Accuracy 0.28846153846153844\n",
            "Mpca 362 Mlda 10 Accuracy 0.28846153846153844\n",
            "Mpca 362 Mlda 11 Accuracy 0.28846153846153844\n",
            "Mpca 362 Mlda 12 Accuracy 0.2980769230769231\n",
            "Mpca 362 Mlda 13 Accuracy 0.2980769230769231\n",
            "Mpca 362 Mlda 14 Accuracy 0.2980769230769231\n",
            "Mpca 362 Mlda 15 Accuracy 0.3076923076923077\n",
            "Mpca 362 Mlda 16 Accuracy 0.3076923076923077\n",
            "Mpca 362 Mlda 17 Accuracy 0.3076923076923077\n",
            "Mpca 362 Mlda 18 Accuracy 0.3076923076923077\n",
            "Mpca 362 Mlda 19 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 20 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 21 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 22 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 23 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 24 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 25 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 26 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 27 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 28 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 29 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 30 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 31 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 32 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 33 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 34 Accuracy 0.3269230769230769\n",
            "Mpca 362 Mlda 35 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 36 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 37 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 38 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 39 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 40 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 41 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 42 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 43 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 44 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 45 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 46 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 47 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 48 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 49 Accuracy 0.33653846153846156\n",
            "Mpca 362 Mlda 50 Accuracy 0.33653846153846156\n",
            "Mpca 363 Mlda 1 Accuracy 0.04807692307692308\n",
            "Mpca 363 Mlda 2 Accuracy 0.07692307692307693\n",
            "Mpca 363 Mlda 3 Accuracy 0.07692307692307693\n",
            "Mpca 363 Mlda 4 Accuracy 0.10576923076923077\n",
            "Mpca 363 Mlda 5 Accuracy 0.1346153846153846\n",
            "Mpca 363 Mlda 6 Accuracy 0.16346153846153846\n",
            "Mpca 363 Mlda 7 Accuracy 0.18269230769230768\n",
            "Mpca 363 Mlda 8 Accuracy 0.19230769230769232\n",
            "Mpca 363 Mlda 9 Accuracy 0.19230769230769232\n",
            "Mpca 363 Mlda 10 Accuracy 0.20192307692307693\n",
            "Mpca 363 Mlda 11 Accuracy 0.20192307692307693\n",
            "Mpca 363 Mlda 12 Accuracy 0.20192307692307693\n",
            "Mpca 363 Mlda 13 Accuracy 0.22115384615384615\n",
            "Mpca 363 Mlda 14 Accuracy 0.22115384615384615\n",
            "Mpca 363 Mlda 15 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 16 Accuracy 0.22115384615384615\n",
            "Mpca 363 Mlda 17 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 18 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 19 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 20 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 21 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 22 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 23 Accuracy 0.23076923076923078\n",
            "Mpca 363 Mlda 24 Accuracy 0.2403846153846154\n",
            "Mpca 363 Mlda 25 Accuracy 0.2403846153846154\n",
            "Mpca 363 Mlda 26 Accuracy 0.2403846153846154\n",
            "Mpca 363 Mlda 27 Accuracy 0.2403846153846154\n",
            "Mpca 363 Mlda 28 Accuracy 0.25\n",
            "Mpca 363 Mlda 29 Accuracy 0.25\n",
            "Mpca 363 Mlda 30 Accuracy 0.25\n",
            "Mpca 363 Mlda 31 Accuracy 0.25\n",
            "Mpca 363 Mlda 32 Accuracy 0.25\n",
            "Mpca 363 Mlda 33 Accuracy 0.25\n",
            "Mpca 363 Mlda 34 Accuracy 0.25\n",
            "Mpca 363 Mlda 35 Accuracy 0.25\n",
            "Mpca 363 Mlda 36 Accuracy 0.25\n",
            "Mpca 363 Mlda 37 Accuracy 0.25\n",
            "Mpca 363 Mlda 38 Accuracy 0.25\n",
            "Mpca 363 Mlda 39 Accuracy 0.25\n",
            "Mpca 363 Mlda 40 Accuracy 0.25\n",
            "Mpca 363 Mlda 41 Accuracy 0.25\n",
            "Mpca 363 Mlda 42 Accuracy 0.25\n",
            "Mpca 363 Mlda 43 Accuracy 0.25\n",
            "Mpca 363 Mlda 44 Accuracy 0.25\n",
            "Mpca 363 Mlda 45 Accuracy 0.25\n",
            "Mpca 363 Mlda 46 Accuracy 0.25\n",
            "Mpca 363 Mlda 47 Accuracy 0.25\n",
            "Mpca 363 Mlda 48 Accuracy 0.25\n",
            "Mpca 363 Mlda 49 Accuracy 0.25\n",
            "Mpca 363 Mlda 50 Accuracy 0.25\n",
            "Accuracy is highest for M_pca: 134 M_lda 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "Nr4XqhOuyBmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "07c13b02-c49f-4db8-c905-a774be1dd1a5"
      },
      "source": [
        "\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "x = np.linspace(1, M_lda_range, M_lda_range)\n",
        "y = np.linspace(1, M_pca_range, M_pca_range)\n",
        "\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "print(acc_array.shape)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(acc_array.min())\n",
        "fig = plt.figure(figsize=[10,5])\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.plot_surface(X, Y, acc_array, rstride=1, cstride=1,\n",
        "                cmap=plt.cm.CMRmap, edgecolor='none')\n",
        "ax.set_title('Accuracy varying M_pca & M_lda');\n",
        "ax.set_xlabel('M_lda')\n",
        "ax.set_ylabel('M_pca')\n",
        "ax.set_zlim3d(0,1)\n",
        "ax.set_zlabel('Accuracy');\n",
        "\n",
        "ax.view_init(30, 220)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(364, 51)\n",
            "(364, 51)\n",
            "(364, 51)\n",
            "-117.51285433658431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAEeCAYAAACOg886AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npdgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}